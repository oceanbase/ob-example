[
    {
        "path": "/Users/zhangying/Desktop/oceanbase-doc-4.1.0/zh-CN/200.quickstart/100.quickly-experience-oceanbase-for-community.md",
        "content": "快速体验 OceanBase 数据库 本文以部署 OceanBase 演示环境、部署 OceanBase 集群环境和部署 OceanBase 容器环境三种部署方案为例指导您如何快速使用 OceanBase 数据库。  注意   本文中的方法仅适用于 OceanBase 数据库快速上手体验，不适用生产环境，如需在生产环境中部署 OceanBase 数据库，请参考 部署数据库 章节。   本文提供的三种方案中，部署演示环境 和 部署集群环境 同时适用于企业版和社区版部署；部署容器环境 仅适用于社区版部署。    背景信息 OceanBase 数据库自 V4.0.0 开始提供统一的安装包 all-in-one package。您可以通过这个统一的安装包一次性完成 OBD、OceanBase 数据库、ODP、OBAgent、Grafana、Prometheus 的安装，自 V4.1.0 起，all-in-one package 新增支持安装 OCP Express。您可以根据实际需求选择部分或全部组件安装。 组件介绍  OBD   OceanBase Deployer，OceanBase 安装部署工具，简称为 OBD。详细信息请参考 OBD 文档。 ODP   OceanBase Database Proxy，OceanBase 数据库代理，是 OceanBase 数据库专用的代理服务器，简称为 ODP（又称为 OBProxy）。详细信息请参考 ODP 文档。 OCP Express   基于 Web 的 OceanBase 数据库 4.x 管理工具，融合在 OceanBase 数据库集群中，支持对数据库集群关键性能及基本数据库管理功能。详细信息请参考 OceanBase 云平台 Express (OCP Express)。 OBAgent   OBAgent 是 OceanBase 数据库监控采集框架，支持推、拉两种数据采集模式，可以满足不同的应用场景。详细信息可参见 OBAgent 章节。 Grafana   Grafana 是一款开源的数据可视化工具，它可以将数据源中的各种指标数据进行可视化展示，以便更直观地了解系统运行状态和性能指标。详细信息可参见 Grafana 官网。 Prometheus   Prometheus 是一个开源的服务监控系统和时序数据库，其提供了通用的数据模型以及快捷数据采集、存储和查询接口。详细信息可参见 Prometheus 官网。  方案介绍 为了助力您快速上手体验 OceanBase 数据库，我们提供了如下三种不同的方案实现快速部署 Oceanbase 数据，您可以根据自身环境情况灵活选择。 * 方案一：部署 OceanBase 演示环境   此方案适用于仅有一台机器时，快速搭建一个可用的 OceanBase 数据库环境。部署的 OceanBase 数据库环境具备数据库的基本功能，可以有效地帮助您了解 OceanBase 数据库；但是该环境不具备任何分布式能力及高可用特性，不建议长期使用。具体操作步骤请参考 方案一：部署 OceanBase 演示环境。 * 方案二：部署 OceanBase 集群环境   此方案适用于需要深入了解 OceanBase 分布式数据库架构原理及功能特性的用户。部署的 OceanBase 集群具备数据库完整能力及分布式高可用的特性。该方案需要您至少准备三台可用资源为 4vCPU、10 GB 内存、50 GB 磁盘的主机。具体操作步骤请参考 方案二：部署 OceanBase 集群环境。 * 方案三：部署 OceanBase 容器环境（仅适用于社区版）   此方案适用于希望通过容器实现部署、管理 OceanBase 数据库的用户。该方案未经过规模化的验证，建议谨慎使用。操作步骤请参考 方案三：部署 OceanBase 容器环境。 前提条件 在参考本文安装 OceanBase 数据库之前，确保您的软硬件环境满足以下要求：  描述 |  --- | Alibaba Cloud Linux 2/3 版本（内核 Linux 3.10.0 版本及以上）Anolis OS 8.X 版本（内核 Linux 3.10.0 版本及以上）Red Hat Enterprise Linux Server 7.X 版本、8.X 版本（内核 Linux 3.10.0 版本及以上）CentOS Linux 7.X 版本、8.X 版本（内核 Linux 3.10.0 版本及以上）Debian 9.X 版本及以上版本（内核 Linux 3.10.0 版本及以上）Ubuntu 20.X 版本及以上版本（内核 Linux 3.10.0 版本及以上）SUSE / OpenSUSE 15.X 版本及以上版本（内核 Linux 3.10.0 版本及以上） KylinOS V10 版本统信 UOS 1020a/1021a/1021e/1001c 版本中科方德 NFSChina 4.0 版本及以上浪潮 Inspur kos 5.8 版本 | 最低要求 2 核，推荐 4 核及以上。| 最低要求 8 GB，推荐设置在 16 GB 至 1024 GB 范围内。| 使用 SSD 存储。| 最低要求 54 GB。| EXT4 戓 XFS，当数据超过 16T 时，使用 XFS。|  all-in-one 安装包需选择 V4.1.0 及以上版本。|  使用 Docker 部署 OceanBase 数据库时需提前安装 Docker 并启动 Docker 服务，详细操作请参考 Docker 文档。|  说明  以下内容以 x86 架构的 CentOS Linux 7.9 镜像作为环境，其他环境可能略有不同。   方案一：部署 OceanBase 演示环境 当您仅拥有一台可用机器时，您可参考本节内容使用 obd demo 命令快速部署单机 OceanBase 数据库。 步骤一：下载并安装 all-in-one 安装包  下载 all-in-one 安装包，并将其上传到机器任一目录下。 企业版：请联系技术支持获取 all-in-one 安装包。 社区版：请从 OceanBase 软件下载中心 下载 all-in-one 安装包，建议下载最新版本。 在安装包所在目录下执行如下命令解压安装包并安装。     shell     [admin@test001 ~]$ tar -xzf oceanbase-all-in-one-*.tar.gz     [admin@test001 ~]$ cd oceanbase-all-in-one/bin/     [admin@test001 bin]$ ./install.sh     [admin@test001 bin]$ source ~/.oceanbase-all-in-one/bin/env.sh  步骤二：单机部署 OceanBase 数据库  执行以下命令，快速部署 OceanBase 数据库 企业版部署      shell      [admin@test001 ~]$ obd demo -c oceanbase,obproxy,obagent,prometheus,grafana  社区版部署      shell      [admin@test001 ~]$ obd demo obd demo 命令默认在当前用户家目录下以最小规格部署并启动 OceanBase 数据库及相关组件（包括 ODP、OBAgent、Grafana 和 Prometheus），固定部署名为 demo。如需更多定制化的部署形式，参见 快速部署命令。    您也可以使用 OBD 命令管理该 OceanBase 数据库，详细命令介绍请参考 集群命令组。    说明 当安装 grafana 或 prometheus 时，会输出 grafana 或 prometheus 的访问地址。在阿里云或其他云环境下，可能出现因无法获取公网 IP 而输出内网地址的情况，此 IP 非公网地址，您需要使用正确的地址。    执行输出中的连接命令连接数据库    obd demo 命令成功执行后会输出通过 OBClient 连接 OceanBase 数据库的命令，示例如下。  通过 2881 端口直连数据库      shell      [admin@test001 ~]$ obclient -h127.0.0.1 -P2881 -uroot@sys -Doceanbase -A 通过 ODP 代理访问数据库      shell      [admin@test001 ~]$ obclient -h127.0.0.1 -P2883 -uroot@sys -Doceanbase -A    使用 OBClient 客户端连接 OceanBase 集群的详细操作可参见 通过 OBClient 连接 OceanBase 租户。连接 OceanBase 数据库更多方法请参见 连接方式概述。 （可选）配置密码    使用 obd demo 命令快速部署 OceanBase 数据库后，您可参考如下步骤为 demo 集群配置密码。 修改配置文件       shell       obd cluster edit-config demo       执行上述命令打开配置文件后，在配置文件中 oceanbase-ce（社区版）/oceanbase（企业版） 组件下添加 root_password: xxxx，添加完成后保存退出。示例如下：       yaml      ",
        "product": "oceanbase",
        "version": "4.1.0"
    },
    {
        "path": "/Users/zhangying/Desktop/oceanbase-doc-4.1.0/zh-CN/200.quickstart/100.quickly-experience-oceanbase-for-community.md",
        "content": " oceanbase-ce:         servers:           - 127.0.0.1         global:           home_path: /home/admin/oceanbase-ce           ... # 省略部分配置项           log_disk_size: 13G           root_password: ****** 重启集群       修改并保存配置文件后，OBD 会输出待执行的重启命令，直接复制执行即可，示例如下。       shell       [admin@test001 ~]$ obd cluster edit-config demo       Search param plugin and load ok       Search param plugin and load ok       Parameter check ok       Save deploy \"demo\" configuration       Use `obd cluster reload demo` to make changes take effect.       Trace ID: 29dd12fa-3d73-11ee-91bc-00163e01cd7a       If you want to view detailed obd logs, please run: obd display-trace 29dd12fa-3d73-11ee-91bc-00163e01cd7a       从输出可以看出，修改配置文件中 root@sys 用户密码后，需执行 obd cluster reload demo 命令重启 demo 集群。    说明 您也可使用 root 用户登录数据库的 sys 租户后，通过 ALTER USER 命令修改用户密码。详细操作可参见 ALTER USER 。   方案二：部署 OceanBase 集群环境 当您拥有多台可用机器时，可参考本节内容使用 obd web 命令启动白屏，在白屏界面部署分布式 OceanBase 集群。  说明 本节仅介绍简单的操作，帮助您快速部署一个分布式 OceanBase 集群。更多配置介绍可参考 通过 OBD 白屏部署 OceanBase 集群 一文。  步骤一：下载并安装 all-in-one 安装包  下载 all-in-one 安装包，并将其上传到机器任一目录下。 企业版：请联系技术支持获取 all-in-one 安装包。 社区版：请从 OceanBase 软件下载中心 下载 all-in-one 安装包，建议下载最新版本。 在安装包所在目录下执行如下命令解压安装包并安装。     shell     [admin@test001 ~]$ tar -xzf oceanbase-all-in-one-*.tar.gz     [admin@test001 ~]$ cd oceanbase-all-in-one/bin/     [admin@test001 bin]$ ./install.sh     [admin@test001 bin]$ source ~/.oceanbase-all-in-one/bin/env.sh  步骤二：使用白屏部署 OceanBase 数据库   命令行执行 obd web 命令启动白屏界面，根据输出地址登录白屏界面并单击 开启体验之旅 开始部署。    shell    [admin@test001 ~]$ obd web    start OBD WEB in 0.0.0.0:8680    please open http://172.xx.xxx.233:8680   说明   白屏界面默认使用 8680 端口，您可使用 obd web -p <PORT> 命令指定端口。   在阿里云或其他云环境下，可能出现程序无法获取公网 IP，从而输出内网地址的情况，此 IP 非公网地址，您需要使用正确的地址访问白屏界面。   obd web 命令绑定在 0.0.0.0 上，在多网卡部署的情况下，您可通过任一一个可访问的 IP 访问白屏界面。      在 部署配置 界面修改 集群名称 和 部署类型，也可不做修改，使用默认配置。单击 下一步 进入 节点配置 页面。      在 节点配置 页面输入节点 IP 和用户密码，单击 下一步 进入 集群配置 页面。     在 集群配置 页面配置集群的部署模式、密码、目录、端口以及更多配置，您也可不做修改，使用默认配置。单击 下一步 进入 预检查 页面。     在 预检查 页面查看配置信息，无误后单击 预检查 进行检查。若预检查报错，您可根据页面建议选择 自动修复 或者单击 了解更多方案 跳转至错误码文档，参考文档自行修改。所有报错修改后，可单击 重新检查 再次进行预检查。     预检查通过后，单击 部署 开始 OceanBase 集群的部署。部署成功会输出各个组件的连接方式，您可复制进行访问。     单击 完成，结束部署流程。 使用 OBClient 客户端连接 OceanBase 数据库，或者登录 OCP Express 白屏界面管理集群。    使用 OBClient 客户端连接 OceanBase 集群的详细操作可参见 通过 OBClient 连接 OceanBase 租户。连接 OceanBase 数据库更多方法请参见 连接方式概述。 通过 2881 端口直连数据库，以直连 10.10.10.1 节点为例      shell      [admin@test001 ~]$ obclient -h10.10.10.1 -P2881 -uroot@sys -p -Doceanbase -A 通过 ODP 代理访问数据库，以 ODP 所在节点为 10.10.10.1 为例      shell      [admin@test001 ~]$ obclient -h10.10.10.1 -P2883 -uroot@sys -p -Doceanbase -A  方案三：部署 OceanBase 容器环境 您可参考本节内容在 Docker 容器里启动 OceanBase 数据库，帮助您快速了解 OceanBase 数据库。 （可选）步骤一：拉取 OceanBase 数据库镜像 运行如下命令，拉取 OceanBase 数据库所需镜像。 * 搜索 OceanBase 数据库相关镜像   shell   [admin@test001 ~]$ docker search oceanbase * 拉取 OceanBase 数据库最新镜像   shell   [admin@test001 ~]$ docker pull oceanbase/oceanbase-ce   说明  上述命令默认拉取最新版本，可根据实际需求在 Docker 镜像 中选择版本。  步骤二：启动 OceanBase 数据库实例 运行如下命令，启动 OceanBase 数据库实例。 * 根据当前容器部署最大规格实例   shell   [admin@test001 ~]$ docker run -p 2881:2881 --name obstandalone -e MINI_MODE=0 -d oceanbase/oceanbase-ce * 部署 mini 的独立实例   shell   [admin@test001 ~]$ docker run -p 2881:2881 --name obstandalone -e MINI_MODE=1 -d oceanbase/oceanbase-ce 启动预计需要 2~5 分钟。执行以下命令，如果返回 boot success!，则表示启动成功。 shell [admin@test001 ~]$ docker logs obstandalone | tail -1 boot success! 步骤三：连接 OceanBase 数据库实例 oceanbase-ce 镜像安装了 OceanBase 数据库客户端 OBClient，并提供了默认连接脚本 ob-mysql。 ```shell 使用 root 用户登录集群的 sys 租户 [admin@test001 ~]$ docker exec -it obstandalone ob-mysql sys 使用 root 用户登录集群的 test 租户 [admin@test001 ~]$ docker exec -it obstandalone ob-mysql root 使用 test 用户登录集群的 test 租户 [admin@test001 ~]$ docker exec -it obstandalone ob-mysql test ``` 您也可以运行以下命令，使用您本机的 OBClient 或者 MySQL 客户端连接实例。  说明 在 Docker 容器中启动 OceanBase 数据库后，您可登录集群执行 ALTER USER 命令修改用户密码，命令详细介绍请参见 ALTER USER。  shell [admin@test001 ~]$ obclient -uroot@sys -h127.1 -P2881 连接成功后，终端将显示如下内容： shell [admin@test001 ~]$ docker exec -it obstandalone ob-mysql s",
        "product": "oceanbase",
        "version": "4.1.0"
    },
    {
        "path": "/Users/zhangying/Desktop/oceanbase-doc-4.1.0/zh-CN/200.quickstart/100.quickly-experience-oceanbase-for-community.md",
        "content": "ys login as root@sys Command is: obclient -h127.1 -uroot@sys -A -Doceanbase -P2881 Welcome to the OceanBase.  Commands end with ; or \\g. Your OceanBase connection id is 3221487727 Server version: OceanBase_CE 4.1.0.0 (r100000192023032010-0265dfc6d00ff4f0ff4ad2710504a18962abaef6) (Built Mar 20 2023 10:12:57) Copyright (c) 2000, 2018, OceanBase and/or its affiliates. All rights reserved. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. obclient [oceanbase]>",
        "product": "oceanbase",
        "version": "4.1.0"
    },
    {
        "path": "/Users/zhangying/Desktop/oceanbase-doc-4.1.0/zh-CN/200.quickstart/800.tutorial-list.md",
        "content": "快速入门系列教程 您可以观看视频快速了解 OceanBase 数据库的安装部署和基本操作。 本教程主要介绍如何快速部署一套 OceanBase 数据库的测试体验环境，并提供了快速搭建应用以及 OceanBase 核心功能的快速体验指导。 本教程涵盖以下内容： * 部署 OceanBase 数据库体验和测试环境     * 使用 OBD 快速部署 OceanBase 数据库     * 使用 Docker 快速部署 OceanBase 数据库 * OceanBase 数据库的基本操作 * 创建示例应用程序     * 创建 Python 应用程序     * 创建 C 应用程序     * 创建 Go 应用程序     * 创建 Java 应用程序 * 体验 OceanBase 数据库高级特性（coming soon）     * 在 OceanBase 数据库上进行 TPC-C 测试     * 体验 OceanBase 数据库热点行更新能力     * 体验 Operational OLAP     * 体验并行导入 & 数据压缩     * 体验多租户特性     * 体验 DDL 使用 OBD 快速部署 OceanBase 数据库 本视频介绍了使用 OBD 快速部署社区版 OceanBase 数据库。  使用 Docker 快速部署 OceanBase 数据库 本视频介绍了使用 Docker 快速部署社区版 OceanBase 数据库。  OceanBase 数据库的基本操作 本视频介绍了社区版 OceanBase 数据库的一些基本操作。  创建 Python 应用程序 本视频介绍如何通过 Python 驱动连接和使用 OceanBase 数据库。  创建 C 应用程序 本视频介绍了如何通过 OceanBase Connector/C 驱动连接并使用 OceanBase 数据库。  创建 Go 应用程序 本视频介绍 Go 应用程序示例如何通过驱动 Go-SQL-Driver/MySQL 连接并使用 OceanBase 数据库。  创建 Java 应用程序 本视频介绍了如何通过 MySQL Connector/J 连接并使用 OceanBase 数据库。  在 OceanBase 数据库上进行 TPC-C 测试 在本视频中，通过在 OceanBase 数据库上运行 TPC-C 测试的方式，体验 OceanBase 数据库的 OLTP 能力。  体验 OceanBase 数据库热点行更新能力 本视频中，我们将通过构造一个多并发单行更新的场景，介绍 OceanBase 数据库 ELR 特性的使用方法和效果对比。  体验 Operational OLAP 本视频带您体验 OceanBase 的 Operational OLAP 功能。  体验并行导入 & 数据压缩 本视频介绍了并行导入和数据压缩相关的使用及说明。  体验多租户特性 本视频介绍了 OceanBase 数据库具有多租户的特性。在 OceanBase 数据库中，每一个租户即一个实例（类比 MySQL instance）。租户与租户之间数据、权限、资源隔离，每个租户拥有自己独立的访问端口及 CPU、内存访问资源。  体验 DDL 本视频介绍了 OceanBase 数据库 MySQL 模式下 DDL 新特性。 ",
        "product": "oceanbase",
        "version": "4.1.0"
    },
    {
        "path": "/Users/zhangying/Desktop/oceanbase-doc-4.1.0/zh-CN/200.quickstart/200.get-started-with-oceanbase-sql/200.basic-sql-operations-of-mysql-mode.md",
        "content": "SQL 基础操作（MySQL 模式） 本节主要介绍 OceanBase 数据库 MySQL 模式下的一些 SQL 基本操作。 创建数据库 使用 CREATE DATABASE 语句创建数据库。 示例：创建数据库 db1，指定字符集为 UTF8 ，并创建读写属性。 sql obclient> CREATE DATABASE db1 DEFAULT CHARACTER SET UTF8 READ WRITE; Query OK, 1 row affected 更多 CREATE DATABASE 语句相关的语法说明，请参见 CREATE DATABASE 章节。 创建完成后，可以通过 SHOW DATABASES 命令查看当前数据库服务器中所有的数据库。 sql obclient> SHOW DATABASES; 3 rows in set 表操作 在 OceanBase 数据库中，表是最基础的数据存储单元，包含了所有用户可以访问的数据，每个表包含多行记录，每个记录由多个列组成。本节主要提供数据库中表的创建、查看、修改和删除的语法和示例。 创建表 使用 CREATE TABLE 语句在数据库中创建新表。 示例：在数据库 db1 中创建表 test。 sql obclient> USE db1; Database changed obclient> CREATE TABLE test (c1 INT PRIMARY KEY, c2 VARCHAR(3)); Query OK, 0 rows affected 更多 CREATE TABLE 语句相关的语法说明，请参见 CREATE TABLE 章节。 查看表 使用 SHOW CREATE TABLE 语句查看建表语句。 示例： * 查看表 test 的建表语句。   sql   obclient> SHOW CREATE TABLE test\\G   *************************** 1. row ***************************         Table: test   Create Table: CREATE TABLE `test` (     `c1` int(11) NOT NULL,     `c2` varchar(3) DEFAULT NULL,     PRIMARY KEY (`c1`)   ) DEFAULT CHARSET = utf8mb4 ROW_FORMAT = DYNAMIC COMPRESSION = 'zstd_1.3.8' REPLICA_NUM = 1 BLOCK_SIZE = 16384 USE_BLOOM_FILTER = FALSE TABLET_SIZE = 134217728 PCTFREE = 0   1 row in set * 使用 SHOW TABLES 语句查看 db1 数据库中的所有表。   sql   obclient> SHOW TABLES FROM db1;   1 row in set 修改表 使用 ALTER TABLE 语句来修改已存在的表的结构，包括修改表及表属性、新增列、修改列及属性、删除列等。 示例： * 将表 test 的字段 c2 改名为 c3，并同时修改其字段类型。   sql   obclient> DESCRIBE test;    Type        Key  Extra |    int(11)     PRI        |    varchar(3)             |   2 rows in set   obclient> ALTER TABLE test CHANGE COLUMN c2 c3 CHAR(10);   Query OK, 0 rows affected   obclient> DESCRIBE test;    Type      Key  Extra |    int(11)   PRI        |    char(10)             |   2 rows in set * 在表 test 中增加、删除列。   sql   obclient> DESCRIBE test;    Type      Key  Extra |    int(11)   PRI        |    char(10)             |   2 rows in set   obclient> ALTER TABLE test ADD c4 int;   Query OK, 0 rows affected   obclient> DESCRIBE test;    Type      Key  Extra |    int(11)   PRI        |    char(10)             |    int(11)              |   3 rows in set   obclient> ALTER TABLE test DROP c3;   Query OK, 0 rows affected   obclient> DESCRIBE test;    Type     Key  Extra |    int(11)  PRI        |    int(11)             |   2 rows in set 更多 ALTER TABLE 语句相关的语法说明，请参见 ALTER TABLE 章节。 删除表 使用 DROP TABLE 语句删除表。 示例：删除表 test。 sql obclient> DROP TABLE test; Query OK, 0 rows affected 更多 DROP TABLE 语句相关的语法说明,请参见 DROP TABLE 章节。 索引操作 索引是创建在表上并对数据库表中一列或多列的值进行排序的一种结构。其作用主要在于提高查询的速度，降低数据库系统的性能开销。本节主要介绍数据库中索引的创建、查看、删除的语法和示例。 创建索引 使用 CREATE INDEX 语句创建表的索引。 示例：在表 test 中创建索引。 sql obclient> DESCRIBE test;  Type      Key  Extra |  int(11)   PRI        |  char(3)              | 2 rows in set obclient> CREATE INDEX test_index ON test (c1, c2); Query OK, 0 rows affected 更多 CREATE INDEX 语句相关的语法说明，请参见 CREATE INDEX 章节。 查看索引 使用 SHOW INDEX 语句查看表的索引。 示例：查看表 test 中的索引信息。 sql obclient> SHOW INDEX FROM test\\G *************************** 1. row ***************************         Table: test    Non_unique: 0      Key_name: PRIMARY  Seq_in_index: 1   Column_name: c1     Collation: A   Cardinality: NULL      Sub_part: NULL        Packed: NULL          Null:    Index_type: BTREE       Comment: available Index_comment:       Visible: YES *************************** 2. row ***************************         Table: test    Non_unique: 1      Key_name: test_index  Seq_in_index: 1   Column_name: c1     Collation: A   Cardinality: NULL      Sub_part: NULL        Packed: NULL          Null:    Index_type: BTREE       Comment: available Index_comment:       Visible: YES *************************** 3. row ***************************         Table: test    Non_unique: 1      Key_name: test_index  Seq_in_index: 2   Column_name: c2     Collation: A   Cardinality: NULL      Sub_part: NULL        Packed: NULL          Null: YES    Index_type: BTREE       Comment: available Index_comment:       Visible: YES 3 rows in set 删除索引 使用 DROP INDEX 语句删除表的索引。 示例：删除表 test 中的索引。 sql ",
        "product": "oceanbase",
        "version": "4.1.0"
    },
    {
        "path": "/Users/zhangying/Desktop/oceanbase-doc-4.1.0/zh-CN/200.quickstart/200.get-started-with-oceanbase-sql/200.basic-sql-operations-of-mysql-mode.md",
        "content": "obclient> DROP INDEX test_index ON test; Query OK, 0 rows affected 更多 DROP INDEX 语句相关的语法说明，请参见 DROP INDEX 章节。 插入数据 使用 INSERT 语句在已经存在的表中插入数据。 示例： * 创建表 t1 并插入一行数据。   sql   obclient> CREATE TABLE t1(c1 INT PRIMARY KEY, c2 int) PARTITION BY KEY(c1) PARTITIONS 4;   Query OK, 0 rows affected   obclient> SELECT * FROM t1;   Empty set   obclient> INSERT t1 VALUES(1,1);   Query OK, 1 row affected   obclient> SELECT * FROM t1;    c2   |       1 |   1 row in set * 向表 t1 中插入多行数据。   sql   obclient> INSERT t1 VALUES(2,2),(3,default),(2+2,3*4);   Query OK, 3 rows affected   Records: 3  Duplicates: 0  Warnings: 0   obclient> SELECT * FROM t1;    c2   |       1 |       2 |    NULL |      12 |   4 rows in set 更多 INSERT 语句相关的语法，请参见 INSERT 章节。 删除数据 使用 DELETE 语句删除数据，支持单表删除和多表删除数据。 示例： * 通过 CREATE TABLE 创建表 t2 和 t3。删除 c1=2 的行，其中 c1 列为表 t2 中的 PRIMARY KEY。   sql   /*表 `t3` 为 `KEY` 分区表，且分区名由系统根据分区命令规则自动生成，即分区名为 `p0`、`p1`、`p2`、`p3`*/   obclient> CREATE TABLE t2(c1 INT PRIMARY KEY, c2 INT);   Query OK, 0 rows affected   obclient> INSERT t2 VALUES(1,1),(2,2),(3,3),(5,5);   Query OK, 4 rows affected   Records: 4  Duplicates: 0  Warnings: 0   obclient> SELECT * FROM t2;    c2   |       1 |       2 |       3 |       5 |   4 rows in set   obclient> CREATE TABLE t3(c1 INT PRIMARY KEY, c2 INT) PARTITION BY KEY(c1) PARTITIONS 4;   Query OK, 0 rows affected   obclient> INSERT INTO t3 VALUES(5,5),(1,1),(2,2),(3,3);   Query OK, 4 rows affected   Records: 4  Duplicates: 0  Warnings: 0   obclient> SELECT * FROM t3;    c2   |       5 |       1 |       2 |       3 |   4 rows in set   obclient> DELETE FROM t2 WHERE c1 = 2;   Query OK, 1 row affected   obclient> SELECT * FROM t2;    c2   |       1 |       3 |       5 |   3 rows in set * 删除表 t2 中按照 c2 列排序之后的第一行数据。   sql   obclient> DELETE FROM t2 ORDER BY c2 LIMIT 1;   Query OK, 1 row affected   obclient> SELECT * FROM t2;    c2   |       3 |       5 |   2 rows in set * 删除表 t3 的 p2 分区的数据。   sql   obclient> SELECT * FROM t3 PARTITION(p2);     c2   |       1 |       2 |       3 |   3 rows in set   obclient> DELETE FROM t3 PARTITION(p2);    Query OK, 3 rows affected   obclient> SELECT * FROM t3;    c2   |        5 |   1 row in set * 删除 t2、t3 表中 t2.c1 = t3.c1 的数据。   sql   obclient> SELECT * FROM t2;    c2   |       3 |       5 |   2 rows in set   obclient> SELECT * FROM t3;    c2   |        5 |   obclient> DELETE t2, t3 FROM t2, t3 WHERE t2.c1 = t3.c1;   Query OK, 3 rows affected   /*等价于   obclient> DELETE FROM t2, t3 USING t2, t3 WHERE t2.c1 = t3.c1;   */   obclient> SELECT * FROM t2;    c2   |       3 |   1 row in set   obclient> SELECT * FROM t3;   Empty set 更多 DELETE 语句相关的语法说明，请参见 DELETE 章节。 更新数据 使用 UPDATE 语句修改表中的字段值。 示例： * 通过 CREATE TABLE 创建表 t4 和 t5，将表 t4 中 t4.c1=10 对应的那一行数据的 c2 列值修改为 100。   sql   obclient> CREATE TABLE t4(c1 INT PRIMARY KEY, c2 INT);   Query OK, 0 rows affected   obclient> INSERT t4 VALUES(10,10),(20,20),(30,30),(40,40);   Query OK, 4 rows affected   Records: 4  Duplicates: 0  Warnings: 0   obclient> SELECT * FROM t4;    c2   |      10 |      20 |      30 |      40 |   4 rows in set   obclient> CREATE TABLE t5(c1 INT PRIMARY KEY, c2 INT) PARTITION BY KEY(c1) PARTITIONS 4;   Query OK, 0 rows affected   obclient> INSERT t5 VALUES(50,50),(10,10),(20,20),(30,30);   Query OK, 4 rows affected   Records: 4  Duplicates: 0  Warnings: 0   obclient> SELECT * FROM t5;    c2   |      20 |      10 |      50 |      30 |   4 rows in set   obclient> UPDATE t4 SET t4.c2 = 100 WHERE t4.c1 = 10;   Query OK, 1 row affected   Rows matched: 1  Changed: 1  Warnings: 0   obclient> SELECT * FROM t4;    c2   |     100 |      20 |      30 |      40 |   4 rows in set * 将表 t4 中按照 c2 列排序的前两行数据的 c2 列值修改为 100。   sql   obclient> UPDATE t4 set t4.c2 = 100 ORDER BY c2 LIMIT 2;   Query OK, 2 rows affected   Rows matched: 2  Changed: 2  Warnings: 0   obclient> SELECT * FROM t4;    c2   |     100 |     100 |     100 |      40 |   4 rows in set * 将表 t5 中 p1 分区的数据中 t5.c1 > 20 的对应行数据的 c2 列值修改为 100。   sql   obclient> SELECT * FROM t5 PARTITIO",
        "product": "oceanbase",
        "version": "4.1.0"
    },
    {
        "path": "/Users/zhangying/Desktop/oceanbase-doc-4.1.0/zh-CN/200.quickstart/200.get-started-with-oceanbase-sql/200.basic-sql-operations-of-mysql-mode.md",
        "content": "N (p1);    c2   |      10 |      50 |   2 rows in set   obclient> UPDATE t5 PARTITION(p1) SET t5.c2 = 100 WHERE t5.c1 > 20;   Query OK, 1 row affected   Rows matched: 1  Changed: 1  Warnings: 0   obclient> SELECT * FROM t5 PARTITION(p1);    c2   |      10 |     100 |   2 rows in set * 对于表 t4 和表 t5 中满足 t4.c2 = t5.c2 对应行的数据，将表 t4 中的 c2 列值修改为 100，表 t5 中的 c2 列值修改为 200。   sql   obclient> UPDATE t4,t5 SET t4.c2 = 100, t5.c2 = 200 WHERE t4.c2 = t5.c2;   Query OK, 1 row affected    Rows matched: 4  Changed: 1  Warnings: 0   obclient> SELECT * FROM t4;    c2   |     100 |     100 |     100 |      40 |   4 rows in set   obclient> SELECT * FROM t5;    c2   |      20 |      10 |     200 |      30 |   4 rows in set 更多 UPDATE 语句相关的语法，请参见 UPDATE 章节。 查询数据 使用 SELECT 语句查询表中的内容。 示例： * 通过 CREATE TABLE 创建表 t6。从表 t6 中读取 name 的数据。   sql   obclient> CREATE TABLE t6 (id INT, name VARCHAR(50), num INT);   Query OK, 0 rows affected   obclient> INSERT INTO t6 VALUES(1,'a',100),(2,'b',200),(3,'a',50);   Query OK, 3 rows affected   Records: 3  Duplicates: 0  Warnings: 0   obclient> SELECT * FROM t6;    NAME     a        b        a       3 rows in set   obclient> SELECT name FROM t6;   3 rows in set * 在查询结果中对 name 进行去重处理。   sql   obclient> SELECT DISTINCT name FROM t6;   2 rows in set * 从表 t6 中根据筛选条件 name = 'a' ，输出对应的 id 、name 和 num。   sql   obclient> SELECT id, name, num FROM t6 WHERE name = 'a';    NAME     a        a       2 rows in set 更多 SELECT 语句相关的语法说明，请参见 SELECT 章节。 提交事务 使用 COMMIT 语句提交事务。 在提交事务（COMMIT）之前： * 您的修改只对当前会话可见，对其他数据库会话均不可见。 * 您的修改没有持久化，您可以通过 ROLLBACK 语句撤销修改。 在提交事务（COMMIT）之后： * 您的修改对所有数据库会话可见。 * 您的修改持久化成功，不能通过 ROLLBACK 语句回滚修改。 示例：通过 CREATE TABLE 创建表 t_insert。使用 COMMIT 语句提交事务。 sql obclient> BEGIN; Query OK, 0 rows affected obclient> CREATE TABLE t_insert(     id number NOT NULL PRIMARY KEY,     name varchar(10) NOT NULL,      value number,     gmt_create DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP  ); Query OK, 0 rows affected obclient> INSERT INTO t_insert(id, name, value, gmt_create) VALUES(1,'CN',10001, current_timestamp),(2,'US',10002, current_timestamp),(3,'EN',10003, current_timestamp); Query OK, 3 rows affected Records: 3  Duplicates: 0  Warnings: 0 obclient> SELECT * FROM t_insert;  name  gmt_create          |  CN    2022-08-22 16:19:26 |  US    2022-08-22 16:19:26 |  EN    2022-08-22 16:19:26 | 3 rows in set obclient> INSERT INTO t_insert(id,name) VALUES(4,'JP'); Query OK, 1 row affected obclient> COMMIT; Query OK, 0 rows affected obclient> exit; Bye obclient> obclient -h127.0.0.1 -ur**t@mysql -P2881 -p****** -Ddb1 obclient> SELECT * FROM t_insert;  name  gmt_create          |  CN    2022-08-22 16:19:26 |  US    2022-08-22 16:19:26 |  EN    2022-08-22 16:19:26 |  JP    2022-08-22 16:21:39 | 4 rows in set 更多事务控制语句相关的说明请参见 事务管理概述。 回滚事务 使用 ROLLBACK 语句回滚事务。 回滚一个事务指将事务的修改全部撤销。可以回滚当前整个未提交的事务，也可以回滚到事务中任意一个保存点。如果要回滚到某个保存点，必须结合使用 ROLLBACK 和 TO SAVEPOINT 语句。 其中： * 如果回滚整个事务，则：   * 事务会结束   * 所有的修改会被丢弃   * 清除所有保存点   * 释放事务持有的所有锁 * 如果回滚到某个保存点，则：   * 事务不会结束   * 保存点之前的修改被保留，保存点之后的修改被丢弃   * 清除保存点之后的保存点（不包括保存点自身）   * 释放保存点之后事务持有的所有锁 示例：回滚事务的全部修改。 sql obclient> SELECT * FROM t_insert;  name  gmt_create          |  CN    2022-08-22 16:19:26 |  US    2022-08-22 16:19:26 |  EN    2022-08-22 16:19:26 | 3 rows in set obclient> BEGIN; Query OK, 0 rows affected obclient> INSERT INTO t_insert(id, name, value) VALUES(4,'JP',10004),(5,'FR',10005),(6,'RU',10006); Query OK, 3 rows affected Records: 3  Duplicates: 0  Warnings: 0 obclient> SELECT * FROM t_insert;  name  gmt_create          |  CN    2022-08-22 16:19:26 |  US    2022-08-22 16:19:26 |  EN    2022-08-22 16:19:26 |  JP    2022-08-22 16:26:23 |  FR    2022-08-22 16:26:23 |  RU    2022-08-22 16:26:23 | 6 rows in set obclient> ROLLBACK; Query OK, 0 rows affected obclient> SELECT * FROM t_insert;  name  gmt_create          |  CN    2022-08-22 16:19:26 |  US    2022-08-22 16:19:26 |  EN    2022-08-22 16:19:26 | 3 rows in set 更多事务控制语句相关的说明，请参见 事务管理概述。",
        "product": "oceanbase",
        "version": "4.1.0"
    },
    {
        "path": "/Users/zhangying/Desktop/oceanbase-doc-4.1.0/zh-CN/200.quickstart/200.get-started-with-oceanbase-sql/100.before-you-start.md",
        "content": "在您开始前 为了能更好的体验和上手 OceanBase 分布式数据库，请您在开始尝试使用前，先了解 内存 和 超时时间 这两个最常见的特性差异。 关于内存 OceanBase 数据库是基于 LSM-Tree 的存储引擎，不同于传统数据库实时刷脏页的机制，OceanBase 数据库将数据分为内存中的 MemTable 和磁盘中的 SSTable，其中所有的数据更新写入操作都在内存的 MemTable 中完成，并且在内存使用量达到一定阈值后触发 Compaction，转储至 SSTable，并释放活跃的内存。这种架构的优势是可以将随机 I/O 转化为顺序 I/O，提供更大的写入吞吐能力。详细介绍请参考 存储架构概述。 由于 LSM-Tree 将增量数据都存放在内存中，达到一定阈值后才触发转储，这会导致小规格的租户实例运行在超过其可承载能力的密集写入场景时（例如数据导入或者运行大量数据批处理场景），会因为 MemTable 达到上限而无法接受新的请求。OceanBase 数据库有如下几种处理方式： * 开启写入限速：设置内存写入达到一定阈值后，OceanBase 数据库主动限制客户端导入速度。 * 租户内存扩容：环境中节点总内存资源相对充足，可扩大租户内存。 * 调整租户内存中 MemTable 的比例：当节点总内存有限，无法扩容时，还可调整租户内存中 MemTable 的比例，扩大可写入内存，并且调低转储阈值，让转储更快发生。 开启写入限速 OceanBase 数据库具备写入过载保护功能，当资源有限，无法扩展内存时，可以通过服务端写入限速来保护内存，避免写入超限。可通过设置如下两个配置项来开启服务端的写入限速功能： * writing_throttling_trigger_percentage：用于设置写入速度的阈值，即当 MemStore 已使用的内存达到该阈值（百分比）时，触发写入限速。该配置项的取值范围为 [1, 100]，默认值为 60，取值为 100 表示关闭写入限速机制。 * writing_throttling_maximum_duration ：指定触发写入限速后，剩余 MemStore 内存分配完所需的时间。默认值为 2h，该配置项一般不做修改。 在租户的管理员账号中，设置内存写入达到 80% 开始限速，并保证剩余内存足够提供 2h 的写入限速，示例如下： sql obclient> ALTER SYSTEM SET writing_throttling_trigger_percentage = 80;  Query OK, 0 rows affected obclient> ALTER SYSTEM SET writing_throttling_maximum_duration = '2h'; Query OK, 0 rows affected 租户内存扩容 当环境中的内存资源相对充足时，最佳处理方案是增大租户内存。 内存配置步骤如下： 1. 使用 root 用户登录 OceanBase 集群的 sys 租户，执行以下 SQL 语句，确认当前租户使用的 UNIT_CONFIG NAME。    sql    obclient> SELECT NAME FROM DBA_OB_UNIT_CONFIGS;    2 rows in set   说明  sys_unit_config  是管控租户的参数，一般不做修改。本示例中租户 test  的 unit_config name  为 test_unit 。    复制租户的 unit_config name，使用如下命令，完成内存扩容。    sql    obclient> ALTER RESOURCE UNIT test_unit MIN_CPU = 2, MAX_CPU = 2, MEMORY_SIZE = '10G', MAX_IOPS = 10000, MIN_IOPS = 10000;   注意 当前版本中，仅 CPU、Memory 配置生效，其他 I/O 参数（例如 IOPS）暂不生效。   调整租户内存中 MemTable 的比例 通过如下配置项来调整租户内存中 MemTable 的比例： * freeze_trigger_percentage：当租户的 MemTable 内存的使用量达到此配置项所限制使用的百分比时，就会自动触发转储，转储后会释放占用的内存。该配置项取值范围 [1,99]，默认值为 20，表示当 MemStore 使用率超过 20%，就会触发转储。 * memstore_limit_percentage：该配置项用于控制租户内存中可用于 MemStore 写入的比例，取值范围 [1,99]，默认值为 50，表示租户可使用的 MemStore 占其总可用内存的 50%。 当内存不足时，可以调高 memstore_limit_percentage 的取值，并调低 freeze_trigger_percentage 的取值，从而达到临时扩容和尽快转储释放的效果。 使用 root 用户登录 OceanBase 集群的 sys 租户，调高 memstore_limit_percentage 的取值，并调低 freeze_trigger_percentage 的取值，示例如下： sql obclient> ALTER SYSTEM SET freeze_trigger_percentage = 20; Query OK, 0 rows affected  obclient> ALTER SYSTEM SET memstore_limit_percentage = 70; Query OK, 0 rows affected 关于超时时间 在 OceanBase 数据库中，您可能在查询或执行 DML 操作时遇到 timeout 或 Transaction is timeout 的错误，这是因为 OceanBase 数据库对查询和事务超时做了默认配置，方便用户针对不同业务场景进行调整。 OceanBase 数据库提供了以下超时时间相关的变量，可使用 SHOW VARIABLES LIKE '%timeout%'; 命令进行查看。 * ob_query_timeout：查询超时时间，单位 us，默认值为 10000000。 * ob_trx_timeout：事务超时时间，单位 us，默认值 86400000000。 * ob_trx_idle_timeout：事务空闲超时时间，单位 us，默认值 86400000000。 设置超时时间 超时时间的设置方法如下： * 在会话/全局进行变量设置。示例如下：    sql    obclient> SET ob_query_timeout = 10000000;    Query OK, 0 rows affected     obclient> SET GLOBAL ob_query_timeout = 10000000;    Query OK, 0 rows affected * 在 JDBC 连接串中设置。示例如下：    html    jdbc:oceanbase://10.1.0.0:1001/unittests?user=**u**@sys&password=******&sessionVariables = ob_query_timeout = 60000000000,ob_trx_timeout = 60000000000&xxxx * 在 SQL 级别添加 Hint 设置。示例如下：    说明 此方式只对当前 SQL 语句生效。   sql    SELECT /*+query_timeout(100000000)  */  c1 FROM t1; 更多关于数据库开发、管理方面的详细内容，请参见 《应用开发》 和 《管理数据库》。",
        "product": "oceanbase",
        "version": "4.1.0"
    },
    {
        "path": "/Users/zhangying/Desktop/oceanbase-doc-4.1.0/zh-CN/200.quickstart/200.get-started-with-oceanbase-sql/300.basic-sql-operations-of-oracle-mode.md",
        "content": "SQL 基础操作（Oracle 模式） 本节主要介绍 OceanBase 数据库 Oracle 模式下的一些 SQL 基本操作。   功能适用性 该内容仅适用于 OceanBase 数据库企业版。OceanBase 数据库社区版仅提供 MySQL 模式。  表操作 本节主要提供数据库中表的创建、查看、修改和删除的语法和示例。 创建表 使用 CREATE TABLE 语句在数据库中创建新表。 示例：创建表 test。 sql obclient> CREATE TABLE test (c1 INT PRIMARY KEY, c2 VARCHAR(3)); Query OK, 0 rows affected 更多 CREATE TABLE 语句相关的语法说明，请参见 CREATE TABLE 章节。 修改表 使用 ALTER TABLE 语句来修改已存在的表的结构，包括修改表及表属性、新增列、修改列及属性、删除列等。 示例： * 修改表 test 的字段 c2 的字段类型。   sql   obclient> DESCRIBE test;    TYPE         KEY  EXTRA |    NUMBER(38)   PRI  NULL  |    VARCHAR2(3)  NULL NULL  |   2 rows in set   obclient> ALTER TABLE test MODIFY c2 CHAR(10);   Query OK, 0 rows affected   obclient> DESCRIBE test;    TYPE        KEY  EXTRA |    NUMBER(38)  PRI  NULL  |    CHAR(10)    NULL NULL  |   2 rows in set * 在表 test 中增加、删除列。   sql   obclient> ALTER TABLE test ADD c3 int;   Query OK, 0 rows affected   obclient> DESCRIBE test;    TYPE        KEY  EXTRA |    NUMBER(38)  PRI  NULL  |    CHAR(10)    NULL  NULL  |    NUMBER(38)  NULL  NULL  |   3 rows in set   obclient> ALTER TABLE test DROP COLUMN c3;   Query OK, 0 rows affected   obclient> DESCRIBE test;    TYPE        KEY  EXTRA |    NUMBER(38)  PRI  NULL  |    CHAR(10)    NULL  NULL  |   2 rows in set 更多 ALTER TABLE 语句相关的语法说明，请参见 ALTER TABLE 章节。 删除表 使用 DROP TABLE 语句删除表。 示例：删除表 test。 sql obclient> DROP TABLE test; Query OK, 0 rows affected 更多 DROP TABLE 语句相关的语法说明，请参见 DROP TABLE 章节。 索引操作 索引是创建在表上并对数据库表中一列或多列的值进行排序的一种结构。其作用主要在于提高查询的速度，降低数据库系统的性能开销。 创建索引 使用 CREATE INDEX 语句创建表的索引。 示例：创建表 test 的索引。 sql obclient> DESCRIBE test;  TYPE        KEY  EXTRA |  NUMBER(38)  PRI  NULL  |  CHAR(10)    NULL  NULL  | 2 rows in set  obclient> CREATE INDEX test_index ON test (c1, c2); Query OK, 0 rows affected 更多 CREATE INDEX 语句相关的语法说明，请参见 CREATE INDEX 章节。 查看索引  通过视图 ALL_INDEXES 查看表的所有索引。   sql   obclient> SELECT OWNER,INDEX_NAME,INDEX_TYPE,TABLE_OWNER,TABLE_NAME FROM ALL_INDEXES WHERE table_name='TEST'\\G   *************************** 1. row ***************************                     OWNER: SYS               INDEX_NAME: TEST_OBPK_1664353339491130               INDEX_TYPE: NORMAL               TABLE_OWNER: SYS               TABLE_NAME: TEST   *************************** 2. row ***************************                     OWNER: SYS               INDEX_NAME: TEST_INDEX               INDEX_TYPE: NORMAL               TABLE_OWNER: SYS               TABLE_NAME: TEST   2 rows in set 通过 USER_IND_COLUMNS 查看表索引的详细信息。   sql   obclient> SELECT * FROM USER_IND_COLUMNS WHERE table_name='TEST'\\G   *************************** 1. row ***************************           INDEX_NAME: TEST_OBPK_1664353339491130           TABLE_NAME: TEST         COLUMN_NAME: C1     COLUMN_POSITION: 1       COLUMN_LENGTH: 22         CHAR_LENGTH: 0             DESCEND: ASC   COLLATED_COLUMN_ID: NULL   *************************** 2. row ***************************           INDEX_NAME: TEST_INDEX           TABLE_NAME: TEST         COLUMN_NAME: C1     COLUMN_POSITION: 1       COLUMN_LENGTH: 22         CHAR_LENGTH: 0             DESCEND: ASC   COLLATED_COLUMN_ID: NULL   *************************** 3. row ***************************           INDEX_NAME: TEST_INDEX           TABLE_NAME: TEST         COLUMN_NAME: C2     COLUMN_POSITION: 2       COLUMN_LENGTH: 10         CHAR_LENGTH: 10             DESCEND: ASC   COLLATED_COLUMN_ID: NULL   3 rows in set  删除索引 使用 DROP INDEX 语句删除表的索引。 示例：删除索引 test_index。 sql obclient> DROP INDEX test_index; Query OK, 0 rows affected 更多 DROP INDEX 语句相关的语法说明，请参见 DROP INDEX 章节。 插入数据 使用 INSERT 语句添加一个或多个记录到表中。 示例： * 通过 CREATE TABLE 创建表 t1，并向表 t1 中插入一行数据。   sql   obclient> CREATE TABLE t1(c1 INT PRIMARY KEY, c2 INT);   Query OK, 0 rows affected   obclient> SELECT * FROM t1;   Empty set   obclient> INSERT INTO t1 VALUES(1,1);   Query OK, 1 row affected   obclient> SELECT * FROM t1;    c2   |       1 |   1 row in set * 直接向子查询中插入数据。   sql   obclient> INSERT INTO (SELECT * FROM t1) VALUES(2,2);   Query OK, 1 row affected   obclient> SELECT * FROM t1",
        "product": "oceanbase",
        "version": "4.1.0"
    },
    {
        "path": "/Users/zhangying/Desktop/oceanbase-doc-4.1.0/zh-CN/200.quickstart/200.get-started-with-oceanbase-sql/300.basic-sql-operations-of-oracle-mode.md",
        "content": ";    C2   |       1 |       2 |   2 rows in set * 包含 RETURNING 子句的数据插入。   sql   obclient> INSERT INTO t1 VALUES(3,3) RETURNING c1;   1 row in set   obclient> SELECT * FROM t1;    C2   |       1 |       2 |       3 |   3 rows in set 更多 INSERT 语句相关的语法，请参见 INSERT 章节。 删除数据 使用 DELETE 语句删除数据。 示例：删除表 t1 中 c1=2 的行。 sql obclient> DELETE FROM t1 WHERE c1 = 2; Query OK, 1 row affected obclient> SELECT * FROM t1;  C2   |     1 |     3 | 2 rows in set 更多 DELETE 语句相关的语法说明，请参见 DELETE 章节。 更新数据 使用 UPDATE 语句修改表中的字段值。 示例: * 将表 t1 中 t1.c1=1 对应的那一行数据的 c2 列值修改为 100。   sql   obclient> UPDATE t1 SET t1.c2 = 100 WHERE t1.c1 = 1;   Query OK, 1 row affected   Rows matched: 1  Changed: 1  Warnings: 0   obclient> SELECT * FROM t1;    C2   |     100 |       3 |   2 rows in set * 直接操作子查询，将子查询中 v.c1=3 对应的那一行数据的 c2 列值修改为 300。   sql   obclient> UPDATE (SELECT * FROM t1) v SET v.c2 = 300 WHERE v.c1 = 3;   Query OK, 1 row affected   Rows matched: 1  Changed: 1  Warnings: 0   obclient> SELECT * FROM t1;    C2   |     100 |     300 |   2 rows in set 更多 UPDATE 语句相关的语法，请参见 UPDATE 章节。 查询数据 使用 SELECT 语句查询表中的内容。 示例： * 通过 CREATE TABLE 创建表 t2。从表 t2 中读取 name 的数据。   sql   obclient> CREATE TABLE t2 (id INT, name VARCHAR(50), num INT);   Query OK, 0 rows affected   obclient> INSERT INTO t2 VALUES(1,'a',100),(2,'b',200),(3,'a',50);   Query OK, 3 rows affected   Records: 3  Duplicates: 0  Warnings: 0   obclient> SELECT * FROM t2;    NAME     a        b        a       3 rows in set   obclient> SELECT name FROM t2;   3 rows in set * 在查询结果中对 name 进行去重处理。   sql   obclient> SELECT DISTINCT name FROM t2;   2 rows in set * 从表 t2 中根据筛选条件 name = 'a' ，输出对应的 id 、name 和 num。   sql   obclient> SELECT id, name, num FROM t2 WHERE name = 'a';    NAME     a        a       2 rows in set 更多 SELECT 语句相关的语法说明，请参见 SELECT 章节。 提交事务 使用 COMMIT 语句提交事务。 在您提交事务之前，您的修改只对当前会话可见，对其他数据库会话是不可见的；您的修改没有持久化，可以用 ROLLBACK 语句撤销修改。 在您提交事务之后，您的修改对所有数据库会话可见。您的修改结果持久化成功，不可以用 ROLLBACK 语句回滚修改。 示例：通过 CREATE TABLE 创建表 t_insert。使用 COMMIT 语句提交事务。 sql obclient> CREATE TABLE t_insert(      id number NOT NULL PRIMARY KEY,       name varchar(10) NOT NULL,       value number NOT NULL,       gmt_create date NOT NULL DEFAULT sysdate  ); Query OK, 0 rows affected obclient> INSERT INTO t_insert(id, name, value, gmt_create) VALUES(1,'CN',10001, sysdate),(2,'US',10002, sysdate),(3,'EN',10003, sysdate); Query OK, 3 rows affected Records: 3  Duplicates: 0  Warnings: 0 obclient> SELECT * FROM t_insert;  NAME  GMT_CREATE |  CN    22-AUG-22  |  US    22-AUG-22  |  EN    22-AUG-22  | 3 rows in set obclient> INSERT INTO t_insert(id, name, value) VALUES(4,'JP',10004); Query OK, 1 row affected obclient> COMMIT; Query OK, 0 rows affected obclient> exit; Bye obclient> obclient -h127.0.0.1 -us**@oracle -P2881 -p****** obclient> SELECT * FROM t_insert;  NAME  GMT_CREATE |  CN    22-AUG-22  |  US    22-AUG-22  |  EN    22-AUG-22  |  JP    22-AUG-22  | 4 rows in set 更多事务控制语句相关的说明，请参见 事务管理概述。 回滚事务 使用 ROLLBACK 语句可以回滚事务。 回滚一个事务指将事务的修改全部撤销。可以回滚当前整个未提交的事务，也可以回滚到事务中任意一个保存点。如果要回滚到某个保存点，必须结合使用 ROLLBACK和 TO SAVEPOINT 语句。 其中： * 如果回滚整个事务，则：   * 事务会结束   * 所有的修改会被丢弃   * 清除所有保存点   * 释放事务持有的所有锁 * 如果回滚到某个保存点，则：   * 事务不会结束   * 保存点之前的修改被保留，保存点之后的修改被丢弃   * 清除保存点之后的保存点（不包括保存点自身）   * 释放保存点之后事务持有的所有锁 示例：回滚事务的全部修改。 sql obclient> SELECT * FROM t_insert;  NAME  GMT_CREATE |  CN    29-SEP-22  |  US    29-SEP-22  |  EN    29-SEP-22  |  JP    29-SEP-22  | 4 rows in set obclient> INSERT INTO t_insert(id, name, value) VALUES(5,'FR',10005),(6,'RU',10006); Query OK, 3 rows affected Records: 3  Duplicates: 0  Warnings: 0 obclient> SELECT * FROM t_insert;  NAME  GMT_CREATE |  CN    22-AUG-22  |  US    22-AUG-22  |  EN    22-AUG-22  |  JP    22-AUG-22  |  FR    22-AUG-22  |  RU    22-AUG-22  | 6 rows in set obclient> ROLLBACK; Query OK, 0 rows affected obclient> SELECT * FROM t_insert;  NAME  GMT_CREATE |  CN    29-SEP-22  |  US    29-SEP-22  |  EN    29-SEP-22  |  JP    29-SEP-22  | 3 rows in set 更多事务控制语句相关的说明，请参见 事务管理概述。",
        "product": "oceanbase",
        "version": "4.1.0"
    },
    {
        "path": "/Users/zhangying/Desktop/oceanbase-doc-4.1.0/zh-CN/200.quickstart/300.create-sample-application-of-mysql-mode/100.python-application-of-mysql-model.md",
        "content": "创建 Python 示例应用程序 本文介绍如何通过 Python 驱动连接和使用 OceanBase 数据库。不同版本的 Python 环境需要使用不同的驱动，Python 3.x 系列需要使用 PyMySQL 驱动，Python 2.x 系列需要使用 MySQL-python 驱动。 前提条件 确保本地已部署 Python 语言运行环境。 Python 3.x 创建应用程序 Python 3.x 创建应用程序时，需要 PyMySQL 驱动进行数据库连接及使用。 步骤一：获取数据库连接串 联系 OceanBase 数据库部署人员或者管理员获取相应的数据库连接串，例如： sql obclient  -h100.88.xx.xx -uroot@test -p****** -P2881 -Doceanbase 数据库连接串包含了访问数据库所需的参数信息，在创建应用程序前，可通过数据库连接串验证登录数据库，保证连接串参数信息正确。 参数说明： * -h：OceanBase 数据库连接 IP，有时候是一个 ODP 地址。 * -u：租户的连接用户名，格式为 用户@租户#集群名称，集群的默认租户是 'sys'，租户的默认管理员用户是 'root'。直连数据库时不填写集群名称，通过 ODP 连接时需要填写。 * -p：用户密码。 * -P：OceanBase 数据库连接端口，也是 ODP 的监听端口。 * -D：需要访问的数据库名称。 步骤二：安装 PyMySQL 驱动 PyMySQL 是在 Python3.x 版本中用于连接 MySQL 服务器的一个库。PyMySQL 遵循 Python 数据库 API v2.0 规范，并包含了 pure-Python MySQL 客户端库。 有关 PyMySQL 的详细信息，请参考 PyMySQL 官网 和 相关 API 参考文档。 PyMySQL 有以下两种安装方式： * 使用命令行安装    bash    python3 -m pip install PyMySQL * 源码编译安装     bash     git clone https://github.com/PyMySQL/PyMySQL     cd PyMySQL/     python3 setup.py install 步骤三：编写应用程序 编辑运行示例 test.py，代码如下： ```python !/usr/bin/python3 import pymysql conn = pymysql.connect(host=\"localhost\", port=2881,                        user=\"root\", passwd=\"\", db=\"test\") cur = conn.cursor() try:     #创建表 cities     sql = 'create table cities (id int, name varchar(24))'     cur.execute(sql)     #往 cities 表中插入两组数据     sql = \"insert into cities values(1,'hangzhou'),(2,'shanghai')\"     cur.execute(sql)     #查询 cities 表中的所有数据     sql = 'select * from cities'     cur.execute(sql)     ans = cur.fetchall()     print(ans)     #删除表 cities     sql = 'drop table cities'     cur.execute(sql) finally:     cur.close()     conn.close() `` 修改代码中的数据库连接参数。参考如下字段，对应的值，则取自步骤一获取的数据库连接串。 * **user**：取自-u参数，租户的连接用户名，格式为 **用户@租户#集群名称**，集群的默认租户是 'sys'，租户的默认管理员用户是 'root'。直连数据库时不填写集群名称，通过 ODP 连接时需要填写。 * **password**：取自-p参数，用户密码。 * **host**：取自-h参数，OceanBase 数据库连接地址，有时候是 ODP 地址。 * **port**：取自-P参数，OceanBase 数据库连接端口，也是 ODP 的监听端口。 * **db**：取自-D` 参数，需要访问的数据库名称。 步骤四：运行应用程序 代码编辑完成后，运行 test.py。 ```bash python3 test.py 返回以下结果，说明数据库连接成功，示例语句正确执行 ((1, 'hangzhou'), (2, 'shanghai')) ``` Python 2.x 创建应用程序 Python 2.x 创建应用程序时，需要 MySQL-python 驱动进行数据库连接及使用。MySQL-python 是 Python2.X 版本中用于连接数据库的一个库。 步骤一：获取数据库连接串 联系 OceanBase 数据库部署人员或者管理员获取相应的数据库连接串，例如： sql obclient  -h100.88.xx.xx -uroot@test -p****** -P2881 -Doceanbase 数据库连接串包含了访问数据库所需的参数信息，在创建应用程序前，可通过数据库连接串验证登录数据库，保证连接串参数信息正确。 参数说明： * -h：OceanBase 数据库连接 IP，有时候是一个 ODP 地址。 * -u：租户的连接用户名，格式为 用户@租户#集群名称，集群的默认租户是 'sys'，租户的默认管理员用户是 'root'。直连数据库时不填写集群名称，通过 ODP 连接时需要填写。 * -p：用户密码。 * -P：OceanBase 数据库连接端口，也是 ODP 的监听端口。 * -D：需要访问的数据库名称。 步骤二：安装 MySQL-python 驱动 MySQL-python 是 Python 连接 MySQL 数据库的接口，它实现了 Python 数据库 API 规范 V2.0，基于 MySQL C API 建立。 有关 MySQL-python 的详细信息，您可参考 MySQL-python 官网 和 Github 文档. MySQL-python 驱动可以通过 yum 安装，命令如下： bash yum install MySQL-python 步骤三：编写应用程序 编辑运行示例 test2.py，代码如下： ```python !/usr/bin/python2 import MySQLdb conn= MySQLdb.connect(     host='127.0.0.1',     port = 2881,     user='root',     passwd='',     db ='test' ) cur = conn.cursor() try:     #创建表 cities     sql = 'create table cities (id int, name varchar(24))'     cur.execute(sql)     #往 cities 表中插入两组数据     sql = \"insert into cities values(1,'hangzhou'),(2,'shanghai')\"     cur.execute(sql)     #查询 cities 表中的所有数据     sql = 'select * from cities'     cur.execute(sql)     ans = cur.fetchall()     print(ans)     #删除表 cities     sql = 'drop table cities'     cur.execute(sql) finally:     cur.close()     conn.close() `` 修改代码中的数据库连接参数。参考如下字段，对应的值，则取自步骤一获取的数据库连接串。 * **host**：取自-h参数，OceanBase 数据库连接地址，有时候是 ODP 地址。 * **user**：取自-u参数，租户的连接用户名，格式为 **用户@租户#集群名称**，集群的默认租户是 'sys'，租户的默认管理员用户是 'root'。直连数据库时不填写集群名称，通过 ODP 连接时需要填写。 * **passwd**：取自-p参数，用户密码 。 * **port**：取自-P参数，OceanBase 数据库连接端口，也是 ODP 的监听端口。 * **db**：取自-D` 参数，需要访问的数据库名称。 步骤四：运行应用程序 代码编辑完成后，运行 test.py。 ```bash python test.py 返回以下结果，说明数据库连接成功，示例语句正确执行 ((1L, 'hangzhou'), (2L, 'shanghai')) ```",
        "product": "oceanbase",
        "version": "4.1.0"
    },
    {
        "path": "/Users/zhangying/Desktop/oceanbase-doc-4.1.0/zh-CN/200.quickstart/300.create-sample-application-of-mysql-mode/300.c-application-of-mysql-model.md",
        "content": "创建 C 示例应用程序 本文介绍了如何通过 MySQL Connector/C (libmysqlclient) 驱动连接并使用 OceanBase 数据库。 前提条件 在安装使用 MySQL Connector/C (libmysqlclient) 前请确保设置了基本的数据库开发环境，要求如下： * GCC 版本为 3.4.6 及以上，推荐使用 4.8.5 版本。 * CMake 版本为 2.8.12 及以上。 创建 C 应用程序 步骤一：获取数据库连接串 联系 OceanBase 数据库部署人员或者管理员获取相应的数据库连接串，例如： sql obclient -h100.88.xx.xx -uroot@test -p****** -P2881 -Doceanbase 数据库连接串包含了访问数据库所需的参数信息，在创建应用程序前，可通过数据库连接串验证登录数据库，保证连接串参数信息正确。 参数说明： * -h：OceanBase 数据库连接 IP，有时候是一个 ODP 地址。 * -u：租户的连接用户名，格式为 用户@租户#集群名称，集群的默认租户是 sys，租户的默认管理员用户是 root。直接连接数据库时不填集群名称，通过 ODP 连接时需要填写。 * -p：用户密码。 * -P：OceanBase 数据库连接端口，也是 ODP 的监听端口。 * -D：需要访问的数据库名称。 步骤二：安装 MySQL Connector/C 驱动 通过 yum 安装 mariadb client  安装 mariadb client。    shell    sudo yum install mariadb-devel  步骤三：编写应用程序 应用程序通过 MySQL Connector/C 与数据库服务器 OBServer 节点交互的基本方式如下： 1. 调用 mysql_library_init() 初始化 MySQL 库。    c    mysql_library_init(0, NULL, NULL); 2. 调用 mysql_init() 初始化一个连接句柄。    c    MYSQL *mysql = mysql_init(NULL); 3. 调用 mysql_real_connect() 连接到 OBServer 节点。    c    mysql_real_connect (mysql, host_name, user_name, password,    db_name, port_num, socket_name, CLIENT_MULTI_STATEMENTS) 4. 调用 mysql_real_query() 或 mysql_query() 向 OBServer 节点发送 SQL 语句。    c    mysql_query(mysql,\"sql_statement\"); 5. 调用 mysql_store_result() 或 mysql_use_result() 处理其结果。    c    result=mysql_store_result(mysql); 6. 调用 mysql_free_result() 释放内存。    c    mysql_free_result(result); 7. 调用 mysql_close() 关闭与 OBServer 节点的连接。    c    mysql_close(mysql); 8. 调用 mysql_library_end() 结束 MariaDB client 的使用。    c    mysql_library_end(); 示例代码 以 mysql_test.c 文件为例，代码如下： ```c include \"mysql.h\" include  include  int main(int argc, char argv) {   mysql_library_init(0, NULL, NULL);   MYSQL mysql = mysql_init(NULL);   char host_name = \"xxx.xxx.xxx.xxx\";//set your mysql host   char user_name = \"\"; //set your user_name   char password = \"\"; //set your password   char db_name = \"test\"; //set your databasename   int port_num = 2883; //set your mysql port   char socket_name = NULL;   MYSQL_RES result;   MYSQL_FIELD fields;   MYSQL_ROW row;   int status = 0;   / connect to server with the CLIENT_MULTI_STATEMENTS option /   if (mysql_real_connect (mysql, host_name, user_name, password,     db_name, port_num, socket_name, CLIENT_MULTI_STATEMENTS) == NULL)   {     printf(\"mysql_real_connect() failed\\n\");     mysql_close(mysql);     exit(1);   }   / execute multiple statements /   status = mysql_query(mysql, \"DROP TABLE IF EXISTS test_table;\");   if (status)   {     printf(\"Could not execute statement(s)\");     mysql_close(mysql);     exit(0);   }   status = mysql_query(mysql, \"CREATE TABLE test_table(id INT,name varchar(24));\");   status = mysql_query(mysql, \"INSERT INTO test_table VALUES(10,'hangzhou'),(20,'shanghai');\");   status = mysql_query(mysql, \"UPDATE test_table SET id=20 WHERE id=10;\");   status = mysql_query(mysql, \"SELECT * FROM test_table;\");   / did current statement return data? /   result = mysql_store_result(mysql);   if (result)   {     / yes; process rows and free the result set /     //process_result_set(mysql, result);     int num_fields = mysql_num_fields(result);     int num_rows = mysql_num_rows(result);     printf(\"result: %d rows %d fields\\n\", num_rows, num_fields);     printf(\"---------------------\\n\");     fields = mysql_fetch_fields(result);     for (int i = 0; i < num_fields; ++i)     {       printf(\"%s\\t\", fields[i].name);     }     printf(\"\\n---------------------\\n\");     while ((row = mysql_fetch_row(result)))     {       for (int i = 0; i < num_fields; ++i)       {         printf(\"%s\\t\", row[i] ? row[i] : \"NULL\");       }       printf(\"\\n\");     }     printf(\"---------------------\\n\");     mysql_free_result(result);   }   else          / no result set or error /   {     if (mysql_field_count(mysql) == 0)      {        printf(\"%lld rows affected\\n\",             mysql_affected_rows(mysql));      }      else  / some error occurred /      {        printf(\"Could not retrieve result set\\n\");      }   }   status = mysql_query(mysql, \"DROP TABLE test_",
        "product": "oceanbase",
        "version": "4.1.0"
    },
    {
        "path": "/Users/zhangying/Desktop/oceanbase-doc-4.1.0/zh-CN/200.quickstart/300.create-sample-application-of-mysql-mode/300.c-application-of-mysql-model.md",
        "content": "table;\");   mysql_close(mysql);   return 0; } `` 修改代码中的数据库连接参数。参考如下字段，对应的值，则取自步骤一获取的数据库连接串。 * **host_name**：取自-h参数，OceanBase 数据库连接地址，有时候是 ODP 地址。 * **user_name**：取自-u参数，租户的连接用户名，格式为 **用户@租户#集群名称**，集群的默认租户是 'sys'，租户的默认管理员用户是root。直连数据库时不填写集群名称，通过 ODP 连接时需要填写。 * **password**：取自-p参数，用户密码。 * **db_name**：取自-D参数，需要访问的数据库名称。 * **port_num**：取自-P` 参数，OceanBase 数据库连接端口，也是 ODP 的监听端口。 步骤四：运行应用程序  代码编辑完成后，可以通过如下命令进行编译。     shell     g++ -I/usr/include/mysql/ -L/usr/lib64/mysql/ -lmysqlclient mysql_test.c -o mysql_test     选项说明： -I 选项：指定编译器的搜索路径，以便让编译器能够找到头文件。例如将 mysql.h 头文件所在的目录 /usr/include/mysql 添加到编译器的搜索路径中，使编译器能够找到 mysql.h 头文件。可以使用 find / -name mysql.h 2>/dev/null 这个命令查找 mysql.h 文件路径。 -L 选项：指定动态链接库的搜索路径。 -l 选项：指定需要链接的库文件。使用 -l 选项时，库文件名应该去掉 lib 前缀和 .so 后缀，例如上面的命令中库文件名为 libmysqlclient.so，但是使用 -l 选项时只需要指定 mysqlclient。   指定运行路径。     shell     export LD_LIBRARY_PATH=/usr/lib64/mysql 通过如下命令运行应用程序。     shell     ./mysql_test     输出结果如下，输出如下结果，说明数据库连接成功，示例语句正确执行。     shell     ---------------------     id      name     ---------------------     20      hangzhou     20      shanghai     --------------------- ",
        "product": "oceanbase",
        "version": "4.1.0"
    },
    {
        "path": "/Users/zhangying/Desktop/oceanbase-doc-4.1.0/zh-CN/200.quickstart/300.create-sample-application-of-mysql-mode/400.golang-application-of-mysql-model.md",
        "content": "创建 Go 示例应用程序 本文介绍 Go 应用程序示例如何通过驱动 Go-SQL-Driver/MySQL 连接并使用 OceanBase 数据库。 前提条件 确保本地已部署 Go 语言环境。 创建 Go 应用程序 步骤一：获取数据库连接串 联系 OceanBase 数据库部署人员或者管理员获取相应的数据库连接串，例如： sql obclient  -h100.88.xx.xx -uroot@test -p****** -P2881 -Doceanbase 数据库连接串包含了访问数据库所需的参数信息，在创建应用程序前，可通过数据库连接串验证登录数据库，保证连接串参数信息正确。 参数说明： * -h：OceanBase 数据库连接 IP，有时候是一个 ODP 地址。 * -u：租户的连接用户名，格式为 用户@租户#集群名称，集群的默认租户是 'sys'，租户的默认管理员用户是 'root'。直接连接数据库时不填集群名称，通过 ODP 连接时需要填写。 * -p：用户密码。 * -P：OceanBase 数据库连接端口，也是 ODP 的监听端口。 * -D：需要访问的数据库名称。 步骤二：安装 Go-SQL-Driver/MySQL 根据 Go 语言的不同版本，可以选择不同的安装方式。 通过 go get 安装（适用于Go V1.13 - V1.16） 安装命令如下： bash go get -u github.com/go-sql-driver/mysql 关于 Go-SQL-Driver/MySQL 的详细信息，您可参考 Github。 通过 go install 安装 如果由于版本或网络的原因，无法通过 go get 命令安装时，可通过如下方法进行 go-sql-driver/mysql 安装。 1. 在 go/src 目录克隆 github 中的 go-sql-driver/mysql 仓库。     bash     cd /usr/local/go/src        git clone https://github.com/go-sql-driver/mysql.git   注意 /usr/local/go/src 需要替换成 Go 实际安装目录操作。   通过 go install 进行安装。     bash     go install mysql   注意 部分版本 go install 的默认执行目录可能不是 /src，可以通过 go install 执行后的报错判断实际目录。例如，报错 cannot find package \"mysql\" in: /usr/local/go/src/vendor/mysql，则应该将 mysql 文件夹放在 /src/vendor 目录下再执行安装命令。   步骤三：编写应用程序 将下文编写示例文件 test.go，代码如下： go package main import (     \"database/sql\"     \"fmt\"     \"log\"     _ \"mysql\"      //填写 go-sql-driver/mysql 安装的准确路径。如果安装在 src 目录下，可以直接填 \"mysql\"。 ) type Str struct {     Name       string } func main() {     select_all()     } func select_all() {     conn := \"root:@tcp(127.0.0.1:2881)/test\"     db, err := sql.Open(\"mysql\", conn)     if err != nil {         log.Fatal(err)     }     defer db.Close()     if err != nil {         log.Fatal(err)     }     fmt.Printf(\"success to connect OceanBase with go_mysql driver\\n\")     //创建表 t1     db.Query(\"create table t1(str varchar(256))\")      //插入数据     db.Query(\"insert into  t1 values ('Hello OceanBase')\")      //查询数据     res, err := db.Query(\"SELECT * FROM t1\")     //删除表 t1     db.Query(\"drop table t1\")      if err != nil {         log.Fatal(err)     }     defer res.Close()     if err != nil {         log.Fatal(err)     }     for res.Next() {         var str Str         res.Scan(&str.Name)         fmt.Printf(\"%s\\n\", str.Name)     } } 修改代码中的数据库连接参数。参考如下字段及拼接方法，对应的值，则取自步骤一获取的数据库连接串。 go //格式 conn := \"{username}:{password}@tcp({hostname}:{port})/{dbname}\" //示例 conn := \"root:@tcp(127.0.0.1:2881)/test\" 参数说明： * username：取自 -u 参数，租户的连接用户名，格式为 用户@租户#集群名称，集群的默认租户是 'sys'，租户的默认管理员用户是 'root'。直连数据库时不填写集群名称，通过 ODP 连接时需要填写。 * password：取自 -p 参数，用户密码。 * hostname：取自 -h 参数，OceanBase 数据库连接地址，有时候是 ODP 地址。 * port：取自 -P 参数，OceanBase 数据库连接端口，也是 ODP 的监听端口。 * dbname：取自 -D 参数，需要访问的数据库名称。 步骤四：执行应用程序 代码编辑完成后，可以通过如下命令运行： bash //配置临时环境变量，根据 Go 语言实际安装路径填写 export PATH=$PATH:/usr/local/go/bin //通过 go run 直接运行 go 文件 go run test.go //或者通过 go build 生成二进制文件后运行 go build test.go ./test 运行后返回如下内容，说明数据库连接成功，示例语句正确执行： bash success to connect OceanBase with go_mysql driver Hello OceanBase",
        "product": "oceanbase",
        "version": "4.1.0"
    },
    {
        "path": "/Users/zhangying/Desktop/oceanbase-doc-4.1.0/zh-CN/200.quickstart/300.create-sample-application-of-mysql-mode/200.java-application-of-mysql-model.md",
        "content": "创建 Java 示例应用程序 OceanBase 数据库支持通过 MySQL 官方 JDBC 驱动连接。本文介绍了如何通过 MySQL Connector/J 连接并使用 OceanBase 数据库。 前提条件  确保计算机上的 Java 环境为 Java JDK 8 及以上版本。 安装 MySQL Connector/J，并配置运行环境。     推荐使用 MySQL Connector/J 5.1.47 版本。详细的下载及安装方法，请参考 Connector/J 下载、Connector/J 安装。  创建 Java 应用程序 步骤一：获取数据库连接串 联系 OceanBase 数据库部署人员或者管理员获取相应的数据库连接串，例如： sql obclient  -h100.88.xx.xx -uroot@test -p****** -P2881 -Doceanbase 数据库连接串包含了访问数据库所需的参数信息，在创建应用程序前，可通过数据库连接串验证登录数据库，保证连接串参数信息正确。 参数说明： * -h：OceanBase 数据库连接 IP，有时候是一个 ODP 地址。 * -u：租户的连接用户名，格式为 用户@租户#集群名称，集群的默认租户是 'sys'，租户的默认管理员用户是 'root'。直接连接数据库时不填集群名称，通过 ODP 连接时需要填写。 * -p：用户密码。 * -P：OceanBase 数据库连接端口，也是 ODP 的监听端口。 * -D：需要访问的数据库名称。 步骤二：编写应用程序 下文以 Linux 中通过 Java 驱动 Connector/J 5.1.47 连接数据库为例。 在正确安装 MySQL Connector/J 5.1.47 驱动并配置环境之后，可以通过以下 Test.java 文件的示例代码进行数据库连接及使用。   注意 如果是 MySQL Connector/J 8.x 版本，Class.forName(\"com.mysql.jdbc.Driver\") 中的 com.mysql.jdbc.Driver 需要替换成 com.mysql.cj.jdbc.Driver。  java import java.sql.Connection; import java.sql.DriverManager; import java.sql.ResultSet; import java.sql.SQLException; import java.sql.Statement; public class Test {    public static void main(String[] args) {        try {             Class.forName(\"com.mysql.jdbc.Driver\").newInstance();             try{                 Connection connection = DriverManager.getConnection(\"jdbc:mysql://127.0.0.1:2881/test?user=r***&password=\");                 System.out.println(connection.getAutoCommit());                 Statement sm = connection.createStatement();                 //新建表 t_meta_form                 sm.executeUpdate(\"CREATE TABLE t_meta_form (name varchar(36) , id int)\");                 //插入数据                 sm.executeUpdate(\"insert into t_meta_form values ('an','1')\");                 //查询数据，并输出结果                 ResultSet rs = sm.executeQuery(\"select * from t_meta_form\");                 while (rs.next()) {                     String name = rs.getString(\"name\");                     String id = rs.getString(\"id\");                     System.out.println(name + ','+ id);                 }                 //删除表                 sm.executeUpdate(\"drop table t_meta_form\");                             }catch(SQLException se){                 System.out.println(\"error!\");                 se.printStackTrace() ;             }             }catch (Exception ex) {                 ex.printStackTrace();         }     } } 修改代码中的数据库连接参数。参考如下字段及拼接方法，对应的值，则取自步骤一获取的数据库连接串。 java connection = DriverManager.getConnection(\"jdbc:mysql://{host}:{port}/{dbname}?user={username}&password={******}\") //示例 jdbc:mysql://100.88.xx.xx:2881/test?user=r***&password=******` * host：取自 -h 参数，OceanBase 数据库连接地址，有时候是 ODP 地址。 * port：取自 -P 参数，OceanBase 数据库连接端口，也是 ODP 的监听端口。 * dbname：取自 -D 参数，需要访问的数据库名称。 * username：取自 -u 参数，租户的连接用户名，格式为 用户@租户#集群名称，集群的默认租户是 'sys'，租户的默认管理员用户是 'root'。直连数据库时不填写集群名称，通过 ODP 连接时需要填写。 * password：取自 -p 参数，用户密码 。 步骤三：运行应用程序 代码编辑完成后，可以通过如下命令进行编译： ```bash 配置临时环境配置，根据 mysql-connector-java-5.1.47.jar 实际安装路径填写 export CLASSPATH=/usr/share/java/mysql-connector-java-5.1.47.jar:$CLASSPATH 编译 javac Test.java 编译完成后，通过如下命令运行 `Test`：bash java Test 输出以下结果说明数据库连接成功，示例语句正确执行 true an,1 ```",
        "product": "oceanbase",
        "version": "4.1.0"
    },
    {
        "path": "/Users/zhangying/Desktop/oceanbase-doc-4.1.0/zh-CN/200.quickstart/300.create-sample-application-of-oracle-mode/300.c-application-of-oracle-model.md",
        "content": "创建 C 示例应用程序 本文介绍 C 应用程序如何通过 OBCI 连接并使用 OceanBase 数据库。   功能适用性 该内容仅适用于 OceanBase 数据库企业版。OceanBase 数据库社区版仅提供 MySQL 模式。  前提条件  确保设置了基本的数据库开发环境。 确保满足如下硬件环境： 硬件平台：x86_64。 操作系统：CentOS/Redhat 系 Linux 发行版 7.2。 编译器：GCC 4.8。 请联系技术支持人员获取 OBCI 和 LibOBClient 的 RPM 安装包。  步骤一：获取数据库连接串 联系 OceanBase 数据库部署人员或者管理员获取相应的数据库连接串，例如： sql obclient  -h100.88.xx.xx -usys@oracle -p****** -P2881 数据库连接串包含了访问数据库所需的参数信息，在创建应用程序前，可通过数据库连接串验证登录数据库，保证连接串参数信息正确。 参数说明： * -h：OceanBase 数据库连接 IP，有时候是一个 ODP 地址。 * -u：租户的连接用户名，格式为 用户@租户#集群名称，租户的连接用户，Oracle 模式的管理员用户名默认是 sys。直连数据库时不填集群名称，通过 ODP 连接时需要填写。 * -p：用户密码。 * -P：OceanBase 数据库连接端口，也是 ODP 的监听端口。 步骤二：安装 C 相关驱动 当您获取 RPM 包后，在命令行工具中以 root 用户权限执行如下命令进行 OBCI 驱动的安装： shell rpm -ivh obci-<version>.x86_64.rpm rpm -ivh libobclient-<version>.x86_64.rpm 在默认情况下，软件包中包含的程序与文件将安装在如下路径中： * 头文件被安装在 /u01/obclient/include 路径下。 * 库文件被安装在 /u01/obclient/lib 路径下。 步骤三：编写应用程序 本文通过具体实例介绍在 OceanBase 数据库 Oracle 模式下，C 应用程序通过 OBCI 与数据库服务器 OBServer 节点交互的基本方式。 1. 初始化 OBCI 环境和线程。    c    /*初始化 OBCI 程序环境*/    OCIInitialize(OCI_DEFAULT, NULL, NULL, NULL, NULL)    /*初始化环境句柄*/    OCIEnvInit(&envhp, OCI_DEFAULT, 0, 0) 2. 分配必要的句柄与数据结构。    c    /*服务上下文句柄*/    OCIHandleAlloc(envhp, (dvoid **)&svchp, OCI_HTYPE_SVCCTX, 0, 0)    /*服务器句柄*/    OCIHandleAlloc(envhp, (dvoid **)&srvhp, OCI_HTYPE_SERVER, 0, 0)    /*会话句柄*/    OCIHandleAlloc(envhp, (dvoid **)&authp, OCI_HTYPE_SESSION, 0, 0)    /*错误句柄*/    OCIHandleAlloc(envhp, (dvoid **)&errhp, OCI_HTYPE_ERROR, 0, 0)    /*描述句柄*/    OCIHandleAlloc(envhp, (dvoid **)&dschp, OCI_HTYPE_DESCRIBE, 0, 0) 3. 建立与数据库的连接以及创建用户会话。    c    /*设置用户名和密码*/     OCIAttrSet(authp, OCI_HTYPE_SESSION, (text *)strUserName,    (ub4)strlen(strUserName), OCI_ATTR_USERNAME, errhp)     OCIAttrSet(authp, OCI_HTYPE_SESSION, (text *)strPassword,    (ub4)strlen(strPassword), OCI_ATTR_PASSWORD, errhp)    /*设置服务器环境句柄属性*/      OCIAttrSet((dvoid *)svchp, (ub4)OCI_HTYPE_SVCCTX,(dvoid *)srvhp, (ub4)0, OCI_ATTR_SERVER, errhp)      OCIAttrSet(svchp, OCI_HTYPE_SVCCTX, (dvoid *)authp,0, OCI_ATTR_SESSION, errhp)    /*创建并开始一个用户会话*/      OCISessionBegin(svchp, errhp, authp, OCI_CRED_RDBMS, OCI_DEFAULT)      OCIHandleAlloc(envhp, (dvoid **)&stmthp, OCI_HTYPE_STMT, 0, 0) 4. 通过 SQL 与 OceanBase 服务器交换数据，而后再做数据处理。一条 SQL 语句在 OBCI 应用程序中的执行步骤如下：    1. 通过调用函数 OCIStmtPrepare() 或者 OCIStmtPrepare2() 准备 SQL 语句。       c       OCIStmtPrepare(stmthp, errhp, (text *)sql, strlen(sql), OCI_NTV_SYNTAX,OCI_DEFAULT)    2. 通过调用一个或者多个函数，如 OCIBindByPos() 或 OCIBindByName() 等把输入变量的地址绑定在 DML 语句中的占位符中。       c       OCIBindByPos(stmthp, &bidhp[0], errhp, 1, &szpersonid,                        sizeof(szpersonid), SQLT_INT, NULL, NULL, NULL, 0, NULL, 0)       OCIBindByName(stmthp, &bidhp[0], errhp, (const OraText*)\":personid\", 9, &szpersonid,                         sizeof(szpersonid), SQLT_INT, NULL, NULL, NULL, 0, NULL, 0)    3. 调用 OCIStmrExecute() 函数执行 SQL 语句。       c       OCIStmtExecute(svchp, stmthp, errhp, (ub4)1, (ub4)0, (CONST OCISnapshot *)0,        (OCISnapshot *)0, (ub4)OCI_DEFAULT)    4. 调用 OCIDefineByPos() 函数为 SQL 语句中的数据输出项定义输出变量。       c       OCIDefineByPos(stmthp, &defhp[0], errhp, 1, &szpersonid,       sizeof(szpersonid), SQLT_INT, &ind[0], 0, 0, OCI_DEFAULT)    5. 调用 OCIStmtFetch() 函数来获取查询的结果集。       c       OCIStmtFetch(stmthp, errhp, 1, OCI_FETCH_NEXT, OCI_DEFAULT) 5. 结束用户会话与断开与数据库的连接。    c    /*结束会话*/      OCISessionEnd(svchp, errhp, authp, (ub4)0)    /*断开与数据库的连接*/      OCIServerDetach(srvhp, errhp, OCI_DEFAULT) 6. 释放在程序中所分配的句柄。    c    OCIHandleFree((dvoid *)dschp, OCI_HTYPE_DESCRIBE)    OCIHandleFree((dvoid *)stmthp, OCI_HTYPE_STMT)    OCIHandleFree((dvoid *)errhp, OCI_HTYPE_ERROR)    OCIHandleFree((dvoid *)authp, OCI_HTYPE_SESSION)    OCIHandleFree((dvoid *)svchp, OCI_HTYPE_SVCCTX)    OCIHandleFree((dvoid *)srvhp, OCI_HTYPE_SERVER) 示例代码 示例文件 test.c 代码内容如下： ```c /******** * Copyright(C) 2014 - 2020 Alibaba Inc. All Rights Reserved. * *  Filename: ob_oci_test.c *  Description: ---- *  Create: 2020-07-07 10:14:59 *  Last Modified: 2020-07-07 10:14:59 *********/ include  inc",
        "product": "oceanbase",
        "version": "4.1.0"
    },
    {
        "path": "/Users/zhangying/Desktop/oceanbase-doc-4.1.0/zh-CN/200.quickstart/300.create-sample-application-of-oracle-mode/300.c-application-of-oracle-model.md",
        "content": "lude  include  include  include \"oci.h\" /声明句柄/ OCIEnv envhp;       /环境句柄/ OCISvcCtx svchp;    /服务环境句柄/ OCIServer srvhp;    /服务器句柄/ OCISession authp;   /会话句柄/ OCIStmt stmthp;     /语句句柄/ OCIDescribe dschp;  /描述句柄/ OCIError errhp;     /错误句柄/ OCIDefine defhp[3]; /定义句柄/ OCIBind bidhp[4];   /绑定句柄/ sb2 ind[3];          /指示符变量/ /绑定 select 结果集的参数/ int szpersonid; /存储 personid 列/ text szname[51];    /存储 name 列/ text szemail[51];   /存储 mail 列/ char sql[256];      /存储执行的 sql 语句/ int main(int argc, char argv[]) {   char strServerName[50];   char strUserName[50];   char strPassword[50];   /设置服务器，用户名和密码/   strcpy(strServerName, \"172.30.xx.xx:2881\");   strcpy(strUserName, \"s@oracle\");   strcpy(strPassword, \"*\");   /初始化 OCI 应用环境/   OCIInitialize(OCI_DEFAULT, NULL, NULL, NULL, NULL);   /初始化环境句柄/   OCIEnvInit(&envhp, OCI_DEFAULT, 0, 0);   /分配句柄*/   OCIHandleAlloc(envhp, (dvoid )&svchp, OCI_HTYPE_SVCCTX, 0, 0);   /服务器环境句柄/   OCIHandleAlloc(envhp, (dvoid )&srvhp, OCI_HTYPE_SERVER, 0, 0);   /服务器句柄/   OCIHandleAlloc(envhp, (dvoid )&authp, OCI_HTYPE_SESSION, 0, 0);   /会话句柄/   OCIHandleAlloc(envhp, (dvoid )&errhp, OCI_HTYPE_ERROR, 0, 0);   /错误句柄/   OCIHandleAlloc(envhp, (dvoid )&dschp, OCI_HTYPE_DESCRIBE, 0, 0);   /描述符句柄/   /连接服务器/   OCIServerAttach(srvhp, errhp, (text )strServerName, (sb4)strlen(strServerName), OCI_DEFAULT);   /设置用户名和密码/   OCIAttrSet(authp, OCI_HTYPE_SESSION, (text )strUserName, (ub4)strlen(strUserName), OCI_ATTR_USERNAME, errhp);   OCIAttrSet(authp, OCI_HTYPE_SESSION, (text )strPassword, (ub4)strlen(strPassword), OCI_ATTR_PASSWORD, errhp);   /设置服务器环境句柄属性/   OCIAttrSet((dvoid )svchp, (ub4)OCI_HTYPE_SVCCTX, (dvoid )srvhp, (ub4)0, OCI_ATTR_SERVER, errhp);   OCIAttrSet(svchp, OCI_HTYPE_SVCCTX, (dvoid )authp, 0, OCI_ATTR_SESSION, errhp);   /创建并开始一个用户会话/   OCISessionBegin(svchp, errhp, authp, OCI_CRED_RDBMS, OCI_DEFAULT);   OCIHandleAlloc(envhp, (dvoid )&stmthp, OCI_HTYPE_STMT, 0, 0);   /语句句柄*/   /**********/   /创建 person 表*/   /**********/   static text SQL_CREATE_TB = (text)\"create table person(personid number, name varchar(256), email  varchar(256))\";   /准备 SQL 语句/   OCIStmtPrepare(stmthp, errhp, SQL_CREATE_TB, strlen((char )SQL_CREATE_TB),OCI_NTV_SYNTAX, OCI_DEFAULT);   /执行 SQL 语句/   OCIStmtExecute(svchp, stmthp, errhp, 1, 0, 0, 0, OCI_DEFAULT);   /提交到数据库/   OCITransCommit(svchp, errhp, OCI_DEFAULT);   /**********/   /插入数据/   /**********/   memset(sql, 0, sizeof(sql));   strcpy(sql, \"insert into person values(:personid,:name,:email)\");   /准备 SQL 语句/   OCIStmtPrepare(stmthp, errhp, (text )sql, strlen(sql),OCI_NTV_SYNTAX, OCI_DEFAULT);   /绑定输入列/   OCIBindByName(stmthp, &bidhp[0], errhp, (const OraText)\":personid\", 9, &szpersonid, sizeof(szpersonid), SQLT_INT, NULL, NULL, NULL, 0, NULL, 0);   OCIBindByName(stmthp, &bidhp[2], errhp, (const OraText)\":name\", 5, szname, sizeof(szname), SQLT_STR, NULL, NULL, NULL, 0, NULL, 0);   OCIBindByName(stmthp, &bidhp[3], errhp, (const OraText)\":email\", 6, szemail, sizeof(szemail), SQLT_STR, NULL, NULL, NULL, 0, NULL, 0);   /设置输入参数/   szpersonid = 1;   memset(szname, 0, sizeof(szname));   strcpy((char)szname, \"obtest\");   memset(szemail, 0, sizeof(szemail));   strcpy((char)szemail, \"t@ob.com\");   /执行 SQL 语句/   OCIStmtExecute(svchp, stmthp, errhp, (ub4)1, (ub4)0, (CONST OCISnapshot )0, (OCISnapshot )0, (ub4)OCI_DEFAULT);   /提交到数据库/   OCITransCommit(svchp, errhp, OCI_DEFAULT);   /**********/   /查询 person 表/   /**********/   strcpy(sql, \"select personid ,name,email from person;\");   /准备 SQL 语句/   OCIStmtPrepare(stmthp, errhp, (text )sql, strlen(sql), OCI_NTV_SYNTAX, OCI_DEFAULT);   /绑定输出列/   OCIDefineByPos(stmthp, &defhp[0], errhp, 1, &szpersonid, sizeof(szpersonid), SQLT_STR, &ind[0], 0, 0, OCI_DEFAULT);   OCIDefineByPos(stmthp, &defhp[1], errhp, 2, (ub1 )szname, sizeof(szname), SQLT_STR, &ind[1], 0, 0, OCI_DEFAULT);   OCIDefineByPos(stmthp, &defhp[2], errhp, 3, (ub1 )szemail, sizeof(szemail), SQLT_STR, &ind[2], 0, 0, OCI_DEFAULT);   /执行 SQL 语句/   OCIStmtExecute(svchp, stmthp, errhp, (ub4)0, 0, NULL, NULL",
        "product": "oceanbase",
        "version": "4.1.0"
    },
    {
        "path": "/Users/zhangying/Desktop/oceanbase-doc-4.1.0/zh-CN/200.quickstart/300.create-sample-application-of-oracle-mode/300.c-application-of-oracle-model.md",
        "content": ",                  OCI_DEFAULT);   printf(\"%-10s%-10s%-10s\\n\", \"PERSONID\", \"NAME\", \"email\");   while ((OCIStmtFetch(stmthp, errhp, 1, OCI_FETCH_NEXT, OCI_DEFAULT)) != OCI_NO_DATA)   {     printf(\"%-10d\", szpersonid);     printf(\"%-10s\", szname);     printf(\"%-10s\\n\", szemail);     break;   }   /提交到数据库/   OCITransCommit(svchp, errhp, OCI_DEFAULT);   /**********/   /删除 person 表*/   /**********/   static text SQL_DROP_TB   = (text)\"drop table person\";   /准备 SQL 语句/   OCIStmtPrepare(stmthp, errhp, (text)SQL_DROP_TB, strlen((char )SQL_DROP_TB), OCI_NTV_SYNTAX, OCI_DEFAULT);   /执行 SQL 语句/   OCIStmtExecute(svchp, stmthp, errhp, 1, 0, 0, 0, OCI_COMMIT_ON_SUCCESS);   /提交到数据库/   OCITransCommit(svchp, errhp, OCI_DEFAULT);   //结束会话   OCISessionEnd(svchp, errhp, authp, (ub4)0);   //断开与数据库的连接   OCIServerDetach(srvhp, errhp, OCI_DEFAULT);   //释放OCI句柄   OCIHandleFree((dvoid )dschp, OCI_HTYPE_DESCRIBE);   OCIHandleFree((dvoid )stmthp, OCI_HTYPE_STMT);   OCIHandleFree((dvoid )errhp, OCI_HTYPE_ERROR);   OCIHandleFree((dvoid )authp, OCI_HTYPE_SESSION);   OCIHandleFree((dvoid )svchp, OCI_HTYPE_SVCCTX);   OCIHandleFree((dvoid *)srvhp, OCI_HTYPE_SERVER);   return 0; } 修改代码中的数据库连接参数。参考如下字段，对应的值，则取自步骤一获取的数据库连接串。c strcpy(strServerName, \"172.30.xx.xx:2881\"); strcpy(strUserName, \"s@oracle\"); strcpy(strPassword, \"**\"); `` * **strServerName**：取自-h和-P参数，IP:port。OceanBase 数据库连接 IP，通常是一个 ODP 地址，以及访问所用的端口号。 * **strUserName**： 取自-u参数，租户的连接用户名，格式为 **用户@租户#集群名称**，oracle 模式的管理员用户名默认是sys。直连数据库时不填集群名称，通过 ODP 连接时需要填写。 * **strPassword**：取自-p` 参数，用户密码。 步骤四：执行应用程序 代码编辑完成后，可以通过如下命令进行编译： c //编译 gcc test.c -I/u01/obclient/include /u01/obclient/lib/libobci.a -L/usr/local/lib64 -lstdc++ -lpthread -ldl -lm -g -o test 编译完成后，运行得到如下结果，说明数据库连接成功且语句执行正常： bash ./test PERSONID  NAME      email 1         obtest    t@ob.com 更多信息 关于 OBCI 的详细安装和使用信息，请参考官网文档 《OceanBase C 语言调用接口》。",
        "product": "oceanbase",
        "version": "4.1.0"
    },
    {
        "path": "/Users/zhangying/Desktop/oceanbase-doc-4.1.0/zh-CN/200.quickstart/300.create-sample-application-of-oracle-mode/200.java-application-of-oracle-model.md",
        "content": "创建 Java 示例应用程序 本文介绍了 Java 应用程序如何使用 OceanBase Connector/J 驱动连接并使用 OceanBase 数据库。   功能适用性 该内容仅适用于 OceanBase 数据库企业版。OceanBase 数据库社区版仅提供 MySQL 模式。  前提条件  确保设置了基本的数据库开发环境。 确保计算机上的 Java 环境为 Java JDK 8 版本。 获取 OceanBase Connector/J 驱动程序安装包。请在 OceanBase 官方网站的 资源 -> 下载中心 -> 企业版 -> 驱动和中间件 下的 OceanBase JDBC 驱动程序 中单击对应的版本，填写信息后自助下载 OceanBase Connector/J 驱动程序安装包。  创建 Java 应用程序 步骤一：获取数据库连接串 联系 OceanBase 数据库部署人员或者管理员获取相应的数据库连接串，例如： sql obclient  -h100.88.xx.xx -usys@oracle -p****** -P2881 数据库连接串包含了访问数据库所需的参数信息，在创建应用程序前，可通过数据库连接串验证登录数据库，保证连接串参数信息正确。 参数说明： * -h：OceanBase 数据库连接 IP，有时候是一个 ODP 地址。 * -u：租户的连接用户名，格式为 用户@租户#集群名称，租户的连接用户，Oracle 模式的管理员用户名默认是 sys。直连数据库时不填集群名称，通过 ODP 连接时需要填写。 * -p：用户密码。 * -P：OceanBase 数据库连接端口，也是 ODP 的监听端口。 步骤二：安装 OceanBase Connector/J 驱动 将 OceanBase Connector/J 的 JAR 包解压后放入本地 /usr/share/java 路径中，并设置临时环境变量。 shell mv ./oceanbase-client-{version}.jar /usr/share/java export CLASSPATH=/usr/share/java/oceanbase-client-{version}.jar:$CLASSPATH  说明  根据下载的实际文件版本进行相应操作。   步骤三：编写应用程序 编写 Java 示例文件 Test.java 。 java import java.sql.Connection; import java.sql.DriverManager; import java.sql.SQLException; import java.sql.ResultSet; import java.sql.Statement; public class Test {     public static void main(String[] args) {         try {             Class.forName(\"com.oceanbase.jdbc.Driver\");             Connection connection = DriverManager.getConnection(\"jdbc:oceanbase://172.30.xx.xx:2881/?pool=false&user=s**@oracle&password=******\");             System.out.println(connection.getAutoCommit());             Statement sm = connection.createStatement();             //新建表 t_meta_form             sm.executeUpdate(\"CREATE TABLE t_meta_form (name varchar(36) , id int)\");             //插入数据             sm.executeUpdate(\"insert into t_meta_form values ('an','1')\");             //查询数据，并输出结果             ResultSet rs = sm.executeQuery(\"select * from t_meta_form\");             while (rs.next()) {                 String name = rs.getString(\"name\");                 String id = rs.getString(\"id\");                 System.out.println(name + ','+ id);             }             //删除表             sm.executeUpdate(\"drop table t_meta_form\");         }catch (SQLException ex) {             System.out.println(\"error!\");             ex.printStackTrace() ;         }catch (ClassNotFoundException e) {             e.printStackTrace();         }     } } 修改代码中的数据库连接参数。参考如下字段，对应的值，则取自步骤一获取的数据库连接串。 * url：取自 -h 和 -P 参数，jdbc:oceanbase://IP:port/?pool=false。OceanBase 数据库连接 IP，通常是一个 ODP 地址，以及访问所用的端口号。 * user：取自 -u 参数，租户的连接用户名，格式为 用户@租户#集群名称，oracle 模式的管理员用户名默认是 sys。直连数据库时不填集群名称，通过 ODP 连接时需要填写。 * password：取自 -p 参数，用户密码。 步骤四：执行应用程序 代码编辑完成后，可以通过如下命令进行编译： bash javac Test.java 编译完成后，执行获得如下结果，说明数据库连接成功，示例语句正确执行： bash java Test true an,1 更多信息 关于 OceanBase Connector/J 的详细使用信息，请参考官方文档 《OceanBase Connector/J》。",
        "product": "oceanbase",
        "version": "4.1.0"
    },
    {
        "path": "/Users/zhangying/Desktop/oceanbase-doc-4.1.0/zh-CN/200.quickstart/500.experience-advanced-features-of-oceanbase/400.experience-multi-tenant-features.md",
        "content": "体验多租户特性 OceanBase 数据库具有多租户的特性，在集群层面实现了实例资源的池化。在 OceanBase 数据库中，每一个租户即一个实例（类比 MySQL Instance）。租户与租户之间数据、权限、资源隔离，每个租户拥有自己独立的访问端口及 CPU、内存访问资源。 背景信息 OceanBase 数据库可以灵活的调整租户资源分配情况（CPU、内存），并且整个过程对上层业务透明。通过多租户机制，OceanBase 集群可以帮助用户高效的利用资源，在保证可用性和性能的前提下，优化成本，并且做到按照需求弹性扩容。 为了帮助您更容易的理解 OceanBase 数据库多租户的概念。下面通过创建一个 OceanBase 数据库租户的例子分步骤进行说明。 创建资源规格 Unit Config 在 OceanBase 数据库中，资源单元 Unit 是一个租户使用 CPU、内存的最小逻辑单元，也是集群扩展和负载均衡的一个基本单位，在集群节点上下线，扩容、缩容时会动态调整资源单元在节点上的分布进而达到资源的使用均衡。而 Unit Config 则规定了一个 Unit 需要使用的计算存储资源（包含内存、CPU 和 IO 等）的规格，是一个配置信息。 因为其分布式的架构，一个 OceanBase 数据库租户可以在资源规格、资源池、副本类型，副本分布几个不同维度灵活定义，所以创建租户时，也需要按照 “unit config -> resource pool -> tenant” 的顺序进行创建和定义。 OceanBase 数据库在创建租户前，需要先确定租户的 Unit Config。您需要使用 sys 租户管理员，通过如下 SQL 语句来创建。 下面创建两个 Unit Config，分别为 unit1 和 unit2 并指定 CPU、内存、使用的最大及最小阈值。 * 创建 unit1 资源单元的 CPU、内存使用大小为 3 C、6 G。     sql     obclient [oceanbase]> CREATE RESOURCE UNIT UNIT1 MAX_CPU =3,MIN_CPU =3 ,MEMORY_SIZE ='6G'; * 创建 unit2 资源单元的 CPU、内存使用大小为 4 C、8 G。     sql     obclient [oceanbase]> CREATE RESOURCE UNIT UNIT2 MAX_CPU =4,MIN_CPU =4 ,MEMORY_SIZE ='8G'; 创建资源池和关联 Unit Config Unit Config 是一组租户的配置规格信息，而 Resource Pool 则是租户的资源实体，所以在这一步我们需要创建一个 Resource Pool，并且与 Unit Config 关联起来。 创建两个不同的资源池 pool1、pool2，并为其分别指定到 unit1、unit2 上。实现资源单元与资源池的对应。UNIT_NUM 表示在一个副本中指定多少个 unit 单元（同一个租户中，一个节点上最多只能有一个 unit），ZONE_LIST 则指定租户在当前集群中在哪几个副本进行部署。 本例中考虑到是单节点集群，我们都指定单个 Unit 和 Zone List。创建 Resource Pool 需要保证有足够的资源剩余，如果资源不足，您可以先尝试删除已有的 test 租户，或者将已有租户的 Unit Config 调整到更小。如何调整请参见 调整租户资源大小。 sql obclient [oceanbase]> CREATE RESOURCE POOL pool1 UNIT='UNIT1',UNIT_NUM=1,ZONE_LIST=('zone1'); obclient [oceanbase]> CREATE RESOURCE POOL pool2 UNIT='UNIT2',UNIT_NUM=1,ZONE_LIST=('zone1');   注意 上面的例子针对的是单节点的集群环境，如果您的集群有 3 个节点，那么 ZONE_LIST 的值应该为 ('zone1','zone2','zone3')，其中 Zone 的名称需要根据您创建的情况具体填写。  根据创建的 Resource Pool 创建租户 在完成 Unit Config、Resource Pool 的创建，完成资源单元和资源池的对应后，就可以正常开始租户创建了。 本例中由于是单节点集群，所以我们只能创建单副本的租户。如果希望创建 3 副本的租户，OceanBase 集群至少需要 3 个节点。 定义一个名为 tenant1 的单副本租户，并规定字符集为 utf8mb4，使用 pool1 的资源池，ob_tcp_invited_nodes 是租户白名单定义，初始可以设置为 '%'，表示任意 IP 地址均可以访问，后期可以修改。 sql obclient [oceanbase]> CREATE TENANT IF NOT EXISTS tenant1 CHARSET='utf8mb4', ZONE_LIST=('zone1'), PRIMARY_ZONE='zone1', RESOURCE_POOL_LIST=('pool1') SET ob_tcp_invited_nodes='%';   注意 上面的例子针对的是单节点的集群环境，只能创建单副本的租户。如果您的集群有 3 个节点，那么 ZONE_LIST 的值应该为('zone1','zone2','zone3')，PRIMARY_ZONE 则填写 'zone1;zone2;zone3'，表示租户的 Leader 优先分布在 zone1，其次为 zone2。  类似的，定义一个名为 tenant2 的一个 单副本的租户，并规定字符集为 utf8mb4，使用 pool2 的资源池。 sql obclient [oceanbase]> CREATE TENANT IF NOT EXISTS tenant2 CHARSET='utf8mb4', ZONE_LIST=('zone1'), PRIMARY_ZONE='zone1', RESOURCE_POOL_LIST=('pool2') SET ob_tcp_invited_nodes='%'; 在完成 tenant1、tenant2 租户创建后，您可以通过查询 oceanbase.DBA_OB_TENANTS 视图来确认租户是否创建成功。 sql obclient [oceanbase]> SELECT * FROM DBA_OB_TENANTS; 上述操作确认完成后，您已完成在同一个集群下实现两个租户的创建过程。接下来便可以在租户里正常的进行数据库操作了。 使用 root 用户登录集群的 tenant1 租户，并创建一张测试表。 sql obclient -hxxx.xxx.xxx.xxx -P2883 -uroot@tenant1#ob_test -p****** obclient [(none)]> SHOW DATABASES; 4 rows in set obclient [(none)]> USE test; Database changed obclient [test]> CREATE TABLE t_f1(id DECIMAL(10,0),id2 DECIMAL(10,0),id3 DATE,id4 DATE,id5 FLOAT,id6 FLOAT,id7 VARCHAR(30),id8 VARCHAR(300)); Query OK, 0 rows affected obclient [test]> SHOW TABLES; 1 row in set 使用 root 用户登录集群的 tenant2 租户，查看 test 库情况。 sql obclient -hxxx.xxx.xxx.xxx -P2883 -uroot@tenant2#ob_test -p****** obclient [(none)]> SHOW DATABASES; 4 rows in set obclient [(none)]> USE test; Database changed obclient [test]> SHOW TABLES; Empty set 可以看到集群下两个租户的资源、数据、权限都是隔离的，您可以进行更多测试，体验 OceanBase 数据库的租户隔离特性。 修改租户配置和调整实例资源规格 OceanBase 数据库可以灵活的对租户资源的 CPU，内存资源进行调整，并且在线生效，对业务透明。修改租户所占用的 CPU、内存大小，您仅需要调整租户所对应的 Unit Config，不需要对资源池或者租户进行调整。 租户资源单元可通过系统视图 oceanbase.DBA_OB_UNIT_CONFIGS 进行查看。 sql obclient [oceanbase]> SELECT * FROM oceanbase.DBA_OB_UNIT_CONFIGS;  NAME             MODIFY_TIME                 MIN_CPU  LOG_DISK_SIZE  MIN_IOPS   sys_unit_config  2022-11-17 18:00:47.297945        1     8053063680     10000   unit1            2022-12-15 11:40:1",
        "product": "oceanbase",
        "version": "4.1.0"
    },
    {
        "path": "/Users/zhangying/Desktop/oceanbase-doc-4.1.0/zh-CN/200.quickstart/500.experience-advanced-features-of-oceanbase/400.experience-multi-tenant-features.md",
        "content": "7.811095        3     2147483648      128    unit2            2022-12-16 16:16:27.053872        4     8589934592      128   6 rows in set (0.003 sec) 查询结果显示，unit1 资源单元 CPU、内存使用的分别是 3 C，6 G。 通过以下命令调整 unit1 资源单元 CPU、内存的使用大小为 5 c，10 G。 sql obclient [oceanbase]>  ALTER resource unit unit1 max_cpu =5,min_cpu =5 ,memory_size ='10G'; Query OK, 0 rows affected obclient [oceanbase]> SELECT * FROM oceanbase.DBA_OB_UNIT_CONFIGS;  NAME             MODIFY_TIME                 MIN_CPU  LOG_DISK_SIZE  MIN_IOPS   sys_unit_config  2022-11-17 18:00:47.297945        1     8053063680     10000   unit1            2023-01-05 16:24:17.287801        5     2147483648      128    unit2            2022-12-16 16:16:27.053872        4     8589934592      128   6 rows in set (0.037 sec) 如上所示，租户配置的调整是在线立即生效的，调整成功后，unit1 的 CPU、内存为 5 c，10 G。OceanBase 数据库通过内核的虚拟化技术，在变更配置后租户的 CPU 和内存资源可以立即生效，无需数据迁移或者切换，对业务无感知。 通过查看 DBA_OB_UNITS 信息，您可以获取到资源单元、资源池、租户在集群里的对应信息及 CPU、内存信息。 sql obclient [oceanbase]> SELECT * FROM DBA_OB_UNITS;",
        "product": "oceanbase",
        "version": "4.1.0"
    },
    {
        "path": "/Users/zhangying/Desktop/oceanbase-doc-4.1.0/zh-CN/200.quickstart/500.experience-advanced-features-of-oceanbase/300.experience-parallelly-importing-and-data-compression.md",
        "content": "体验并行导入和数据压缩 本文介绍了并行导入和数据压缩相关的使用及说明。 并行导入 除了分析查询，Operational OLAP 中还有很重要的一个部分，那就是大量数据的并行导入，也就是数据批处理能力。OceanBase 数据库的并行执行框架能够将 DML 语句也通过并发的方式进行执行（Parallel DML），对于多节点的数据库，实现多机并发写入，并且保证大事务的一致性。结合异步转储机制，还能在很大程度上优化 LSM-Tree 存储引擎在内存紧张的情况下对大事务的支持。 我们通过这样一个例子来体验 PDML：仍然以 TPC-H 的 lineitem 表为基础，创建一张相同表结构的空表 lineitem2。然后以 INSERT INTO ...SELECT 的方式，用一条 SQL 语句将 lineitem 的全部 600 万行数据插入到新表 lineitem2 中。下面我们分别用关闭和开启 PDML 的方式执行，观察其效果和区别。 首先，复制 lineitem 的表结构，创建 lineitem2。注意，在 OceanBase 数据库中我们使用分区表进行数据扩展，此处的例子中我们使用 16 个分区，那么对应的 lineitem2 也应完全相同： shell obclient [test]>  SHOW CREATE TABLE lineitem\\G; *************************** 1. row ***************************        Table: lineitem Create Table: CREATE TABLE `lineitem` (   `l_orderkey` bigint(20) NOT NULL,   `l_partkey` bigint(20) NOT NULL,   `l_suppkey` bigint(20) NOT NULL,   `l_linenumber` bigint(20) NOT NULL,   `l_quantity` bigint(20) NOT NULL,   `l_extendedprice` bigint(20) NOT NULL,   `l_discount` bigint(20) NOT NULL,   `l_tax` bigint(20) NOT NULL,   `l_returnflag` char(1) DEFAULT NULL,   `l_linestatus` char(1) DEFAULT NULL,   `l_shipdate` date NOT NULL,   `l_commitdate` date DEFAULT NULL,   `l_receiptdate` date DEFAULT NULL,   `l_shipinstruct` char(25) DEFAULT NULL,   `l_shipmode` char(10) DEFAULT NULL,   `l_comment` varchar(44) DEFAULT NULL,   PRIMARY KEY (`l_orderkey`, `l_linenumber`),   KEY `I_L_ORDERKEY` (`l_orderkey`) BLOCK_SIZE 16384 LOCAL,   KEY `I_L_SHIPDATE` (`l_shipdate`) BLOCK_SIZE 16384 LOCAL ) DEFAULT CHARSET = utf8mb4 ROW_FORMAT = COMPACT COMPRESSION = 'zstd_1.3.8' REPLICA_NUM = 1 BLOCK_SIZE = 16384 USE_BLOOM_FILTER = FALSE TABLET_SIZE = 134217728 PCTFREE = 0 TABLEGROUP = 'x_tpch_tg_lineitem_order_group'  partition by key(l_orderkey)   (partition p0,   partition p1,   partition p2,   partition p3,   partition p4,   partition p5,   partition p6,   partition p7,   partition p8,   partition p9,   partition p10,   partition p11,   partition p12,   partition p13,   partition p14,   partition p15) 1 row in set 默认方式执行，不开启 PDML 创建好 lineitem2 后，我们先以默认配置不开启并行的方式插入, 因为这是一个 600 万行的大事务，我们需要将 OceanBase 数据库默认的事务超时时间调整到更大的值（单位为 μs）： ```shell SET ob_query_timeout = 1000000000; SET ob_trx_timeout = 1000000000; 插入数据，执行结果如下：shell obclient [test]> INSERT INTO lineitem2 SELECT * FROM lineitem; Query OK, 6001215 rows affected (1 min 47.312 sec) Records: 6001215  Duplicates: 0  Warnings: 0 ``` 可以看到，不开启并行的情况下，单个事务插入 600 万行数据，OceanBase 的耗时为 107 秒。 开启 PDML 执行 下面我们通过添加一个 Hint，开启 PDML 的执行选项。注意再次插入前，我们先将上次插入的数据清空。 shell obclient [test]> TRUNCATE TABLE lineitem2; obclient [test]> INSERT /*+ parallel(16) enable_parallel_dml */ INTO lineitem2 SELECT * FROM lineitem; 来看这次的执行耗时： shell obclient> TRUNCATE TABLE lineitem2; Query OK, 0 rows affected (0.108 sec) obclient> INSERT /*+ parallel(16) enable_parallel_dml */ INTO lineitem2 SELECT * FROM lineitem; Query OK, 6001215 rows affected (22.117 sec) Records: 6001215  Duplicates: 0  Warnings: 0 可以看到开启 PDML 后，相同的表插入 600 万行数据，OceanBase 数据库的耗时缩短为 22 秒左右。PDML 特性带来的性能提升大约为 5 倍。这一特性可以在用户在需要批量数据处理的场景提供帮助。 数据压缩 OceanBase 数据库基于 LSM-Tree 结构开发了自己的存储引擎。其中数据大致被分为基线数据（SSTable）和增量数据（MemTable）两部分，基线数据被保存在磁盘中，增量修改在内存中进行。这使得一方面数据在磁盘中能够以更紧凑的方式存储。除此之外由于在磁盘中的基线数据不会频繁更新，OceanBase 数据库又基于通用压缩算法对基线数据进行了再次压缩，使得数据存储在 OceanBase 数据库中可以获得非常好的压缩比。同时这种数据压缩并未带来查询和写入性能的下降。下面我们介绍 OceanBase 数据库导入大量外部数据并且观察数据压缩比的方法。 数据准备 首先我们使用数据准备工具 CreateData.jar 生成 5 千万行模拟数据到 /home/soft 目录下，生成数据大概需要十几分钟时间，您也可以使用其他工具生成测试数据。 ```shell mkdir /home/soft/ java -jar CreateData.jar /home/soft/ 50000000 filePath is : /home/soft/ Start Time : 2022-07-10 15:33:00 End Time : 2022-07-10 15:52:53 du -sh * 10G     t_bigdata_loader.unl OceanBase 数据库支持多种方式将 csv 格式的数据导入到 OceanBase 数据库中，本文我们介绍通过 Load Data 命令执行。 1. 首先您需对生成的文件进行命名，并确认实际大小。shell     # mv t_bigdata_loader.unl t_f1.csv     # du -sh t_f1.csv     10G     t_f1.csv     2. 对 `t_f1.csv` 文件内容查看可知，预先生成好的 csv 文件，通过随机算法，获取了 8 列数据，可对应不同的数据类型。因此在体验 OceanBase 数据压缩特性时，需要在租户下先创建一张表，将 csv 文件中的记录，导入到表中。shell     11980-06-017470.689nOLqnBYtnp     22018-11-096891.054UzqteeMaHP     32006-10-0",
        "product": "oceanbase",
        "version": "4.1.0"
    },
    {
        "path": "/Users/zhangying/Desktop/oceanbase-doc-4.1.0/zh-CN/200.quickstart/500.experience-advanced-features-of-oceanbase/300.experience-parallelly-importing-and-data-compression.md",
        "content": "7286.43692KJJtylgxkv     41982-12-182986.242rTkUBWhdPt     ....     3. 在 `test` 租户下的 `test` 数据库中创建一张表，表名为 `t_f1`。详细的租户创建过程，请参考管理租户内容。shell     # obclient -hxxx.xxx.xxx.xxx -P2881 -uroot@test  -Dtest -A -p -c     obclient [test]> CREATE TABLE t_f1(id DECIMAL(10,0),id2 DECIMAL(10,0),id3 DATE,id4 DATE,id5 FLOAT,id6 FLOAT,id7 VARCHAR(30),id8 VARCHAR(300));     ``` 数据导入 我们可以使用 OceanBase 数据库内置的 Load Data 命令导入数据，Load Data 同样支持并行导入。开始导入前进行如下设置。Load Data 命令仅支持数据文件在 OBServer 节点本地执行，如果您希望远程进行数据导入，可以参考使用 OceanBase 数据库的 obloader 工具。 shell obclient [test]> SET GLOBAL secure_file_priv = \"\"; obclient [test]> GRANT FILE ON *.* to username;   注意 由于安全原因，只能使用通过本地连接的 Client 执行修改 secure_file_priv 的 SQL 语句。详细信息请参见 secure_file_priv。  设置完成后，重连会话使设置生效。再设置下会话的事务超时时间，保证执行过程中不会因为超时退出。 shell obclient [test]> SET ob_query_timeout=1000000000; obclient [test]> SET ob_trx_timeout=1000000000; 然后运行导入语句： shell obclient [test]> LOAD DATA /*+ parallel(16) */ INFILE '/home/soft/t_f1.csv' INTO table t_f1 fields TERMINATED BY '\\|' LINES TERMINATED BY '\\n'; 可以看到，开启并行导入后，10 GB 数据耗时大约 4 分钟。本文中租户的 CPU 并行度配置为 16，可以根据您的具体配置设置合适的并行度，配置越高导入速度越快。 导入后，进入数据库对该表记录条数及占用空间大小进行查看。 1. 查看表记录数有 5 千万条。     shell     obclient [test]> SELECT COUNT(*) FROM t_f1; 2. 对数据库合并。    为了查看基线数据的压缩效果，使用 root 用户登录集群的 sys 租户，主动触发对数据库进行合并，使增量数据可以和基线数据进行合并与压缩。您可以通过如下的方式手动触发合并。     shell     # obclient -h127.0.0.1 -P2881 -uroot@sys  -Doceanbase -A -p -c     obclient[oceanbase]> ALTER SYSTEM MAJOR FREEZE; 3. 当看到如下查询返回 IDLE 时，表示合并完成。     shell     obclient [oceanbase]> SELECT * FROM oceanbase.CDB_OB_MAJOR_COMPACTION;      FROZEN_SCN           GLOBAL_BROADCAST_SCN  LAST_FINISH_TIME            STATUS  IS_SUSPENDED       1679248800404017149   1679248800404017149  2023-03-20 02:00:44.035785  IDLE    NO                 1679248804191204504   1679248804191204504  2023-03-20 02:00:46.094551  IDLE    NO                 1679248802450394471   1679248802450394471  2023-03-20 02:00:33.818514  IDLE    NO                1 row in set 4. 使用 sys 租户查询如下语句，可查看导入至 OceanBase 后的数据存储占用情况。     shell     obclient [oceanbase]> select b.table_name,a.svr_ip,data_size/1024/1024/1024 from CDB_OB_TABLET_REPLICAS a,DBA_OB_TABLE_LOCATIONS b where a.tablet_id=b.tablet_id and b.table_name='T_F1';      svr_ip              xxx.xx.xxx.xx 压缩后的表大小约为 6.145 G，压缩比为 = 10/6.145 = 1.62。",
        "product": "oceanbase",
        "version": "4.1.0"
    },
    {
        "path": "/Users/zhangying/Desktop/oceanbase-doc-4.1.0/zh-CN/200.quickstart/500.experience-advanced-features-of-oceanbase/200.experience-operational-olap.md",
        "content": "体验 Operational OLAP OceanBase 数据库可以处理混合负载类型的场景。由于 OceanBase 数据库是基于对等节点的分布式架构，使得它既可以承载高并发和可扩展的 OLTP 任务，还可以在同一套数据引擎中基于 MPP 架构进行 OLAP 的并行计算，无需维护两套数据。 在 OceanBase 数据库中，您不但可以在大量在线业务数据上直接进行并行分析，还可以通过 PDML 能力（Parallel DML）将批量写入数据的大事务以并发的方式快速安全的执行。并且，这一切都是在严格保证事务一致性的前提下做到的。 下面让我们手动进行 TPC-H 测试，演示 OceanBase 数据库在 Operational OLAP 场景的特点和用法。TPC-H 是一个业界常用的基于决策支持业务的 Benchmark，通过一系列在大量数据集上面执行的复杂查询请求，检验数据库系统的分析以及决策支持能力。详细信息，可参见 TPC 组织官方网站。（2021 年 5 月 20 日，OceanBase 数据库以 1526 万 QphH 的成绩刷新了 TPC-H 世界纪录，并且是唯一一个同时刷新了TPC-C 以及 TPC-H 纪录的数据库，证明了其能够同时处理在线交易和实时分析两类业务场景能力。详细信息请参见 TPC-H Result ） 手动进行 TPC-H 测试 以下内容为基于 TPC 官方 TPC-H 工具进行手动 Step-by-Step 进行 TPC-H 测试。手动测试可以帮助更好的学习和了解 OceanBase 数据库，尤其是一些参数的设置。 进行环境调优  OceanBase 数据库调优。    请在系统租户（sys 租户）下执行以下语句配置相关参数。    bash    # 调整 sys 租户占用的内存，以提供测试租户更多资源，需根据实际环境动态调整    ALTER SYSTEM SET system_memory='15g';    ALTER RESOURCE UNIT sys_unit_config memory_size ='15G';    # 调优参数    ALTER SYSTEM SET trace_log_slow_query_watermark='100s';    ALTER SYSTEM SET enable_sql_operator_dump=True;    ALTER SYSTEM SET _hash_area_size='3g';    ALTER SYSTEM SET memstore_limit_percentage=50;    ALTER SYSTEM SET enable_rebalance=False;    ALTER SYSTEM SET memory_chunk_cache_size='0';    ALTER SYSTEM SET major_compact_trigger=5;    ALTER SYSTEM SET cache_wash_threshold='30g';    # 调整日志级别及保存个数    ALTER SYSTEM SET syslog_level='ERROR';    ALTER SYSTEM SET max_syslog_file_count=100;    ALTER SYSTEM SET enable_syslog_recycle='True'; 设置租户配置。    请在测试租户（用户租户）下执行以下语句配置相关参数。    bash    # 设置全局参数    SET GLOBAL ob_sql_work_area_percentage=80;    SET GLOBAL optimizer_use_sql_plan_baselines = true;    SET GLOBAL optimizer_capture_sql_plan_baselines = true;    ALTER SYSTEM SET ob_enable_batched_multi_statement='true';    # 租户下设置，防止事务超时    SET GLOBAL ob_query_timeout=36000000000;    SET GLOBAL ob_trx_timeout=36000000000;    SET GLOBAL max_allowed_packet=67108864;    SET GLOBAL secure_file_priv=\"\";    /*    parallel_server_target 推荐设置为测试租户分配的 Resource Unit CPU 数的 10 倍 * 机器数 * 0.8    如测试租户使用的 Unit 配置为：`CREATE RESOURCE UNIT $unit_name max_cpu 26;`    那么该值为 26*10*3*0.8=624    */    SET GLOBAL parallel_servers_target=624; 调优参数设置完毕后请重启集群。  安装 TPC-H Tool  下载 TPC-H Tool。详细信息请参考 TPC-H Tool 下载页面。 下载完成后解压文件，进入 TPC-H 解压后的目录。    bash    [wieck@localhost ~] $ unzip 7e965ead-8844-4efa-a275-34e35f8ab89b-tpc-h-tool.zip    [wieck@localhost ~] $ cd TPC-H_Tools_v3.0.0 复制 Makefile.suite。    bash    [wieck@localhost TPC-H_Tools_v3.0.0] $ cd dbgen/    [wieck@localhost dbgen] $ cp Makefile.suite Makefile 修改 Makefile 文件中的 CC、DATABASE、MACHINE、WORKLOAD 等参数定义。    bash    CC      = gcc    # Current values for DATABASE are: INFORMIX, DB2, TDAT (Teradata)    #                                  SQLSERVER, SYBASE, ORACLE, VECTORWISE    # Current values for MACHINE are:  ATT, DOS, HP, IBM, ICL, MVS,    #                                  SGI, SUN, U2200, VMS, LINUX, WIN32    # Current values for WORKLOAD are:  TPCH    DATABASE= MYSQL    MACHINE = LINUX    WORKLOAD = TPCH 修改 tpcd.h 文件，并添加新的宏定义。    bash    #ifdef MYSQL    #define GEN_QUERY_PLAN \"\"    #define START_TRAN \"START TRANSACTION\"    #define END_TRAN \"COMMIT\"    #define SET_OUTPUT \"\"    #define SET_ROWCOUNT \"limit %d;\\n\"    #define SET_DBASE \"use %s;\\n\"    #endif 6.编译文件。    bash    make  生成数据 您可以根据实际环境生成 TCP-H 10G、100G 或者 1T 数据。本文以生成 100G 数据为例。 bash ./dbgen -s 100 mkdir tpch100 mv *.tbl tpch100 生成查询 SQL  说明  您可参考本节中的下述步骤生成查询 SQL 后进行调整，也可直接使用 [GitHub](https://github.com/oceanbase/obdeploy/tree/master/plugins/tpch/3.1.0/queries) 中给出的查询 SQL。  若您选择使用 GitHub 中的查询 SQL，您需将 SQL 语句中的 cpu_num修改为实际并发数。   复制 qgen 和 dists.dss 文件至 queries 目录。    bash    cp qgen queries    cp dists.dss queries 在 queries 目录下创建 gen.sh 脚本生成查询 SQL。    bash    #!/usr/bin/bash    for i in {1..22}    do      ./qgen -d $i -s 100 > db\"$i\".sql    done 执行 gen.sh 脚本。    bash    chmod +x  gen.sh    ./gen.sh 查询 SQL 进行调整。    bash    dos2unix * 调整后的查询 SQL 请参考 GitHub。您需将 GitHub 给出的 SQL 语句中的 cpu_num 修改为实际并发数。建议并发数的数值与可用 CPU 总数相同，两者相等时性能最好。 您可在 sys 租户下使用如下命令查看租户的可用 CPU 总数。 sql s",
        "product": "oceanbase",
        "version": "4.1.0"
    },
    {
        "path": "/Users/zhangying/Desktop/oceanbase-doc-4.1.0/zh-CN/200.quickstart/500.experience-advanced-features-of-oceanbase/200.experience-operational-olap.md",
        "content": "elect sum(max_cpu) from DBA_OB_UNITS ; 以 q1 为例，修改后的 SQL 语句如下： sql select /*+    parallel(96) */   ---增加 parallel 并发执行    l_returnflag,    l_linestatus,    sum(l_quantity) as sum_qty,    sum(l_extendedprice) as sum_base_price,    sum(l_extendedprice * (1 - l_discount)) as sum_disc_price,    sum(l_extendedprice * (1 - l_discount) * (1 + l_tax)) as sum_charge,    avg(l_quantity) as avg_qty,    avg(l_extendedprice) as avg_price,    avg(l_discount) as avg_disc,    count(*) as count_order from    lineitem where    l_shipdate <= date '1998-12-01' - interval '90' day  group by    l_returnflag,    l_linestatus order by    l_returnflag,    l_linestatus;  新建表 创建表结构文件 create_tpch_mysql_table_part.ddl。 sql create tablegroup if not exists tpch_tg_100g_lineitem_order_group binding true partition by key 1 partitions 192; create tablegroup if not exists tpch_tg_100g_partsupp_part binding true partition by key 1 partitions 192; drop database if exists $db_name; create database $db_name; use $db_name;     create table lineitem (        l_orderkey bigint not null,        l_partkey bigint not null,        l_suppkey bigint not null,        l_linenumber bigint not null,        l_quantity bigint not null,        l_extendedprice bigint not null,        l_discount bigint not null,        l_tax bigint not null,        l_returnflag char(1) default null,        l_linestatus char(1) default null,        l_shipdate date not null,        l_commitdate date default null,        l_receiptdate date default null,        l_shipinstruct char(25) default null,        l_shipmode char(10) default null,        l_comment varchar(44) default null,        primary key(l_orderkey, l_linenumber))        tablegroup = tpch_tg_100g_lineitem_order_group        partition by key (l_orderkey) partitions 192;     create index I_L_ORDERKEY on lineitem(l_orderkey) local;     create index I_L_SHIPDATE on lineitem(l_shipdate) local;     create table orders (        o_orderkey bigint not null,        o_custkey bigint not null,        o_orderstatus char(1) default null,        o_totalprice bigint default null,        o_orderdate date not null,        o_orderpriority char(15) default null,        o_clerk char(15) default null,        o_shippriority bigint default null,        o_comment varchar(79) default null,        primary key (o_orderkey))        tablegroup = tpch_tg_100g_lineitem_order_group        partition by key(o_orderkey) partitions 192;     create index I_O_ORDERDATE on orders(o_orderdate) local;     create table partsupp (        ps_partkey bigint not null,        ps_suppkey bigint not null,        ps_availqty bigint default null,        ps_supplycost bigint default null,        ps_comment varchar(199) default null,        primary key (ps_partkey, ps_suppkey))        tablegroup tpch_tg_100g_partsupp_part        partition by key(ps_partkey) partitions 192;     create table part (        p_partkey bigint not null,        p_name varchar(55) default null,        p_mfgr char(25) default null,        p_brand char(10) default null,        p_type varchar(25) default null,        p_size bigint default null,        p_container char(10) default null,        p_retailprice bigint default null,        p_comment varchar(23) default null,        primary key (p_partkey))        tablegroup tpch_tg_100g_partsupp_part        partition by key(p_partkey) partitions 192;    create table customer (        c_custkey bigint not null,        c_name varchar(25) default null,        c_address varchar(40) default null,        c_nationkey bigint default null,        c_phone char(15) default null,        c_acctbal bigint default null,        c_mktsegment char(10) default null,        c_comment varchar(117) default null,        primary key (c_custkey))        partition by key(c_custkey) partitions 192;    create table supplier (        s_suppkey bigint not null,        s_name char(25) default null,        s_address varchar(40) default null,        s_nationkey bigint default null,        s_phone char(15) defaul",
        "product": "oceanbase",
        "version": "4.1.0"
    },
    {
        "path": "/Users/zhangying/Desktop/oceanbase-doc-4.1.0/zh-CN/200.quickstart/500.experience-advanced-features-of-oceanbase/200.experience-operational-olap.md",
        "content": "t null,        s_acctbal bigint default null,        s_comment varchar(101) default null,        primary key (s_suppkey)      ) partition by key(s_suppkey) partitions 192;    create table nation (        n_nationkey bigint not null,        n_name char(25) default null,        n_regionkey bigint default null,        n_comment varchar(152) default null,        primary key (n_nationkey));    create table region (        r_regionkey bigint not null,        r_name char(25) default null,        r_comment varchar(152) default null,        primary key (r_regionkey)); 加载数据 您可以根据上述步骤生成的数据和 SQL 自行编写脚本。加载数据示例操作如下： 1. 创建加载脚本目录。    bash    mkdir load    cd load    cp ../dss.ri  ../dss.ddl ./ 2. 创建 load.py 脚本。    python    $cat load.py    #/usr/bin/evn python    #-*- encoding:utf-8 -*-    import os    import sys    import time    import commands    hostname='$host_ip'  # 注意！！请填写某个 observer，如 observer A 所在服务器的 IP 地址    port='$host_port'               # observer A 的端口号    tenant='$tenant_name'              # 租户名    user='$user'               # 用户名    password='******'           # 密码    data_path='$path'         # 注意！！请填写 observer A 所在服务器下 tbl 所在目录    db_name='$db_name'             # 数据库名    # 创建表    cmd_str='obclient -h%s -P%s -u%s@%s -p%s -D%s < create_tpch_mysql_table_part.ddl'%(hostname,port,user,tenant,password,db_name)    result = commands.getstatusoutput(cmd_str)    print result    cmd_str='obclient -h%s -P%s -u%s@%s -p%s  -D%s -e \"show tables;\" '%(hostname,port,user,tenant,password,db_name)    result = commands.getstatusoutput(cmd_str)    print result    cmd_str=\"\"\" obclient -h%s -P%s -u%s@%s -p%s -c  -D%s -e \"load data /*+ parallel(80) */ infile '%s/customer.tbl' into table customer fields terminated by '|';\" \"\"\" %(hostname,port,user,tenant,password,db_name,data_path)    result = commands.getstatusoutput(cmd_str)    print result    cmd_str=\"\"\" obclient -h%s -P%s -u%s@%s -p%s -c  -D%s -e \"load data /*+ parallel(80) */ infile '%s/lineitem.tbl' into table lineitem fields terminated by '|';\" \"\"\" %(hostname,port,user,tenant,password,db_name,data_path)    result = commands.getstatusoutput(cmd_str)    print result    cmd_str=\"\"\" obclient -h%s -P%s -u%s@%s -p%s -c -D%s -e \"load data /*+ parallel(80) */ infile '%s/nation.tbl' into table nation fields terminated by '|';\" \"\"\" %(hostname,port,user,tenant,password,db_name,data_path)    result = commands.getstatusoutput(cmd_str)    print result    cmd_str=\"\"\" obclient -h%s -P%s -u%s@%s -p%s -c  -D%s -e \"load data /*+ parallel(80) */ infile '%s/orders.tbl' into table orders fields terminated by '|';\" \"\"\" %(hostname,port,user,tenant,password,db_name,data_path)    result = commands.getstatusoutput(cmd_str)    print result    cmd_str=\"\"\" obclient -h%s -P%s -u%s@%s -p%s   -D%s -e \"load data /*+ parallel(80) */ infile '%s/partsupp.tbl' into table partsupp fields terminated by '|';\" \"\"\" %(hostname,port,user,tenant,password,db_name,data_path)    result = commands.getstatusoutput(cmd_str)    print result    cmd_str=\"\"\" obclient -h%s -P%s -u%s@%s -p%s -c  -D%s -e \"load data /*+ parallel(80) */ infile '%s/part.tbl' into table part fields terminated by '|';\" \"\"\" %(hostname,port,user,tenant,password,db_name,data_path)    result = commands.getstatusoutput(cmd_str)    print result    cmd_str=\"\"\" obclient -h%s -P%s -u%s@%s -p%s -c  -D%s -e \"load data /*+ parallel(80) */ infile '%s/region.tbl' into table region fields terminated by '|';\" \"\"\" %(hostname,port,user,tenant,password,db_name,data_path)    result = commands.getstatusoutput(cmd_str)    print result    cmd_str=\"\"\" obclient -h%s -P%s -u%s@%s -p%s -c  -D%s -e \"load data /*+ parallel(80) */ infile '%s/supplier.tbl' into table supplier fields terminated by '|';\" \"\"\" %(hostname,port,user,tenant,password,db_name,data_path)    result = commands.getstatusoutput(cmd_str)    print result 3. 加载数据。    注意 加载数据需要安装 OBClient 客户端。  python    $ python load.py    (0,'')    (0, 'obclient: [Warning] Using a password on the command line interface can be insecure.\\nTABLE_NAME\\nT1",
        "product": "oceanbase",
        "version": "4.1.0"
    },
    {
        "path": "/Users/zhangying/Desktop/oceanbase-doc-4.1.0/zh-CN/200.quickstart/500.experience-advanced-features-of-oceanbase/200.experience-operational-olap.md",
        "content": "\\nLINEITEM\\nORDERS\\nPARTSUPP\\nPART\\nCUSTOMER\\nSUPPLIER\\nNATION\\nREGION')    (0, 'obclient: [Warning] Using a password on the command line interface can be insecure.')    (0, 'obclient: [Warning] Using a password on the command line interface can be insecure.')    (0, 'obclient: [Warning] Using a password on the command line interface can be insecure.')    (0, 'obclient: [Warning] Using a password on the command line interface can be insecure.')    (0, 'obclient: [Warning] Using a password on the command line interface can be insecure.')    (0, 'obclient: [Warning] Using a password on the command line interface can be insecure.')    (0, 'obclient: [Warning] Using a password on the command line interface can be insecure.') 4. 执行合并。    Major 合并将当前大版本的 SSTable 和 MemTable 与前一个大版本的全量静态数据进行合并，使存储层统计信息更准确，生成的执行计划更稳定。    注意 执行合并需要使用 root 用户登录 OceanBase 集群的 sys 租户。  sql    MySQL [(none)]> USE oceanbase    Database changed    MySQL [oceanbase]> ALTER SYSTEM MAJOR FREEZE;    Query OK, 0 rows affected 5. 查看合并是否完成。    sql    MySQL [oceanbase]> SELECT FROZEN_SCN, LAST_SCN FROM oceanbase.CDB_OB_MAJOR_COMPACTION;     LAST_SCN            |     1667239201167716767 |     1667239200111919300 |     1667239201167452168 |     1667239201168053124 |     1667239201167520213 |   说明  所有的 FROZEN_SCN 和 LAST_SCN 的值相等即表示合并完成。  执行测试 您可以根据上述步骤生成的数据和 SQL 自行编写脚本。执行测试示例操作如下： 1. 在 queries 目录下编写测试脚本 tpch.sh。    bash    #!/bin/bash    TPCH_TEST=\"obclient -h $host_ip -P $host_port -utpch_100g_part@tpch_mysql  -D tpch_100g_part  -ptest -c\"    # warmup预热    for i in {1..22}    do       sql1=\"source db${i}.sql\"       echo $sql1| ret=1    done    # 正式执行    for i in {1..22}    do       starttime=`date +%s%N`       echo `date  '+[%Y-%m-%d %H:%M:%S]'` \"BEGIN Q${i}\"       sql1=\"source db${i}.sql\"       echo $sql1| ret=1       stoptime=`date +%s%N`       costtime=`echo $stoptime $starttime | awk '{printf \"%0.2f\\n\", ($1 - $2) / 1000000000}'`       echo `date  '+[%Y-%m-%d %H:%M:%S]'` \"END,COST ${costtime}s\"    done 2. 执行测试脚本。    bash    sh tpch.sh FAQ  导入数据失败。报错信息如下：   bash   ERROR 1017 (HY000) at line 1: File not exist tbl 文件必须放在所连接的 OceanBase 数据库所在机器的某个目录下，因为加载数据必须本地导入。 查看数据报错。报错信息如下：   bash   ERROR 4624 (HY000)：No memory or reach tenant memory limit   内存不足，建议增大租户内存。 导入数据报错。报错信息如下：   bash   ERROR 1227 (42501) at line 1: Access denied   需要授予用户访问权限。运行以下命令，授予权限：   bash   grant file on *.* to tpch_100g_part; 查询 SQL 进行调整 dos2unix * 时报错，报错信息如下：   bash   -bash: dos2unix: command not found   需要安装 dos2unix。执行以下命令，即可安装：    bash    yum install -y dos2unix  手动体验 Operational OLAP 通过上一步的操作，我们已经获得了一个 TPCH 的测试环境，下面让我们通过手动执行来看看，OceanBase 数据库在 OLAP 方面的能力和特性。 我们先使用 OBClient 登录到数据库中，如果您没有安装 OBClient，使用 mysql 客户端也是可以的。 shell obclient -h127.0.0.1 -P2881 -uroot@test  -Dtest -A -p -c 在开始之前，您需要根据 OceanBase 集群和租户的配置，进行并行度的设置，具体大小建议不超过当前租户配置的 CPU 核数的 2 倍。例如您的租户 CPU 最大配置为8，那么此处建议并行度设置为16： sql MySQL [test]> SET GLOBAL parallel_servers_target=16; Query OK, 0 rows affected  MySQL [test]> SET GLOBAL parallel_max_servers=16; Query OK, 0 rows affected OceanBase 数据库兼容大多数 MySQL 的内部视图，我们可以通过如下查询查看当前环境中表的大小： sql MySQL [test]> SELECT table_name, table_rows, CONCAT(ROUND(data_length/(1024*1024*1024),2),' GB')  table_size FROM information_schema.TABLES WHERE table_schema = 'test' order by table_rows desc;  table_rows      6001215      1500000       800000       200000       150000        10000           25            5  8 rows in set 下面我们通过 TPC-H 测试中的 Q1 来体验 OceanBase 数据库查询能力，Q1 查询会在最大的 lineitem 表上，汇总分析指定时间内各类商品的价格、折扣、发货、数量等信息。这个查询对全表数据都会进行读取、并进行分区、排序、聚合等计算。 不开启并发查询 首先，我们在默认不开启并发的情况下执行该查询： sql select   l_returnflag,  l_linestatus,  sum(l_quantity) as sum_qty,  sum(l_extendedprice) as sum_base_price,  sum(l_extendedprice * (1 - l_discount)) as sum_disc_price,  sum(l_extendedprice * (1 - l_discount) * (1 + l_tax)) as sum_charge,  avg(l_quantity) as avg_qty,  avg(l_extendedprice) as avg_price,  avg(l_discount) as avg_disc,  count(*) as count_order from  lineitem where  l_shipdate <= date '1998-12-01' - interval '90' day",
        "product": "oceanbase",
        "version": "4.1.0"
    },
    {
        "path": "/Users/zhangying/Desktop/oceanbase-doc-4.1.0/zh-CN/200.quickstart/500.experience-advanced-features-of-oceanbase/200.experience-operational-olap.md",
        "content": " group by  l_returnflag,  l_linestatus order by  l_returnflag,  l_linestatus; 在本例的测试环境中，执行结果如下: sql  l_linestatus  sum_base_price  sum_charge    avg_price   count_order |  F                56586577106   56586577106  38273.1451      1478493 |  F                 1487505208    1487505208  38284.4806        38854 |  O               111701776272  111701776272  38249.1339      2920374 |  F                56568064200   56568064200  38250.8701      1478870 | 4 rows in set (6.791 sec) 开启并发查询 OceanBase 数据库的 Operational OLAP 能力基于一套数据以及执行引擎，无需进行异构的数据同步和维护。下面我们通过添加一个 parallel Hint，以并行度为8的方式再次执行这条语句： sql select /*+parallel(8) */  l_returnflag,  l_linestatus,  sum(l_quantity) as sum_qty,  sum(l_extendedprice) as sum_base_price,  sum(l_extendedprice * (1 - l_discount)) as sum_disc_price,  sum(l_extendedprice * (1 - l_discount) * (1 + l_tax)) as sum_charge,  avg(l_quantity) as avg_qty,  avg(l_extendedprice) as avg_price,  avg(l_discount) as avg_disc,  count(*) as count_order from  lineitem where  l_shipdate <= date '1998-12-01' - interval '90' day group by  l_returnflag,  l_linestatus order by  l_returnflag,  l_linestatus; 在相同的环境和数据集中，执行结果如下： sql  l_linestatus  sum_base_price  sum_charge    avg_price   count_order |  F                56586577106   56586577106  38273.1451      1478493 |  F                 1487505208    1487505208  38284.4806        38854 |  O               111701776272  111701776272  38249.1339      2920374 |  F                56568064200   56568064200  38250.8701      1478870 | 4 rows in set (1.197 sec) 可以看到，对比默认无并发的执行耗时，并行查询下速度提升了将近 6 倍。如果我们通过 EXPLAIN 命令查看执行计划，也可以看到并行度的展示（第 18 行，1 号算子，dop=8）： ```sql =============================================================== OPERATOR                      EST. ROWS  PX COORDINATOR MERGE SORT     6        EXCHANGE OUT DISTR           6         SORT                        6          HASH GROUP BY              6           EXCHANGE IN DISTR         6            EXCHANGE OUT DISTR (HASH)6             HASH GROUP BY           6              PX BLOCK ITERATOR      5939712         TABLE SCAN            5939712 =============================================================== Outputs & filters:  0 - output([lineitem.l_returnflag], [lineitem.l_linestatus], [T_FUN_SUM(T_FUN_SUM(lineitem.l_quantity))], [T_FUN_SUM(T_FUN_SUM(lineitem.l_extendedprice))], [T_FUN_SUM(T_FUN_SUM(lineitem.l_extendedprice * 1 - lineitem.l_discount))], [T_FUN_SUM(T_FUN_SUM(lineitem.l_extendedprice * 1 - lineitem.l_discount * 1 + lineitem.l_tax))], [T_FUN_SUM(T_FUN_SUM(lineitem.l_quantity)) / cast(T_FUN_COUNT_SUM(T_FUN_COUNT(lineitem.l_quantity)), DECIMAL(20, 0))], [T_FUN_SUM(T_FUN_SUM(lineitem.l_extendedprice)) / cast(T_FUN_COUNT_SUM(T_FUN_COUNT(lineitem.l_extendedprice)), DECIMAL(20, 0))], [T_FUN_SUM(T_FUN_SUM(lineitem.l_discount)) / cast(T_FUN_COUNT_SUM(T_FUN_COUNT(lineitem.l_discount)), DECIMAL(20, 0))], [T_FUN_COUNT_SUM(T_FUN_COUNT())]), filter(nil), sort_keys([lineitem.l_returnflag, ASC], [lineitem.l_linestatus, ASC])   1 - output([lineitem.l_returnflag], [lineitem.l_linestatus], [T_FUN_SUM(T_FUN_SUM(lineitem.l_quantity))], [T_FUN_SUM(T_FUN_SUM(lineitem.l_extendedprice))], [T_FUN_SUM(T_FUN_SUM(lineitem.l_extendedprice * 1 - lineitem.l_discount))], [T_FUN_SUM(T_FUN_SUM(lineitem.l_extendedprice * 1 - lineitem.l_discount * 1 + lineitem.l_tax))], [T_FUN_COUNT_SUM(T_FUN_COUNT())], [T_FUN_SUM(T_FUN_SUM(lineitem.l_quantity)) / cast(T_FUN_COUNT_SUM(T_FUN_COUNT(lineitem.l_quantity)), DECIMAL(20, 0))], [T_FUN_SUM(T_FUN_SUM(lineitem.l_extendedprice)) / cast(T_FUN_COUNT_SUM(T_FUN_COUNT(lineitem.l_extendedprice)), DECIMAL(20, 0))], [T_FUN_SUM(T_FUN_SUM(lineitem.l_discount)) / cast(T_FUN_COUNT_SUM(T_FUN_COUNT(lineitem.l_discount)), DECIMAL(20, 0))]), filter(nil), dop=8   2 - output([lineitem.l_returnflag], [lineitem.l_linestatus], [T_FUN_SUM(T_FUN_SUM(lineitem.l_quantity))], [T_FUN_SUM(T_FUN_SUM(lineitem.l_extendedprice))], [T_FUN_SUM(T_FUN_SUM(lineitem.l_extendedprice * 1 - lineitem.l_discount))], [T_FUN_SUM(T_FUN_SUM(lineitem.l_extendedp",
        "product": "oceanbase",
        "version": "4.1.0"
    },
    {
        "path": "/Users/zhangying/Desktop/oceanbase-doc-4.1.0/zh-CN/200.quickstart/500.experience-advanced-features-of-oceanbase/200.experience-operational-olap.md",
        "content": "rice * 1 - lineitem.l_discount * 1 + lineitem.l_tax))], [T_FUN_COUNT_SUM(T_FUN_COUNT())], [T_FUN_SUM(T_FUN_SUM(lineitem.l_quantity)) / cast(T_FUN_COUNT_SUM(T_FUN_COUNT(lineitem.l_quantity)), DECIMAL(20, 0))], [T_FUN_SUM(T_FUN_SUM(lineitem.l_extendedprice)) / cast(T_FUN_COUNT_SUM(T_FUN_COUNT(lineitem.l_extendedprice)), DECIMAL(20, 0))], [T_FUN_SUM(T_FUN_SUM(lineitem.l_discount)) / cast(T_FUN_COUNT_SUM(T_FUN_COUNT(lineitem.l_discount)), DECIMAL(20, 0))]), filter(nil), sort_keys([lineitem.l_returnflag, ASC], [lineitem.l_linestatus, ASC])   3 - output([lineitem.l_returnflag], [lineitem.l_linestatus], [T_FUN_SUM(T_FUN_SUM(lineitem.l_quantity))], [T_FUN_SUM(T_FUN_SUM(lineitem.l_extendedprice))], [T_FUN_SUM(T_FUN_SUM(lineitem.l_extendedprice * 1 - lineitem.l_discount))], [T_FUN_SUM(T_FUN_SUM(lineitem.l_extendedprice * 1 - lineitem.l_discount * 1 + lineitem.l_tax))], [T_FUN_COUNT_SUM(T_FUN_COUNT(lineitem.l_quantity))], [T_FUN_COUNT_SUM(T_FUN_COUNT(lineitem.l_extendedprice))], [T_FUN_SUM(T_FUN_SUM(lineitem.l_discount))], [T_FUN_COUNT_SUM(T_FUN_COUNT(lineitem.l_discount))], [T_FUN_COUNT_SUM(T_FUN_COUNT())]), filter(nil),       group([lineitem.l_returnflag], [lineitem.l_linestatus]), agg_func([T_FUN_SUM(T_FUN_SUM(lineitem.l_quantity))], [T_FUN_SUM(T_FUN_SUM(lineitem.l_extendedprice))], [T_FUN_SUM(T_FUN_SUM(lineitem.l_extendedprice * 1 - lineitem.l_discount))], [T_FUN_SUM(T_FUN_SUM(lineitem.l_extendedprice * 1 - lineitem.l_discount * 1 + lineitem.l_tax))], [T_FUN_COUNT_SUM(T_FUN_COUNT())], [T_FUN_COUNT_SUM(T_FUN_COUNT(lineitem.l_quantity))], [T_FUN_COUNT_SUM(T_FUN_COUNT(lineitem.l_extendedprice))], [T_FUN_SUM(T_FUN_SUM(lineitem.l_discount))], [T_FUN_COUNT_SUM(T_FUN_COUNT(lineitem.l_discount))])   4 - output([lineitem.l_returnflag], [lineitem.l_linestatus], [T_FUN_SUM(lineitem.l_quantity)], [T_FUN_SUM(lineitem.l_extendedprice)], [T_FUN_SUM(lineitem.l_extendedprice * 1 - lineitem.l_discount)], [T_FUN_SUM(lineitem.l_extendedprice * 1 - lineitem.l_discount * 1 + lineitem.l_tax)], [T_FUN_COUNT(lineitem.l_quantity)], [T_FUN_COUNT(lineitem.l_extendedprice)], [T_FUN_SUM(lineitem.l_discount)], [T_FUN_COUNT(lineitem.l_discount)], [T_FUN_COUNT()]), filter(nil)   5 - (#keys=2, [lineitem.l_returnflag], [lineitem.l_linestatus]), output([lineitem.l_returnflag], [lineitem.l_linestatus], [T_FUN_SUM(lineitem.l_quantity)], [T_FUN_SUM(lineitem.l_extendedprice)], [T_FUN_SUM(lineitem.l_extendedprice * 1 - lineitem.l_discount)], [T_FUN_SUM(lineitem.l_extendedprice * 1 - lineitem.l_discount * 1 + lineitem.l_tax)], [T_FUN_COUNT(lineitem.l_quantity)], [T_FUN_COUNT(lineitem.l_extendedprice)], [T_FUN_SUM(lineitem.l_discount)], [T_FUN_COUNT(lineitem.l_discount)], [T_FUN_COUNT()]), filter(nil), dop=8   6 - output([lineitem.l_returnflag], [lineitem.l_linestatus], [T_FUN_SUM(lineitem.l_quantity)], [T_FUN_SUM(lineitem.l_extendedprice)], [T_FUN_SUM(lineitem.l_extendedprice * 1 - lineitem.l_discount)], [T_FUN_SUM(lineitem.l_extendedprice * 1 - lineitem.l_discount * 1 + lineitem.l_tax)], [T_FUN_COUNT(lineitem.l_quantity)], [T_FUN_COUNT(lineitem.l_extendedprice)], [T_FUN_SUM(lineitem.l_discount)], [T_FUN_COUNT(lineitem.l_discount)], [T_FUN_COUNT()]), filter(nil),       group([lineitem.l_returnflag], [lineitem.l_linestatus]), agg_func([T_FUN_SUM(lineitem.l_quantity)], [T_FUN_SUM(lineitem.l_extendedprice)], [T_FUN_SUM(lineitem.l_extendedprice * 1 - lineitem.l_discount)], [T_FUN_SUM(lineitem.l_extendedprice * 1 - lineitem.l_discount * 1 + lineitem.l_tax)], [T_FUN_COUNT(*)], [T_FUN_COUNT(lineitem.l_quantity)], [T_FUN_COUNT(lineitem.l_extendedprice)], [T_FUN_SUM(lineitem.l_discount)], [T_FUN_COUNT(lineitem.l_discount)])   7 - output([lineitem.l_returnflag], [lineitem.l_linestatus], [lineitem.l_quantity], [lineitem.l_extendedprice], [lineitem.l_discount], [lineitem.l_extendedprice * 1 - lineitem.l_discount], [lineitem.l_extendedprice * 1 - lineitem.l_discount * 1 + lineitem.l_tax]), filter(nil)   8 - output([lineitem.l_returnflag], [lineitem.l_linestatus], [lineitem.l_quantity], [",
        "product": "oceanbase",
        "version": "4.1.0"
    },
    {
        "path": "/Users/zhangying/Desktop/oceanbase-doc-4.1.0/zh-CN/200.quickstart/500.experience-advanced-features-of-oceanbase/200.experience-operational-olap.md",
        "content": "lineitem.l_extendedprice], [lineitem.l_discount], [lineitem.l_extendedprice * 1 - lineitem.l_discount], [lineitem.l_extendedprice * 1 - lineitem.l_discount * 1 + lineitem.l_tax]), filter([lineitem.l_shipdate <= ?]),       access([lineitem.l_shipdate], [lineitem.l_returnflag], [lineitem.l_linestatus], [lineitem.l_quantity], [lineitem.l_extendedprice], [lineitem.l_discount], [lineitem.l_tax]), partitions(p[0-15]) ``` 本文中的例子使用单节点环境部署，值得特别说明的是，OceanBase 数据库的并行执行框架最大的特点是还可以将大量数据的分析查询以多节点并发执行的方式进行分析。例如一张表包含上亿行数据，分布在多个 OceanBase 数据库节点上，当进行分析查询时，OceanBase 数据库的分布式执行框架可以生成一个分布式并行执行计划，利用多个节点的资源进行分析。因此具备很好的扩展性，同时针对并行的设置还可以在 SQL、会话、表上多个维度进行设置。 使用 OBD 工具自动进行 TPCH 测试  功能适用性 该内容仅适用于 OceanBase 数据库社区版。OceanBase 数据库企业版暂不支持 OBD 使用。  进行 TPC-H 测试除了可以参考 TPC 官方网站提供的数据集生成工具，我们也可以使用 OBD 方便的进行数据集生成、建表、数据导入等工作，并且自动完成 22 个 SQL 的执行。 在使用 OBD 进行 TPC-H 测试前，您需要先在部署了 OceanBase 和 OBD 的节点上安装 obtpch 组件： test sudo yum install obtpch 完成后，我们通过如下命令，就可以启动一个数据集规模为 1 GB 的 TPCH 测试了，整个过程包括数据集生成、schema 导入、以及自动运行测试。本文中假设您的测试环境部署和 快速体验 OceanBase 数据库 中的步骤一致，如有差别，例如集群名称、密码 安装目录等，请根据具体情况进行调整。   注意 请确保您的磁盘空间足够放置数据集文件，以免将空间占满导致系统异常。  本例中我们使用 /tmp 目录进行测试。 test cd /tmp obd test tpch obtest --tenant=test -s 1 --password='******' --remote-tbl-dir=/tmp/tpch1 执行上述命令后，OBD 开始执行，可以看到执行过程中的每个步骤:   数据导入完成后，OBD 自动进行 22 个 SQL 的执行，并打印每个 SQL 的耗时以及总耗时。",
        "product": "oceanbase",
        "version": "4.1.0"
    },
    {
        "path": "/Users/zhangying/Desktop/oceanbase-doc-4.1.0/zh-CN/200.quickstart/500.experience-advanced-features-of-oceanbase/500.experience-ddl/200.experience-ddl-of-oracle-mode.md",
        "content": "体验 DDL 新特性（Oracle 模式） OceanBase 数据库 Oracle 模式下的 DDL 新特性包括变更主键、变更分区类型和变更列类型。   功能适用性 该内容仅适用于 OceanBase 数据库企业版。OceanBase 数据库社区版仅提供 MySQL 模式。  变更主键 OceanBase 数据库 Oracle 模式下的主键操作包括添加主键、修改主键和删除主键。 添加主键 添加主键的语法如下： sql ALTER TABLE table_name ADD PRIMARY KEY (column_name); 添加主键的示例如下： sql obclient> CREATE TABLE tbl1(c1 INT,c2 VARCHAR(50)); Query OK, 0 rows affected obclient [test]> SHOW CREATE TABLE tbl1;  Create Table                                                                                                                                                                                                                                                   |  CREATE TABLE `tbl1` (   `c1` int(11) DEFAULT NULL,   `c2` varchar(50) DEFAULT NULL ) DEFAULT CHARSET = utf8mb4 ROW_FORMAT = DYNAMIC COMPRESSION = 'zstd_1.3.8' REPLICA_NUM = 1 BLOCK_SIZE = 16384 USE_BLOOM_FILTER = FALSE TABLET_SIZE = 134217728 PCTFREE = 0 | 1 row in set obclient> ALTER TABLE tbl1 ADD PRIMARY KEY(c1); Query OK, 0 rows affected obclient> SHOW CREATE TABLE tbl1;  Create Table                                                                                                                                                                                                                                                                     |  CREATE TABLE `tbl1` (   `c1` int(11) NOT NULL,   `c2` varchar(50) DEFAULT NULL,   PRIMARY KEY (`c1`) ) DEFAULT CHARSET = utf8mb4 ROW_FORMAT = DYNAMIC COMPRESSION = 'zstd_1.3.8' REPLICA_NUM = 1 BLOCK_SIZE = 16384 USE_BLOOM_FILTER = FALSE TABLET_SIZE = 134217728 PCTFREE = 0 | 1 row in set 修改主键 修改主键的语法如下： sql ALTER TABLE table_name MODIFY PRIMARY KEY (column_name); 修改主键的示例如下： sql obclient> ALTER TABLE tbl1 MODIFY PRIMARY KEY (c2); Query OK, 0 rows affected obclient [test]> SHOW CREATE TABLE tbl1;  Create Table                                                                                                                                                                                                                                                                     |  CREATE TABLE `tbl1` (   `c1` int(11) NOT NULL,   `c2` varchar(50) DEFAULT NULL,   PRIMARY KEY (`c2`) ) DEFAULT CHARSET = utf8mb4 ROW_FORMAT = DYNAMIC COMPRESSION = 'zstd_1.3.8' REPLICA_NUM = 1 BLOCK_SIZE = 16384 USE_BLOOM_FILTER = FALSE TABLET_SIZE = 134217728 PCTFREE = 0 | 1 row in set 删除主键 删除主键的语法如下： sql ALTER TABLE table_name DROP PRIMARY KEY; 删除主键的示例如下： sql obclient> ALTER TABLE tbl1 DROP PRIMARY KEY; Query OK, 0 rows affected obclient [test]> SHOW CREATE TABLE tbl1;  Create Table                                                                                                                                                                                                                                               |  CREATE TABLE `tbl1` (   `c1` int(11) NOT NULL,   `c2` varchar(50) DEFAULT NULL ) DEFAULT CHARSET = utf8mb4 ROW_FORMAT = DYNAMIC COMPRESSION = 'zstd_1.3.8' REPLICA_NUM = 1 BLOCK_SIZE = 16384 USE_BLOOM_FILTER = FALSE TABLET_SIZE = 134217728 PCTFREE = 0 | 1 row in set 变更分区类型 OceanBase 数据库 Oracle 模式下变更分区类型（支持将非分区表转换为一级分区表和二级分区表）的语法如下： sql ALTER TABLE table_name MODIFY partition_option;   注意 OceanBase 数据库当前版本只支持非分区表转换成分区表。  变更分区示例 示例 1：将非分区表转换成为一级分区表。 sql obclient> CREATE TABLE tbl1(c1 INT PRIMARY KEY, c2 DATE); Query OK, 0 rows affected obclient> ALTER TABLE tbl1 MODIFY PARTITION BY HASH(c1) PARTITIONS 4; Query OK, 0 rows affected obclient> SHOW  CREATE TABLE tbl1;  CREATE TABLE                                                                                                                                                                                                                                                                                                               |  CREATE TABLE \"TBL1\" (   \"C1\" NUMBER(*,0),   \"C2\" DATE,   CONSTRAINT \"TBL1_OBPK_1668762793014376\" PRIMARY KEY (\"C1\") ) COMPRESS FOR ARCHIVE REPLICA_NUM = 1 BLOCK_SIZE = 16384 USE_BLOOM_FILTER",
        "product": "oceanbase",
        "version": "4.1.0"
    },
    {
        "path": "/Users/zhangying/Desktop/oceanbase-doc-4.1.0/zh-CN/200.quickstart/500.experience-advanced-features-of-oceanbase/500.experience-ddl/200.experience-ddl-of-oracle-mode.md",
        "content": " = FALSE TABLET_SIZE = 134217728 PCTFREE = 0  partition by hash(c1) (partition P0, partition P1, partition P2, partition P3) | 1 row in set 示例 2：将非分区表转换成为二级分区表（模版化）。 sql obclient> CREATE TABLE tbl2(c1 INT, c2 DATE, PRIMARY KEY(c1, c2)); Query OK, 0 rows affected obclient> ALTER TABLE tbl2 MODIFY PARTITION BY HASH(c1)                                 SUBPARTITION BY RANGE (c2)                 SUBPARTITION TEMPLATE(                 SUBPARTITION p1 VALUES LESS THAN (TO_DATE('2016/02/01','YYYY/MM/DD')),                 SUBPARTITION p2 VALUES LESS THAN (TO_DATE('2116/02/01','YYYY/MM/DD'))                 ); Query OK, 0 rows affected obclient [SYS]> SHOW CREATE TABLE tbl2;  CREATE TABLE                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |  CREATE TABLE \"TBL2\" (   \"C1\" NUMBER(*,0),   \"C2\" DATE,   CONSTRAINT \"TBL2_OBPK_1668762841207762\" PRIMARY KEY (\"C1\", \"C2\") ) COMPRESS FOR ARCHIVE REPLICA_NUM = 1 BLOCK_SIZE = 16384 USE_BLOOM_FILTER = FALSE TABLET_SIZE = 134217728 PCTFREE = 0  partition by hash(c1) subpartition by range(c2) subpartition template ( subpartition P1 values less than (TO_DATE(' 2016-02-01 00:00:00', 'SYYYY-MM-DD HH24:MI:SS', 'NLS_CALENDAR=GREGORIAN')), subpartition P2 values less than (TO_DATE(' 2116-02-01 00:00:00', 'SYYYY-MM-DD HH24:MI:SS', 'NLS_CALENDAR=GREGORIAN'))) (partition P0) | 1 row in set 示例 3：将非分区表转换成为二级分区表（非模版化）。 sql obclient> CREATE TABLE tbl3(c1 INT, c2 DATE, PRIMARY KEY(c1, c2)); Query OK, 0 rows affected obclient> ALTER TABLE tbl3 MODIFY PARTITION BY RANGE(c1)              SUBPARTITION BY RANGE(c2) (                   PARTITION p0 VALUES LESS THAN(0),                   PARTITION p1 VALUES LESS THAN(100)); Query OK, 0 rows affected obclient> SHOW CREATE TABLE tbl3;  CREATE TABLE                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |  CREATE TABLE \"TBL3\" (   \"C1\" NUMBER(*,0),   \"C2\" DATE,   CONSTRAINT \"TBL3_OBPK_1668762883951475\" PRIMARY KEY (\"C1\", \"C2\") ) COMPRESS FOR ARCHIVE REPLICA_NUM = 1 BLOCK_SIZE = 16384 USE_BLOOM_FILTER = FALSE TABLET_SIZE = 134217728 PCTFREE = 0  partition by range(c1) subpartition by range(c2) (partition P0 values less than (0) ( subpartition P8192 values less than (MAXVALUE)), partition P1 values less than (100) ( subpartition P8193 values less than (MAXVALUE))) | 1 row in set 变更列类型 OceanBase 数据库 Oracle 模式下所支持的列类型的相关转换如下： * 字符类型列的数据类型转换，包括 CHAR 和 VARCHAR2。 * 数值数据类型支持改变精度，包括 NUMBER（不允许降低精度）。 * 字符数据类型支持改变精度，包括 CHAR（不允许降低精度）、VARCHAR2 、NVARCHAR2 和 NCHAR。  修改列类型的语法如下： sql ALTER TABLE table_name MODIFY column_name data_type; 修改列类型的示例 字符数据类型之间的转换示例 示例 1：修改字符数据类型列的数据类型并提升长度。 sql obclient> CREATE TABLE test01 (c1 INT PRIMARY KEY, c2 CHAR(10), c3 VARCHAR2(32)); Query OK, 0 rows affected obclient> ALTER TABLE test01 MODIFY c2 VARCHAR(20); Query OK, 0 rows affected obclient> ALTER TABLE test01 MODIFY c3 VARCHAR(64); Query OK, 0 rows affected obclient> ALTER TABLE test01 MODIFY c3 CHAR(256); Query OK, 0 rows affected obclient> SHOW CREATE TABLE test01;  CREATE TABLE                                                                                                                                               ",
        "product": "oceanbase",
        "version": "4.1.0"
    },
    {
        "path": "/Users/zhangying/Desktop/oceanbase-doc-4.1.0/zh-CN/200.quickstart/500.experience-advanced-features-of-oceanbase/500.experience-ddl/200.experience-ddl-of-oracle-mode.md",
        "content": "                                                                                                              |  CREATE TABLE \"TEST01\" (   \"C1\" NUMBER(*,0),   \"C2\" VARCHAR2(20),   \"C3\" CHAR(256),   CONSTRAINT \"TEST01_OBPK_1668762938184544\" PRIMARY KEY (\"C1\") ) COMPRESS FOR ARCHIVE REPLICA_NUM = 1 BLOCK_SIZE = 16384 USE_BLOOM_FILTER = FALSE TABLET_SIZE = 134217728 PCTFREE = 0 | 1 row in set 示例 2：缩短字符数据类型列的长度。 sql obclient> CREATE TABLE test02(c1 VARCHAR2(128)); Query OK, 0 rows affected obclient> ALTER TABLE test02 MODIFY c1 VARCHAR2(64); Query OK, 0 rows affected obclient [SYS]> SHOW CREATE TABLE test02;  CREATE TABLE                                                                                                                                                       |  CREATE TABLE \"TEST02\" (   \"C1\" VARCHAR2(64) ) COMPRESS FOR ARCHIVE REPLICA_NUM = 1 BLOCK_SIZE = 16384 USE_BLOOM_FILTER = FALSE TABLET_SIZE = 134217728 PCTFREE = 0 | 1 row in set obclient> CREATE TABLE test03(c1 CHAR(10)); Query OK, 0 rows affected obclient> ALTER TABLE test03 MODIFY c1 CHAR(20); Query OK, 0 rows affected obclient> SHOW CREATE TABLE test03;  CREATE TABLE                                                                                                                                                   |  CREATE TABLE \"TEST03\" (   \"C1\" CHAR(20) ) COMPRESS FOR ARCHIVE REPLICA_NUM = 1 BLOCK_SIZE = 16384 USE_BLOOM_FILTER = FALSE TABLET_SIZE = 134217728 PCTFREE = 0 | 1 row in set 改变数值数据类型精度的示例 示例 1：修改带精度的数值数据类型列的精度。  sql obclient> CREATE TABLE test05(c1 NUMBER(10,2)); Query OK, 0 rows affected obclient> ALTER TABLE test05 MODIFY c1 NUMBER(11,3); Query OK, 0 rows affected obclient [SYS]> SHOW CREATE TABLE test05;  CREATE TABLE                                                                                                                                                       |  CREATE TABLE \"TEST05\" (   \"C1\" NUMBER(11,3) ) COMPRESS FOR ARCHIVE REPLICA_NUM = 1 BLOCK_SIZE = 16384 USE_BLOOM_FILTER = FALSE TABLET_SIZE = 134217728 PCTFREE = 0 | 1 row in set",
        "product": "oceanbase",
        "version": "4.1.0"
    },
    {
        "path": "/Users/zhangying/Desktop/oceanbase-doc-4.1.0/zh-CN/200.quickstart/500.experience-advanced-features-of-oceanbase/500.experience-ddl/100.experience-ddl-of-mysql-mode.md",
        "content": "体验 DDL 新特性（MySQL 模式） OceanBase 数据库 MySQL 模式下的 DDL 新特性包括变更主键、变更分区类型、变更列类型和修改字符集。 变更主键 OceanBase 数据库 MySQL 模式下的变更主键操作包括添加主键、修改主键和删除主键。 添加主键 添加主键的语法如下： sql ALTER TABLE table_name ADD PRIMARY KEY (column_name); 添加主键的示例如下： sql obclient> CREATE TABLE tbl1(c1 INT,c2 VARCHAR(50)); Query OK, 0 rows affected obclient> SHOW CREATE TABLE tbl1;  Create Table                                                                                                                                                                                                                                                   |  CREATE TABLE `tbl1` (   `c1` int(11) DEFAULT NULL,   `c2` varchar(50) DEFAULT NULL ) DEFAULT CHARSET = utf8mb4 ROW_FORMAT = DYNAMIC COMPRESSION = 'zstd_1.3.8' REPLICA_NUM = 1 BLOCK_SIZE = 16384 USE_BLOOM_FILTER = FALSE TABLET_SIZE = 134217728 PCTFREE = 0 | obclient> ALTER TABLE tbl1 ADD PRIMARY KEY(c1); Query OK, 0 rows affected obclient> SHOW CREATE TABLE tbl1;  Create Table                                                                                                                                                                                                                                                                     |  CREATE TABLE `tbl1` (   `c1` int(11) NOT NULL,   `c2` varchar(50) DEFAULT NULL,   PRIMARY KEY (`c1`) ) DEFAULT CHARSET = utf8mb4 ROW_FORMAT = DYNAMIC COMPRESSION = 'zstd_1.3.8' REPLICA_NUM = 1 BLOCK_SIZE = 16384 USE_BLOOM_FILTER = FALSE TABLET_SIZE = 134217728 PCTFREE = 0 | 1 row in set 修改主键 修改主键的语法如下： sql ALTER TABLE table_name DROP PRIMARY KEY,ADD PRIMARY KEY (column_name_list); 修改主键的示例如下： sql obclient> ALTER TABLE tbl1 DROP PRIMARY KEY,ADD PRIMARY KEY(c2); Query OK, 0 rows affected obclient [test]> SHOW CREATE TABLE tbl1;  Create Table                                                                                                                                                                                                                                                                 |  CREATE TABLE `tbl1` (   `c1` int(11) NOT NULL,   `c2` varchar(50) NOT NULL,   PRIMARY KEY (`c2`) ) DEFAULT CHARSET = utf8mb4 ROW_FORMAT = DYNAMIC COMPRESSION = 'zstd_1.3.8' REPLICA_NUM = 1 BLOCK_SIZE = 16384 USE_BLOOM_FILTER = FALSE TABLET_SIZE = 134217728 PCTFREE = 0 | 1 row in set 删除主键 删除主键的语法如下： sql ALTER TABLE table_name DROP PRIMARY KEY; 删除主键的示例如下： sql obclient> ALTER TABLE tbl1 DROP PRIMARY KEY; Query OK, 0 rows affected obclient> SHOW CREATE TABLE tbl1;  Create Table                                                                                                                                                                                                                                           |  CREATE TABLE `tbl1` (   `c1` int(11) NOT NULL,   `c2` varchar(50) NOT NULL ) DEFAULT CHARSET = utf8mb4 ROW_FORMAT = DYNAMIC COMPRESSION = 'zstd_1.3.8' REPLICA_NUM = 1 BLOCK_SIZE = 16384 USE_BLOOM_FILTER = FALSE TABLET_SIZE = 134217728 PCTFREE = 0 | 1 row in set 变更分区类型 OceanBase 数据库 MySQL 模式下变更分区类型的语法如下： sql ALTER TABLE table_name PARTITION BY (partition_definitions); 变更分区示例 示例 1：将 Hash 分区更改为 Key 分区方式。 sql obclient> CREATE TABLE tbl2(c1 INT, c2 DATETIME, PRIMARY KEY(c1, c2))  PARTITION BY HASH(c1) PARTITIONS 4; Query OK, 0 rows affected obclient [test]> SHOW CREATE TABLE tbl2;  Create Table                                                                                                                                                                                                                                                                                                                                                    |  CREATE TABLE `tbl2` (   `c1` int(11) NOT NULL,   `c2` datetime NOT NULL,   PRIMARY KEY (`c1`, `c2`) ) DEFAULT CHARSET = utf8mb4 ROW_FORMAT = DYNAMIC COMPRESSION = 'zstd_1.3.8' REPLICA_NUM = 1 BLOCK_SIZE = 16384 USE_BLOOM_FILTER = FALSE TABLET_SIZE = 134217728 PCTFREE = 0  partition by hash(c1) (partition ",
        "product": "oceanbase",
        "version": "4.1.0"
    },
    {
        "path": "/Users/zhangying/Desktop/oceanbase-doc-4.1.0/zh-CN/200.quickstart/500.experience-advanced-features-of-oceanbase/500.experience-ddl/100.experience-ddl-of-mysql-mode.md",
        "content": "p0, partition p1, partition p2, partition p3) | 1 row in set obclient> ALTER TABLE tbl2 PARTITION BY KEY(c1) PARTITIONS 10; Query OK, 0 rows affected obclient [test]> SHOW CREATE TABLE tbl2;  Create Table                                                                                                                                                                                                                                                                                                                                                                                                                                       |  CREATE TABLE `tbl2` (   `c1` int(11) NOT NULL,   `c2` datetime NOT NULL,   PRIMARY KEY (`c1`, `c2`) ) DEFAULT CHARSET = utf8mb4 ROW_FORMAT = DYNAMIC COMPRESSION = 'zstd_1.3.8' REPLICA_NUM = 1 BLOCK_SIZE = 16384 USE_BLOOM_FILTER = FALSE TABLET_SIZE = 134217728 PCTFREE = 0  partition by key(c1) (partition p0, partition p1, partition p2, partition p3, partition p4, partition p5, partition p6, partition p7, partition p8, partition p9) | 1 row in set 示例 2：将一级 Hash 分区表修改为模板化 Hash+Range 二级分区表。 sql obclient> ALTER TABLE tbl2         PARTITION BY HASH(c1)                 SUBPARTITION BY RANGE COLUMNS(c2)                 SUBPARTITION TEMPLATE(                 SUBPARTITION p1 VALUES LESS THAN ('2016-10-10'),                 SUBPARTITION p2 VALUES LESS THAN ('2116-3-30')) PARTITIONS 2; Query OK, 0 rows affected obclient> SHOW CREATE TABLE tbl2;  Create Table                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |  CREATE TABLE `tbl2` (   `c1` int(11) NOT NULL,   `c2` datetime NOT NULL,   PRIMARY KEY (`c1`, `c2`) ) DEFAULT CHARSET = utf8mb4 ROW_FORMAT = DYNAMIC COMPRESSION = 'zstd_1.3.8' REPLICA_NUM = 1 BLOCK_SIZE = 16384 USE_BLOOM_FILTER = FALSE TABLET_SIZE = 134217728 PCTFREE = 0  partition by hash(c1) subpartition by range columns(c2) subpartition template ( subpartition p1 values less than ('2016-10-10 00:00:00'), subpartition p2 values less than ('2116-03-30 00:00:00')) (partition p0, partition p1) | 1 row in set 示例 3：将 Hash + Range 二级分区表转为 Range Columns+Range Columns 分区。 sql obclient> ALTER TABLE tbl2    PARTITION BY RANGE COLUMNS(c1)     SUBPARTITION BY RANGE COLUMNS(c2)   (   PARTITION p0 VALUES LESS THAN (100)   (SUBPARTITION sp0 VALUES LESS THAN ('2020-01-01')   ,SUBPARTITION sp1 VALUES LESS THAN  ('2021-01-01')   ,SUBPARTITION sp2 VALUES LESS THAN ('2022-01-01')   ,SUBPARTITION sp3 VALUES LESS THAN  ('2023-01-01')   ),   PARTITION p1 VALUES LESS THAN (200)   (SUBPARTITION sp4 VALUES LESS THAN ('2020-01-01')   ,SUBPARTITION sp5 VALUES LESS THAN  ('2021-01-01')   ,SUBPARTITION sp6 VALUES LESS THAN ('2022-01-01')   ,SUBPARTITION sp7 VALUES LESS THAN  ('2023-01-01'))   ); Query OK, 0 rows affected obclient [test]> SHOW CREATE TABLE tbl2;  Create Table                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ",
        "product": "oceanbase",
        "version": "4.1.0"
    },
    {
        "path": "/Users/zhangying/Desktop/oceanbase-doc-4.1.0/zh-CN/200.quickstart/500.experience-advanced-features-of-oceanbase/500.experience-ddl/100.experience-ddl-of-mysql-mode.md",
        "content": "                                                                                                                         |  CREATE TABLE `tbl2` (   `c1` int(11) NOT NULL,   `c2` datetime NOT NULL,   PRIMARY KEY (`c1`, `c2`) ) DEFAULT CHARSET = utf8mb4 ROW_FORMAT = DYNAMIC COMPRESSION = 'zstd_1.3.8' REPLICA_NUM = 1 BLOCK_SIZE = 16384 USE_BLOOM_FILTER = FALSE TABLET_SIZE = 134217728 PCTFREE = 0  partition by range columns(c1) subpartition by range columns(c2) (partition p0 values less than (100) ( subpartition sp0 values less than ('2020-01-01 00:00:00'), subpartition sp1 values less than ('2021-01-01 00:00:00'), subpartition sp2 values less than ('2022-01-01 00:00:00'), subpartition sp3 values less than ('2023-01-01 00:00:00')), partition p1 values less than (200) ( subpartition sp4 values less than ('2020-01-01 00:00:00'), subpartition sp5 values less than ('2021-01-01 00:00:00'), subpartition sp6 values less than ('2022-01-01 00:00:00'), subpartition sp7 values less than ('2023-01-01 00:00:00'))) | 1 row in set 变更列类型 OceanBase 数据库 MySQL 模式下所支持的列类型的相关转换如下： * 字符类型列的数据类型转换，包括 CHAR、VARCHAR、TINYTEXT、TEXT 和 LONGTEXT。 * 数值类型列的数据类型转换，包括 TINYINT、SMALLINT、MEDIUMINT、INT 和 BIGINT。 * 二进制类型的数据类型转换，包括 BINARY、VARBINARY、BLOB、TINYBLOB、MEDIUMBLOB 和 LONGBLOB。 * 带精度的数据类型支持改变精度，包括 VARCHAR、FLOAT、DOUBLE 和 DECIMAL。 * 带精度的数据类型之间的转换，包括 FLOAT、DOUBLE 和 DECIMAL。 * 不同数据类型之间的转换，包括 INT、VARCHAR、DOUBLE、FLOAT 和 DECIMAL。  修改列类型的语法如下： sql ALTER TABLE table_name MODIFY column_name data_type; 修改列类型的示例 字符数据类型之间的转换示例 如下示例为修改字符数据类型列的数据类型并提升长度。 sql obclient> CREATE TABLE test01 (c1 INT PRIMARY KEY, c2 CHAR(10), c3 CHAR(10)); Query OK, 0 rows affected obclient> ALTER TABLE test01 MODIFY C2 VARCHAR(20); Query OK, 0 rows affected obclient> ALTER TABLE test01 MODIFY C2 VARCHAR(40); Query OK, 0 rows affected obclient> SHOW CREATE TABLE test01;  Create Table                                                                                                                                                                                                                                                                                                     |  CREATE TABLE `test01` (   `c1` int(11) NOT NULL,   `C2` varchar(40) DEFAULT NULL,   `c3` char(10) DEFAULT NULL,   PRIMARY KEY (`c1`) ) DEFAULT CHARSET = utf8mb4 ROW_FORMAT = DYNAMIC COMPRESSION = 'zstd_1.3.8' REPLICA_NUM = 1 BLOCK_SIZE = 16384 USE_BLOOM_FILTER = FALSE TABLET_SIZE = 134217728 PCTFREE = 0 | 1 row in set obclient> ALTER TABLE test01 MODIFY C2 TINYTEXT; Query OK, 0 rows affected obclient> ALTER TABLE test01 MODIFY C2 LONGTEXT; Query OK, 0 rows affected obclient> ALTER TABLE test01 MODIFY C3 CHAR(20); Query OK, 0 rows affected obclient> ALTER TABLE test01 MODIFY C3 VARCHAR(30); Query OK, 0 rows affected obclient> SHOW CREATE TABLE test01;  Create Table                                                                                                                                                                                                                                                                                                     |  CREATE TABLE `test01` (   `c1` int(11) NOT NULL,   `C2` longtext DEFAULT NULL,   `C3` varchar(30) DEFAULT NULL,   PRIMARY KEY (`c1`) ) DEFAULT CHARSET = utf8mb4 ROW_FORMAT = DYNAMIC COMPRESSION = 'zstd_1.3.8' REPLICA_NUM = 1 BLOCK_SIZE = 16384 USE_BLOOM_FILTER = FALSE TABLET_SIZE = 134217728 PCTFREE = 0 | 1 row in set 数值数据类型之间的转换示例 示例 1：修改整数类型列的数据类型并提升长度。  sql obclient> CREATE TABLE test02 (id INT PRIMARY KEY, name VARCHAR(10),age TINYINT, description VARCHAR(65525)); Query OK, 0 rows affected obclient> ALTER TABLE test02 MODIFY age SMALLINT; Query OK, 0 rows affected obclient> SHOW CREATE TABLE test02;  Create Table                                                                                                                                                                                                                                                                               ",
        "product": "oceanbase",
        "version": "4.1.0"
    },
    {
        "path": "/Users/zhangying/Desktop/oceanbase-doc-4.1.0/zh-CN/200.quickstart/500.experience-advanced-features-of-oceanbase/500.experience-ddl/100.experience-ddl-of-mysql-mode.md",
        "content": "                                                               |  CREATE TABLE `test02` (   `id` int(11) NOT NULL,   `name` varchar(10) DEFAULT NULL,   `age` smallint(6) DEFAULT NULL,   `description` varchar(65525) DEFAULT NULL,   PRIMARY KEY (`id`) ) DEFAULT CHARSET = gbk ROW_FORMAT = DYNAMIC COMPRESSION = 'zstd_1.3.8' REPLICA_NUM = 1 BLOCK_SIZE = 16384 USE_BLOOM_FILTER = FALSE TABLET_SIZE = 134217728 PCTFREE = 0 | 1 row in set obclient> ALTER TABLE test02 MODIFY age INT; Query OK, 0 rows affected obclient> SHOW CREATE TABLE test02;  Create Table                                                                                                                                                                                                                                                                                                                                              |  CREATE TABLE `test02` (   `id` int(11) NOT NULL,   `name` varchar(10) DEFAULT NULL,   `age` int(11) DEFAULT NULL,   `description` varchar(65525) DEFAULT NULL,   PRIMARY KEY (`id`) ) DEFAULT CHARSET = gbk ROW_FORMAT = DYNAMIC COMPRESSION = 'zstd_1.3.8' REPLICA_NUM = 1 BLOCK_SIZE = 16384 USE_BLOOM_FILTER = FALSE TABLET_SIZE = 134217728 PCTFREE = 0 | 1 row in set obclient> ALTER TABLE test02 MODIFY age BIGINT; Query OK, 0 rows affected obclient> SHOW CREATE TABLE test02;  Create Table                                                                                                                                                                                                                                                                                                                                              |  CREATE TABLE `test02` (   `id` int(11) NOT NULL,   `name` varchar(10) DEFAULT NULL,   `age` bigint(20) DEFAULT NULL,   `description` varchar(65525) DEFAULT NULL,   PRIMARY KEY (`id`) ) DEFAULT CHARSET = gbk ROW_FORMAT = DYNAMIC COMPRESSION = 'zstd_1.3.8' REPLICA_NUM = 1 BLOCK_SIZE = 16384 USE_BLOOM_FILTER = FALSE TABLET_SIZE = 134217728 PCTFREE = 0 | 1 row in set 示例 2：修改带精度的数据类型列的数据类型和长度。  sql obclient> CREATE TABLE test03(c1 INT, c2 FLOAT(8,0), c3 FLOAT(8,0), UNIQUE(c2, c3)); Query OK, 0 rows affected obclient> ALTER TABLE test03 MODIFY c2 FLOAT(5,0); Query OK, 0 rows affected obclient> ALTER TABLE test03 MODIFY c2 DOUBLE(10,0); Query OK, 0 rows affected obclient> ALTER TABLE test03 MODIFY c2 DOUBLE(5,0); Query OK, 0 rows affected obclient> ALTER TABLE test03 MODIFY c2 DECIMAL(20, 4); Query OK, 0 rows affected obclient> SHOW CREATE TABLE test03;  Create Table                                                                                                                                                                                                                                                                                                                                              |  CREATE TABLE `test03` (   `c1` int(11) DEFAULT NULL,   `c2` decimal(20,4) DEFAULT NULL,   `c3` float(8,0) DEFAULT NULL,   UNIQUE KEY `c2` (`c2`, `c3`) BLOCK_SIZE 16384 LOCAL ) DEFAULT CHARSET = utf8mb4 ROW_FORMAT = DYNAMIC COMPRESSION = 'zstd_1.3.8' REPLICA_NUM = 1 BLOCK_SIZE = 16384 USE_BLOOM_FILTER = FALSE TABLET_SIZE = 134217728 PCTFREE = 0 | 1 row in set 二进制类型数据类型的转换示例 sql obclient> CREATE TABLE test04 (c1 TINYBLOB, c2 BINARY(64)); Query OK, 0 rows affected obclient> ALTER TABLE test04 MODIFY c1 BLOB; Query OK, 0 rows affected obclient> ALTER TABLE test04 MODIFY c1 BINARY(256); Query OK, 0 rows affected obclient> SHOW CREATE TABLE test04;  Create Table                                                                                                                                                                                                                                                        |  CREATE TABLE `test04` (   `c1` binary(256) DEFAULT NULL,   `c2` binary(64) DEFAULT NULL ) DEFAULT CHARSET = utf8mb4 ROW_FORMAT = DYNAMIC COMPRESSION = 'zstd_1.3.8'",
        "product": "oceanbase",
        "version": "4.1.0"
    },
    {
        "path": "/Users/zhangying/Desktop/oceanbase-doc-4.1.0/zh-CN/200.quickstart/500.experience-advanced-features-of-oceanbase/500.experience-ddl/100.experience-ddl-of-mysql-mode.md",
        "content": " REPLICA_NUM = 1 BLOCK_SIZE = 16384 USE_BLOOM_FILTER = FALSE TABLET_SIZE = 134217728 PCTFREE = 0 | 1 row in set obclient> CREATE TABLE test05 (id INT PRIMARY KEY, name TINYTEXT,age INT, description VARCHAR(65535)); Query OK, 0 rows affected obclient> ALTER TABLE test05 MODIFY name VARCHAR(256); Query OK, 0 rows affected obclient> SHOW CREATE TABLE test05;  Create Table                                                                                                                                                                                                                                                                                                                                                     |  CREATE TABLE `test05` (   `id` int(11) NOT NULL,   `name` varchar(256) DEFAULT NULL,   `age` int(11) DEFAULT NULL,   `description` varchar(65535) DEFAULT NULL,   PRIMARY KEY (`id`) ) DEFAULT CHARSET = utf8mb4 ROW_FORMAT = DYNAMIC COMPRESSION = 'zstd_1.3.8' REPLICA_NUM = 1 BLOCK_SIZE = 16384 USE_BLOOM_FILTER = FALSE TABLET_SIZE = 134217728 PCTFREE = 0 | 1 row in set 整数型数据与字符型数据的转换示例 sql obclient> CREATE TABLE test06 (c1 INT); Query OK, 0 rows affected obclient> ALTER TABLE test06 MODIFY c1 VARCHAR(64); Query OK, 0 rows affected obclient [test]> SHOW CREATE TABLE test06;  Create Table                                                                                                                                                                                                                        |  CREATE TABLE `test06` (   `c1` varchar(64) DEFAULT NULL ) DEFAULT CHARSET = utf8mb4 ROW_FORMAT = DYNAMIC COMPRESSION = 'zstd_1.3.8' REPLICA_NUM = 1 BLOCK_SIZE = 16384 USE_BLOOM_FILTER = FALSE TABLET_SIZE = 134217728 PCTFREE = 0 | 1 row in set obclient> CREATE TABLE test07 (c1 VARCHAR(32)); Query OK, 0 rows affected obclient> ALTER TABLE test07 MODIFY c1 INT; Query OK, 0 rows affected obclient [test]> SHOW CREATE TABLE test07;  Create Table                                                                                                                                                                                                                    |  CREATE TABLE `test07` (   `c1` int(11) DEFAULT NULL ) DEFAULT CHARSET = utf8mb4 ROW_FORMAT = DYNAMIC COMPRESSION = 'zstd_1.3.8' REPLICA_NUM = 1 BLOCK_SIZE = 16384 USE_BLOOM_FILTER = FALSE TABLET_SIZE = 134217728 PCTFREE = 0 | 1 row in set 修改表或者列的字符集和字符序（COLLATION） 修改表的字符集和字符序 OceanBase 数据库 MySQL 模式下修改表的字符序和字符集的语法如下： sql ALTER TABLE table_name CHARACTER SET = charset_name COLLATE =collate_name;  说明 此语法只修改表所在的 Schema 上的字符序和字符集，只对之后新增加的表起作用。  示例如下： sql obclient> CREATE TABLE test_collation (c1 INT PRIMARY KEY, c2 VARCHAR(32), c3 VARCHAR(32), UNIQUE KEY idx_test_collation_c2(c2)); Query OK, 0 rows affected obclient> SHOW CREATE TABLE test_collation;  Create Table                                                                                                                                                                                                                                                                                                                                                                                    |  CREATE TABLE `test_collation` (   `c1` int(11) NOT NULL,   `c2` varchar(32) DEFAULT NULL,   `c3` varchar(32) DEFAULT NULL,   PRIMARY KEY (`c1`),   UNIQUE KEY `idx_test_collation_c2` (`c2`) BLOCK_SIZE 16384 LOCAL ) DEFAULT CHARSET = utf8mb4 ROW_FORMAT = DYNAMIC COMPRESSION = 'zstd_1.3.8' REPLICA_NUM = 1 BLOCK_SIZE = 16384 USE_BLOOM_FILTER = FALSE TABLET_SIZE = 134217728 PCTFREE = 0 | 1 row in set obclient [test]> ALTER TABLE test_collation CHARACTER SET = utf16 COLLATE = utf16_general_ci; Query OK, 0 rows affected obclient [test]> SHOW CREATE TABLE test_collation;  Create Table                                                                                                                                                                                                  ",
        "product": "oceanbase",
        "version": "4.1.0"
    },
    {
        "path": "/Users/zhangying/Desktop/oceanbase-doc-4.1.0/zh-CN/200.quickstart/500.experience-advanced-features-of-oceanbase/500.experience-ddl/100.experience-ddl-of-mysql-mode.md",
        "content": "                                                                                                                                                                                                                            |  CREATE TABLE `test_collation` (   `c1` int(11) NOT NULL,   `c2` varchar(32) CHARACTER SET utf8mb4 DEFAULT NULL,   `c3` varchar(32) CHARACTER SET utf8mb4 DEFAULT NULL,   PRIMARY KEY (`c1`),   UNIQUE KEY `idx_test_collation_c2` (`c2`) BLOCK_SIZE 16384 LOCAL ) DEFAULT CHARSET = utf16 ROW_FORMAT = DYNAMIC COMPRESSION = 'zstd_1.3.8' REPLICA_NUM = 1 BLOCK_SIZE = 16384 USE_BLOOM_FILTER = FALSE TABLET_SIZE = 134217728 PCTFREE = 0 | 1 row in set 修改表中已有数据的字符集和字符序 OceanBase 数据库 MySQL 模式下修改表中已有数据的字符集和字符序的语法如下： sql ALTER TABLE table_name CONVERT TO CHARACTER SET charset_name COLLATE collate_name;  说明 此语法不仅修改了表上已有数据的字符集和字符序，也会修改表所在的 Schema 上的字符序和字符集。   示例如下： sql obclient> ALTER TABLE test_collation CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_bin; Query OK, 0 rows affected 修改列的字符集和字符序 OceanBase 数据库 MySQL 模式下修改列的字符序和字符集的语法如下： sql ALTER TABLE table_name MODIFY COLUMN column_name data_type COLLATE collate_name; 示例如下： sql obclient> ALTER TABLE test_collation MODIFY COLUMN c2 VARCHAR(32) COLLATE utf8mb4_bin; Query OK, 0 rows affected obclient> SHOW CREATE TABLE test_collation;  Create Table                                                                                                                                                                                                                                                                                                                                                                                                                                                  |  CREATE TABLE `test_collation` (   `c1` int(11) NOT NULL,   `c2` varchar(32) COLLATE utf8mb4_bin DEFAULT NULL,   `c3` varchar(32) COLLATE utf8mb4_bin DEFAULT NULL,   PRIMARY KEY (`c1`),   UNIQUE KEY `idx_test_collation_c2` (`c2`) BLOCK_SIZE 16384 LOCAL ) DEFAULT CHARSET = utf8mb4 COLLATE = utf8mb4_bin ROW_FORMAT = DYNAMIC COMPRESSION = 'zstd_1.3.8' REPLICA_NUM = 1 BLOCK_SIZE = 16384 USE_BLOOM_FILTER = FALSE TABLET_SIZE = 134217728 PCTFREE = 0 | 1 row in set",
        "product": "oceanbase",
        "version": "4.1.0"
    },
    {
        "path": "/Users/zhangying/Desktop/oceanbase-doc-4.1.0/zh-CN/200.quickstart/500.experience-advanced-features-of-oceanbase/100.experience-scalable-oltp/200.experience-the-hot-row-update-capability-of-oceanbase-database.md",
        "content": "体验 OceanBase 数据库热点行更新能力 随着在线交易、电商行业的发展，业务系统的热点并发压力逐渐成为一种挑战。热点账户短时间内余额大量更新，或者热门商品在营销活动中限时抢购，都是这种场景的直接体现。热点更新的本质是短时间内对数据库中的同一行数据的某些字段值进行高并发的修改（余额，库存等），这其中的瓶颈主要在于关系型数据库为了保持事务一致性，对数据行的更新都需要经过 “加锁->更新->写日志提交->释放锁” 的过程，而这个过程实质上是串行的。所以，提高热点行更新能力的关键在于如何尽可能缩短持有锁的时间。 虽然学术界很早就提出了 “提前解行锁（Early Lock Release）” 的方案（即 ELR），但是因为 ELR 的异常处理场景非常复杂，业界很少有成熟的工业实现。OceanBase 数据库在这个问题上通过持续的探索，提出了一种基于分布式架构的实现方式，提升类似业务场景中单行并发更新的能力，作为 OceanBase 数据库 “可扩展的 OLTP” 中的关键能力之一。 本篇文章中，我们将通过构造一个多并发单行更新的场景，介绍 OceanBase 数据库 ELR 特性的使用方法和效果对比。因为是在多并发压力场景下验证，我们建议至少使用和本例中相同的节点规格进行体验和验证，达到更好的效果。关于 OceanBase 数据库 ELR 的设计和原理实现，因其较为复杂，本文暂不做详细讨论。 本例中我们使用一台 16C-128GB 配置的节点，下面我们来分步骤体验 OceanBase 数据库 ELR 特性。 步骤一：创建测试表，插入测试数据 首先我们在测试库中创建一张表，并插入测试数据。 sql CREATE TABLE `sbtest1` (    `id` int(11) NOT NULL AUTO_INCREMENT,    `k` int(11) NOT NULL DEFAULT '0',    `c` char(120) NOT NULL DEFAULT '',    `pad` char(60) NOT NULL DEFAULT '',    PRIMARY KEY (`id`) ); INSERT INTO sbtest1 VALUES(1,0,'aa','aa'); 本例中我们通过类似 UPDATE sbtest1  SET k=k+1 WHERE id=1 的语句，以主键查询方式针对 k 列进行并发更新，您也可以插入更多数据进行测试，但因为是针对单行并发的压测，对整体结果基本没有影响。 步骤二：构造并发更新场景 本例中，我们使用 Python 多线程的方式来模拟并发更新，同时启动 50 个 Thread，每个 Thread 并发的对 id=1 的行数据将 k 字段值 +1。您在自己搭建的环境中也可以直接使用下面的脚本 ob_elr.py 进行测试，只需要将脚本中的数据库连接信息修改一下即可使用。 ```python !/usr/bin/env python3 from concurrent.futures import ThreadPoolExecutor import pymysql import time import threading database connection info config = {     'user': 'root@test',     'password': '****',     'host': 'xxx.xxx.xxx.xxx',     'port': 2881,     'database': 'test' } parallel thread and updates in each thread parallel = 50 batch_num = 2000 update query def update_elr():     update_hot_row = (\"update sbtest1 set k=k+1 where id=1\")     cnx = pymysql.connect(config)     cursor = cnx.cursor()     for i in range(0,batch_num):         cursor.execute(update_hot_row)     cursor.close()     cnx.close() start=time.time() with ThreadPoolExecutor(max_workers=parallel) as pool:     for i in range(parallel):         pool.submit(update_elr) end = time.time() elapse_time = round((end-start),2) print('Parallel Degree:',parallel) print('Total Updates:',parallelbatch_num) print('Elapse Time:',elapse_time,'s') print('TPS on Hot Row:' ,round(parallelbatch_num/elapse_time,2),'/s') ``` 步骤三：默认配置下执行测试 作为对比参照，我们先在默认不开启 ELR 的情况下测试，在测试机器上直接执行 ob_elr.py 脚本。 本例中我们采用 50 并发数，总计更新 100000 次。 shell ./ob_elr.py 执行完成，测试脚本输出执行时间和 TPS： shell [root@obce00 ~]# ./ob_elr.py Parallel Degree: 50 Total Updates: 100000 Elapse Time: 54.5 s TPS on Hot Row: 1834.86 /s 测试结果如下： 在不开启 ELR 的默认配置下，本例测试环境中，单行并发更新 TPS 为1834.86/s。 步骤四：打开 OceanBase 数据库 ELR 配置 接下来我们开启 OceanBase 数据库的热点行功能，首先需要使用 root 用户登录集群的 sys 租户。 shell [root@obce00 ~]# obclient -h127.0.0.1 -P2881 -uroot@sys  -Doceanbase -A -p -c 然后进行如下两个参数的设置。其中 enable_early_lock_release 参数的生效范围，既可以指定具体租户，也可以指定全部租户，即 tenant=all。 sql ALTER SYSTEM SET _max_elr_dependent_trx_count = 1000; ALTER SYSTEM SET enable_early_lock_release=true tenant= test; 步骤五：开启 OceanBase 数据库 ELR 进行测试 开启热点行功能后，我们再次执行测试。在执行前我们先查看表 sbtest 中 id=1 的记录，k 字段值为 100000，这是因为刚刚执行了一轮默认配置下的 100000 次的更新。 shell SELECT * FROM sbtest1 WHERE id=1;  k       pad |  100000  aa  | 1 row in set 接下来我们在测试机器上再次执行 ob_elr.py。仍然采用 50 并发数，总计更新 100000 次。 shell ./ob_elr.py 执行完成，测试脚本会输出执行时间和 TPS： shell [root@obce00 ~]# ./ob_elr.py Parallel Degree: 50 Total Updates: 100000 Elapse Time: 12.16 s TPS on Hot Row: 8223.68 /s 测试结果如下： OceanBase 数据库在开启 ELR 提前解行锁能力后，单行更新的 TPS 达到 8223.68/s，相比默认配置下提升 4.5 倍左右。 同时我们可以看到表 sbtest1 的 k 值为 200000，即本次也更新了 100000 次。 sql SELECT * FROM sbtest1 WHERE id=1;  k       pad |  200000  aa  | 1 row in set 本例中仅介绍了单行并发更新的场景，OceanBase 数据库的 ELR 能力还支持多语句事务的并发更新，根据语句数量和场景差异，同样可以获得显著的性能提升。 此外 OceanBase 数据库的 ELR 还可以应用在多地部署高网络延迟的场景中，例如单个事务在默认场景下 30 ms，并发下开启 ELR 可以获得近百倍的 TPS 吞吐量提升。 由于 OceanBase 数据库的日志协议基于 Multi-Paxos 构建，并且优化了 2PC 提交过程，OceanBase 数据库在开启 ELR 后，如果发生节点宕机重启、Leader 切换，仍然可以保证事务的一致性。您可以尝试构造这些实验进行体验。",
        "product": "oceanbase",
        "version": "4.1.0"
    },
    {
        "path": "/Users/zhangying/Desktop/oceanbase-doc-4.1.0/zh-CN/200.quickstart/500.experience-advanced-features-of-oceanbase/100.experience-scalable-oltp/100.run-the-tpc-c-test-on-oceanbase-database.md",
        "content": "在 OceanBase 数据库上进行 TPC-C 测试 TPC-C 是 TPC 组织（Transaction Processing Performance Council）推出的一系列性能测试标准中的一款，自推出以来，一直是数据库业界性能测试的重要参考，全世界各大数据库厂商都向 TPC 委员会提交了测试结果，以期望在 TPC-C 测试的排行榜上取得更好的成绩。OceanBase 数据库在 2019 年和 2020 年两次刷新了 TPC-C 的世界纪录，成为榜单上首个分布式关系型数据库。 在本篇文章中，通过在 OceanBase 数据库上运行 TPC-C 测试的方式，体验 OceanBase 数据库的 OLTP 能力。 关于 TPC-C 数据库模型 TPC-C Benchmark 规定了数据库的初始状态，其中 ITEM 表中包含固定的 10 万种商品，而仓库的数量可根据测试规模进行调整，假设 WAREHOUSE 表中有 W 条记录，那么： - STOCK 表中应有 W×10 万条记录（每个仓库对应 10 万种商品的库存数据）。 - DISTRICT 表中应有 W×10 条记录（每个仓库为 10 个地区提供服务）。 - CUSTOMER 表中应有 W×10×3000 条记录（每个地区有 3000 个客户）。 - HISTORY 表中应有 W×10×3000 条记录（每个客户一条交易历史）。 - ORDER 表中应有 W×10×3000 条记录（每个地区 3000 个订单），并且最后生成的 900 个订单将被添加到 NEW-ORDER 表中，每个订单随机生成 5~15 条 ORDER-LINE 记录。 在测试过程中，每一个地区（DISTRICT）都有一个对应的终端（Terminal），模拟为用户提供服务。在每个终端的生命周期内，要循环往复地执行各类事务，当终端执行完一个事务的周期后，就进入下一个事务的周期。 客户下单后，包含若干个订单明细（ORDER-LINE）的订单（ORDER）被生成，并被加入新订单（NEW-ORDER）列表。 客户支付订单会产生交易历史（HISTORY）。每个订单（ORDER）平均包含 10 条订单项（ORDER-LINE），其中 1% 需要从远程仓库中获取，这些就是 TPC-C 模型中的 9 个数据表。 事务类型 该 Benchmark 包含 5 类事务： - NewOrder：新订单请求从某一仓库中随机选取 5~15 件商品，创建新订单。其中 1% 的事务需要回滚（即 err）。一般地，新订单请求不可能超出全部事务请求的 45%。 - Payment：订单付款更新客户账户余额，反映其支付情况。在全部事务请求中占比 43% 。 - OrderStatus：最近订单查询随机选择一个用户，查询其最近一条订单，显示该订单内的每个商品状态。在全部事务请求中占比 4%。 - Delivery：配送模拟批处理交易，更新该订单用户的余额，把发货单从 NewOrder 中删除。在全部事务请求中占比 4%。 - StockLevel：库存缺货状态分析，在全部事务请求中占比 4%。 环境准备 OceanBase 集群 根据部署的 OceanBase 集群类型的差异以不同的方式观察 OceanBase 数据库的表现，如果是按照快速开始章节中创建的单节点 OceanBase 集群，那么本文中可以看到 OceanBase 数据库在单机形态下的运行情况。如果希望体验 OceanBase 数据库分布式架构的 Scalable OLTP 能力，那么建议采用至少三节点的 OceanBase 集群进行测试。 本例中使用的租户模式为 MySQL 模式，租户名为 test，您可以创建自己的租户，具体步骤详见 体验多租户特性。 安装 BenchmarkSQL TPC 组织为 TPC-C 定义了严格、详细的测试标准。一般情况下开发者如果想要模拟 TPC-C 的场景进行测试，可以使用目前常用的开源测试工具。例如本文中使用的 BenchmarkSQL，下载请访问 BenchmarkSQL 官方下载地址。   注意 测试环境需要有 Java 运行环境，且版本不低于 V1.8.0。  适配 Benchmark SQL5 由于 Benchmark SQL5 不支持 OceanBase 数据库的 TPC-C 测试，本节将详细介绍如何通过修改 BenchMarkSQL5 部分源码支持 OceanBase 数据库。 1. 修改 benchmarksql-5.0/src/client/jTPCC.java 文件，增加 OceanBase 数据库相关内容。    java    if (iDB.equals(\"firebird\"))            dbType = DB_FIREBIRD;        else if (iDB.equals(\"oracle\"))            dbType = DB_ORACLE;        else if (iDB.equals(\"postgres\"))            dbType = DB_POSTGRES;        else if (iDB.equals(\"oceanbase\"))            dbType = DB_OCEANBASE;        else        {            log.error(\"unknown database type '\" + iDB + \"'\");            return;        }    修改 benchmarksql-5.0/src/client/jTPCCConfig.java 文件，增加 OceanBase 数据库类型。    java    public final static int             DB_UNKNOWN = 0,    DB_FIREBIRD = 1,    DB_ORACLE = 2,    DB_POSTGRES = 3,    DB_OCEANBASE = 4; 2. 修改 benchmarksql-5.0/src/client/jTPCCConnection.java 文件，在 SQL 子查询增加 AS L 别名。    java    default:                stmtStockLevelSelectLow = dbConn.prepareStatement(                    \"SELECT count(*) AS low_stock FROM (\" +                    \"    SELECT s_w_id, s_i_id, s_quantity \" +                    \"        FROM bmsql_stock \" +                    \"        WHERE s_w_id = ? AND s_quantity < ? AND s_i_id IN (\" +                    \"            SELECT ol_i_id \" +                    \"                FROM bmsql_district \" +                    \"                JOIN bmsql_order_line ON ol_w_id = d_w_id \" +                    \"                 AND ol_d_id = d_id \" +                    \"                 AND ol_o_id >= d_next_o_id - 20 \" +                    \"                 AND ol_o_id < d_next_o_id \" +                    \"                WHERE d_w_id = ? AND d_id = ? \" +                    \"        ) \" +                    \"    )AS L\");                break; 3. 重新编译修改后的源码。    shell    [oceanbase@testdrier test]# cd benchmarksql-5.0    [oceanbase@testdrier benchmarksql-5.0]# ant 4. 修改文件：benchmarksql-5.0/run/funcs.sh，添加 OceanBase 数据库类型。    java    function setCP()    {       case \"$(getProp db)\" in    firebird)        cp=\"../lib/firebird/*:../lib/*\"        ;;    oracle)        cp=\"../lib/oracle/*\"        if [ ! -z \"${ORACLE_HOME}\" -a -d ${ORACLE_HOME}/lib ] ; then     cp=\"${cp}:${ORACLE_HOME}/lib/*\"        fi        cp=\"${cp",
        "product": "oceanbase",
        "version": "4.1.0"
    },
    {
        "path": "/Users/zhangying/Desktop/oceanbase-doc-4.1.0/zh-CN/200.quickstart/500.experience-advanced-features-of-oceanbase/100.experience-scalable-oltp/100.run-the-tpc-c-test-on-oceanbase-database.md",
        "content": "}:../lib/*\"        ;;    postgres)        cp=\"../lib/postgres/*:../lib/*\"        ;;    oceanbase)        cp=\"../lib/oceanbase/*:../lib/*\"        ;;       esac       myCP=\".:${cp}:../dist/*\"       export myCP    }    ...省略    case \"$(getProp db)\" in       firebirdpostgres|oceanbase)       ;;       \"\") echo \"ERROR: missing db= config option in ${PROPS}\" >&2       exit 1       ;;       *)  echo \"ERROR: unsupported database type 'db=$(getProp db)' in ${PROPS}\" >&2       exit 1       ;;    esac 5. 修改 benchmarksql-5.0/run/runDatabaseBuild.sh 。    java    AFTER_LOAD=\"indexCreates foreignKeys extraHistID buildFinish\"    # 修改为：    AFTER_LOAD=\"indexCreates buildFinish\" 修改配置文件 配置文件 props.ob 在 BenchmarkSQL 的 run/  目录下：    java    db=oceanbase    driver=com.mysql.jdbc.Driver    conn=jdbc:mysql://127.0.0.1:2881/tpccdb?useUnicode=true&characterEncoding=utf-8&rewriteBatchedStatements=true&allowMultiQueries=true    user=root@test    password=****    warehouses=10    loadWorkers=2    //fileLocation=/data/temp/    terminals=10    //To run specified transactions per terminal- runMins must equal zero    runTxnsPerTerminal=0    //To run for specified minutes- runTxnsPerTerminal must equal zero    runMins=10    //Number of total transactions per minute    limitTxnsPerMin=0    //Set to true to run in 4.x compatible mode. Set to false to use the    //entire configured database evenly.    terminalWarehouseFixed=true    //The following five values must add up to 100    newOrderWeight=45    paymentWeight=43    orderStatusWeight=4    deliveryWeight=4    stockLevelWeight=4    // Directory name to create for collecting detailed result data.    // Comment this out to suppress.    resultDirectory=my_result_%tY-%tm-%td_%tH%tM%tS    osCollectorScript=./misc/os_collector_linux.py    osCollectorInterval=1    //osCollectorSSHAddr=user@dbhost    //osCollectorDevices=net_eth0 blk_sda  说明 db：指定数据库类型。此处保持和模板一致即可。driver：驱动程序文件，推荐使用 MySQL 的 JDBC 驱动：mysql-connector-java-5.1.47，驱动下载地址。conn：此处的 IP 建议填写 OceanBase Server 的 IP，端口为 OceanBase Server 部署端口，其他部分保持和模板一致。user & password：根据环境中使用的用户名、租户名以及密码即可。如果环境中有多个 OceanBase 集群，则 user 的格式建议为 {user_name}@{tenant_name}#{cluster_name}。warehouses：指定仓库数，仓库数决定性能测试的成绩。如果希望针对多节点的 OceanBase 集群进行测试，建议选择 1000 仓以上。如果机器配置有限，可以选择 100 仓进行测试。loadWorkers：指定仓库数据加载时的并发。如果机器配置较高，该值可以设置大一些，例如 100。如果机器配置有限，该值需要设置小一些，如 10 并发。过高的并发可能会导致内存消耗太快，出现报错，导致数据加载需要重新进行。terminals：指定性能压测时的并发数。建议并发数不要高于仓库数 * 10。否则，会有不必要的锁等待。在生产环境中，建议将此参数设置为最多 1000。在测试环境中，建议从 100 开始。runMins：指定性能测试持续的时间。时间越久，越能考验数据库的性能和稳定性。建议不要少于 10 分钟，生产环境中机器建议不少于 1 小时。  数据准备 创建 tpccdb 数据库 在测试租户 test 中，创建本次测试的数据库 tpccdb： sql CREATE DATABASE tpccdb; 创建表 建表脚本通常放在 benchmarskSQL 的 run/sql.common 下或者其他指定目录下。建表脚本如下，采用分区表方式创建，大部分表按照仓库 ID 做 HASH 分区。分区数取决于要测试的数据规模和机器数。 如果集群只有 1 台或 3 台机器，分区数设置 9 个即可。如果是 5000 仓以上，或者集群中节点数较多，则分区数可以调整到 99。 sql [root@obce-0000 run]# cat sql.common/tableCreates_parts.sql create table bmsql_config ( cfg_name    varchar(30) primary key, cfg_value   varchar(50) ); -- drop tablegroup tpcc_group; create tablegroup tpcc_group binding true partition by hash partitions 9; create table bmsql_warehouse (    w_id        integer   not null,    w_ytd       decimal(12,2),    w_tax       decimal(4,4),    w_name      varchar(10),    w_street_1  varchar(20),    w_street_2  varchar(20),    w_city      varchar(20),    w_state     char(2),    w_zip       char(9),    primary key(w_id) )tablegroup='tpcc_group' partition by hash(w_id) partitions 9; create table bmsql_district (    d_w_id       integer       not null,    d_id         integer       not null,    d_ytd        decimal(12,2),    d_tax        decimal(4,4),    d_next_o_id  integer,    d_name       varchar(10),    d_street_1   varchar(20),    d_street_2   varchar(20),    d_city       varchar(20),    d_state      char(2),    d_zip        char(9),    PRIMARY KEY (d_w_id, d_id) )tablegroup='tpcc_group' partition by hash(d_w_id) partitions 9; create table bmsql_customer (    c_w_id         integer        not null,    c_d_id         integer        not",
        "product": "oceanbase",
        "version": "4.1.0"
    },
    {
        "path": "/Users/zhangying/Desktop/oceanbase-doc-4.1.0/zh-CN/200.quickstart/500.experience-advanced-features-of-oceanbase/100.experience-scalable-oltp/100.run-the-tpc-c-test-on-oceanbase-database.md",
        "content": " null,    c_id           integer        not null,    c_discount     decimal(4,4),    c_credit       char(2),    c_last         varchar(16),    c_first        varchar(16),    c_credit_lim   decimal(12,2),    c_balance      decimal(12,2),    c_ytd_payment  decimal(12,2),    c_payment_cnt  integer,    c_delivery_cnt integer,    c_street_1     varchar(20),    c_street_2     varchar(20),    c_city         varchar(20),    c_state        char(2),    c_zip          char(9),    c_phone        char(16),    c_since        timestamp,    c_middle       char(2),    c_data         varchar(500),    PRIMARY KEY (c_w_id, c_d_id, c_id) )tablegroup='tpcc_group' partition by hash(c_w_id) partitions 9; create table bmsql_history (    hist_id  integer,    h_c_id   integer,    h_c_d_id integer,    h_c_w_id integer,    h_d_id   integer,    h_w_id   integer,    h_date   timestamp,    h_amount decimal(6,2),    h_data   varchar(24) )tablegroup='tpcc_group' partition by hash(h_w_id) partitions 9; create table bmsql_new_order (    no_w_id  integer   not null ,    no_d_id  integer   not null,    no_o_id  integer   not null,    PRIMARY KEY (no_w_id, no_d_id, no_o_id) )tablegroup='tpcc_group' partition by hash(no_w_id) partitions 9; create table bmsql_oorder (    o_w_id       integer      not null,    o_d_id       integer      not null,    o_id         integer      not null,    o_c_id       integer,    o_carrier_id integer,    o_ol_cnt     integer,    o_all_local  integer,    o_entry_d    timestamp,    PRIMARY KEY (o_w_id, o_d_id, o_id) )tablegroup='tpcc_group' partition by hash(o_w_id) partitions 9; create table bmsql_order_line (    ol_w_id         integer   not null,    ol_d_id         integer   not null,    ol_o_id         integer   not null,    ol_number       integer   not null,    ol_i_id         integer   not null,    ol_delivery_d   timestamp,    ol_amount       decimal(6,2),    ol_supply_w_id  integer,    ol_quantity     integer,    ol_dist_info    char(24),    PRIMARY KEY (ol_w_id, ol_d_id, ol_o_id, ol_number) )tablegroup='tpcc_group' partition by hash(ol_w_id) partitions 9; create table bmsql_item (    i_id     integer      not null,    i_name   varchar(24),    i_price  decimal(5,2),    i_data   varchar(50),    i_im_id  integer,    PRIMARY KEY (i_id) ); create table bmsql_stock (    s_w_id       integer       not null,    s_i_id       integer       not null,    s_quantity   integer,    s_ytd        integer,    s_order_cnt  integer,    s_remote_cnt integer,    s_data       varchar(50),    s_dist_01    char(24),    s_dist_02    char(24),    s_dist_03    char(24),    s_dist_04    char(24),    s_dist_05    char(24),    s_dist_06    char(24),    s_dist_07    char(24),    s_dist_08    char(24),    s_dist_09    char(24),    s_dist_10    char(24),    PRIMARY KEY (s_w_id, s_i_id) )tablegroup='tpcc_group' use_bloom_filter=true partition by hash(s_w_id) partitions 9; 运行如下命令建表。 shell ./runSQL.sh props.ob sql.common/tableCreates_parts.sql 加载数据 加载数据即数据初始化，加载数据的速度，取决于机器配置，配置越高的机器，加载数据的速度越快。 shell ./runLoader.sh props.ob 加载数据的 INSERT SQL 使用了 Batch Insert 特性，这点是在 props.ob 里的 JDBC URL 里指定的。开启该特性的写入性能会有明显提升。 创建索引 当数据初始化完成后，登录到集群的 test 租户，在 tpccdb 中补充创建如下两个索引。 sql [root@obce-0000 run]# cat sql.common/indexCreates.sql create index bmsql_customer_idx1   on  bmsql_customer (c_w_id, c_d_id, c_last, c_first) local; create  index bmsql_oorder_idx1   on  bmsql_oorder (o_w_id, o_d_id, o_carrier_id, o_id) local; 开始测试 在开始性能测试之前，建议您先登录到对应租户做一次集群合并（major freeze），获得更好的测试结果。您可以通过如下的方式手动触发合并，这个过程并不是必须的。 sql obclient[oceanbase]> ALTER SYSTEM MAJOR FREEZE; 当看到如下查询返回 IDLE 时，表示合并完成。 sql MySQL [oceanbase]> SELECT * FROM oceanbase.CDB_OB_ZONE_MAJOR_COMPACTION;  ZONE   LAST_SCN             START_TIME                   zone1  1664503499339325817  2022-09-30 10:04:59.369976   zone1                    1  1970-01-01 08:00:00.000000  2 rows in set 合并完成后，开始执行测试： shell ./runBenchmark.sh props.ob TPC-C 用 tpmC 值（Transactions per Minute）来衡量系统最大有效吞吐量。其中 Transactions 以 NewOrder Transaction 为准，即最终衡量单位",
        "product": "oceanbase",
        "version": "4.1.0"
    },
    {
        "path": "/Users/zhangying/Desktop/oceanbase-doc-4.1.0/zh-CN/200.quickstart/500.experience-advanced-features-of-oceanbase/100.experience-scalable-oltp/100.run-the-tpc-c-test-on-oceanbase-database.md",
        "content": "为每分钟处理的订单数。 体验 OceanBase 数据库 Scalable OLTP 上面的测试中，不管是单节点集群测试，还是多节点集群，默认情况下参与事务处理的只有一个副本 Zone，及租户 Leader 所在的副本。这是因为默认设置下，租户的 Leader 是按照 Zone 维度以一定优先级分布的。 OceanBase 作为分布式数据库，用户可以选择将一个租户的所有数据分区的多个 Leader 打散 Shuffle 到多个副本上，实现计算处理能力的多机线性扩展。 如果您的集群环境是三节点或更多节点的配置，您只需以管理员身份执行以下命令，然后再次启动测试，即可体验分布式集群在扩展模式下的处理能力。 sql alter tenant test set primary_zone='zone1'; 相关文档 更多有关使用 OBD 一键测试和手动进行 TPC-C 测试的信息，请参见 OceanBase 数据库 TPC-C 测试。",
        "product": "oceanbase",
        "version": "4.1.0"
    }
]
